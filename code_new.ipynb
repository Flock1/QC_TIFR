{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem:\n",
    "\n",
    "I am trying to solve a very basic quantum computing problem (No prior QC knowledge needed). I am trying to implement vanilla policy gradient to see if a model can be trained to make any quantum state reach equal superposition. Let me explain:\n",
    "\n",
    "A random quantum state is in superposition between 0 and 1 with some specific probability. eg, a rough example is 0.2|0> + 0.8|1>. So the probability for 0 is 0.2 and probability for 1 is 0.8. Equal superposition is 0.5|0> + 0.5|1>. So equal probability for 0 and 1. That's it!\n",
    "\n",
    "Now, the gate sequence that needs to be followed (for any random quantum state) is a measurement and Hadamard gate. This is the sequence that the model needs to learn and I have defined these gates in the method \"functions\" and I call these gates using the variable \"command\" as initialised few cells down. \n",
    "\n",
    "So I create an \"Environment\" that randomly initialises a random quantum state and returns that. Then, I create a model and train it according to vanilla PG and I also have a greedy epsilon strategy as \"get_exploration_rate\". So if you run, the model doesn't seem to converge at all. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from qiskit.quantum_info import random_state\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import math\n",
    "import random\n",
    "from functions import *\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# import objgraph\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is in case you make changes to any python file'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This is in case you make changes to any python file'''\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "# from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in discounted reward\n",
      "[[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "[[ 1.37769927]\n",
      " [ 0.72416108]\n",
      " [ 0.03622616]\n",
      " [-0.68791587]\n",
      " [-1.45017064]]\n"
     ]
    }
   ],
   "source": [
    "r = [0.0,0.0,0.0,0.0,-1.0]\n",
    "gamma = 0.95\n",
    "r = np.vstack(r)\n",
    "d_rw = discounted_reward(r,gamma)\n",
    "print(d_rw)\n",
    "d_rw -= np.mean(d_rw)\n",
    "d_rw /= np.std(d_rw)\n",
    "print(d_rw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "\n",
    "    def reset(self):\n",
    "        state = random_state(2)\n",
    "        new_state = state_norm(state)\n",
    "        new_state = np.reshape(new_state.flatten(), (1,1,2))\n",
    "        return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The exploration-exploitation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class epsilod_strategy():\n",
    "#     def __init__(self, start, end, decay):\n",
    "#         self.start = start\n",
    "#         self.end = end\n",
    "#         self.decay = decay\n",
    "    \n",
    "def get_exploration_rate(current_step, start, end, decay):\n",
    "\n",
    "    return max(end, end + (start - end)/math.exp(1.*current_step*decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 1.0\n",
    "end = 0.01\n",
    "decay = 0.009\n",
    "x = []\n",
    "for i in range(10000):\n",
    "    x.append(max(end, get_exploration_rate(i, start, end, decay)))\n",
    "\n",
    "plt.plot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The changes I made:\n",
    "\n",
    "Commenting lines 141 and 142 (basically no standardising the discounting sum of rewards)and changing the formula for \"label\" in line 150 and replacing it with line 151."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, state_size, new_state, is_eval=False, model_name=\"\"):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = 6 # measurement, CNOT, bit-flip\n",
    "#         self.memory = deque(maxlen=1000)\n",
    "        self.inventory = []\n",
    "        self.model_name = model_name\n",
    "        self.value = new_state\n",
    "        self.is_eval = is_eval\n",
    "        self.done = False\n",
    "#         self.final_state = [1/math.sqrt(2),1/math.sqrt(2)]\n",
    "\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon_start = 1.0\n",
    "        self.epsilon_end = 0.01\n",
    "        self.epsilon_decay = 0.009\n",
    "        self.learning_rate = 0.01\n",
    "        self.model = self.QC_model()\n",
    "#         self.model = load_model(\"model_June_23.h5\")\n",
    "        self.current_step = 0\n",
    "        self.final_state = np.array([(1/math.sqrt(2))+0j,(1/math.sqrt(2))+0j])\n",
    "\n",
    "#         self.model = load_model(\"models/\" + model_name) if is_eval else self._model()\n",
    "\n",
    "# '''\n",
    "# Method to initialize the network model. It contains 4 fully connected layers, where the last layer gives the\n",
    "# prbabilities of the gates\n",
    "\n",
    "# The network will be optmised using adam optimizer. \n",
    "\n",
    "# '''\n",
    "    def QC_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=16, input_shape=self.state_size, activation=\"relu\", name='layer1'))\n",
    "        model.add(Dense(units=32, activation=\"relu\", name='layer2'))\n",
    "        model.add(Dense(units=8, activation=\"relu\", name='layer3'))\n",
    "        model.add(Dense(self.action_size, activation=\"softmax\"))\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=0.003))\n",
    "        return model\n",
    "# '''\n",
    "# This defines how we select the action using exploration-exploitation rate, we defined above. \n",
    "\n",
    "# If random is more than the output of the exploration rate, then we select exploration. Else, exploitation. \n",
    "# The exploration rate reduces exponentially and we start exploiting rather than exploring by the last epochs. \n",
    "# The rate plot can be assesed through the cell the above\n",
    "\n",
    "# '''\n",
    "\n",
    "    def act(self, state, episode): #add episode to reduce the epsilon value\n",
    "#        action = 0\n",
    "        rate = get_exploration_rate(episode, self.epsilon_start, self.epsilon_end, self.epsilon_decay)\n",
    "        if random.random() <= rate:\n",
    "            options = self.model.predict(state)\n",
    "            options = np.squeeze(options)\n",
    "            action =  random.randrange(self.action_size)\n",
    "        else:\n",
    "            options = self.model.predict(state)\n",
    "            options = np.squeeze(options)\n",
    "    #             print(\"PROBABILITIES: \", options)\n",
    "#             print(options)\n",
    "            action = np.where(options == np.amax(options))[0][0]\n",
    "#         print(\"PROBABILITIES OPTIONS: \", options.shape)\n",
    "#         options = np.squeeze(options)\n",
    "        return action, options\n",
    "\n",
    "# '''\n",
    "# Method to collect data and train the model. \n",
    "\n",
    "# '''\n",
    "\n",
    "    def train(self):\n",
    "#         column_name = ['episode','time_step','reward', 'projection']\n",
    "#         with open('reward.csv','a') as fd:\n",
    "#             write_outfile = csv.writer(fd)\n",
    "#             write_outfile.writerow(column_name)\n",
    "        batch_size = 10\n",
    "        t = 0                   #increment\n",
    "        states, prob_actions, dlogps, drs, reward_data =[], [], [], [], []  #initialize the list variables\n",
    "        tr_x, tr_y = [],[]\n",
    "        avg_reward = []\n",
    "        reward_sum = 0\n",
    "        ep_number = 0\n",
    "        prev_state = None\n",
    "        new_state = self.value\n",
    "\n",
    "        while ep_number<1000:\n",
    "            print(\"episode number: \",ep_number)\n",
    "            prev_state = new_state          # Store the initial state\n",
    "            states.append(new_state)\n",
    "            action, probs = self.act(new_state, ep_number)        # send the state through the network and get the output\n",
    "            prob_actions.append(probs)\n",
    "            y = np.zeros([self.action_size])\n",
    "            new_state = np.squeeze(new_state)\n",
    "            y[action] = 1                         # one hot encoding for the actions\n",
    "            new_state = eval(command[action])       # run the command according to the action predicted by the network\n",
    "            if(np.allclose(new_state,self.final_state)):    # if the state is equal to the final state\n",
    "                rw = 1\n",
    "                drs.append(rw)\n",
    "                reward_sum+=rw\n",
    "                self.done = True                # set done = True so that we can train the network on the data\n",
    "            if(t<4 and not np.allclose(new_state,self.final_state)):  # when we are NOT done with the episode and want to store the reward\n",
    "                rw = reward(new_state, self.final_state)\n",
    "                drs.append(rw)\n",
    "                reward_sum+=rw\n",
    "            elif(t==4):                      # when we have reached the final time stamp for the episode\n",
    "                self.done = True\n",
    "                if not np.allclose(new_state, self.final_state):\n",
    "                    rw = -1\n",
    "                    drs.append(rw)\n",
    "                    reward_sum+=rw\n",
    "#             reward_data = [ep_number, t, reward_sum, proj]\n",
    "#             with open('reward.csv','a') as fd:\n",
    "#                 write_outfile = csv.writer(fd)\n",
    "#                 write_outfile.writerow(reward_data)\n",
    "#            with open('reward.csv','a') as fd:\n",
    "#                write_outfile = csv.writer(fd)\n",
    "#                write_outfile.writerow((reward_sum))\n",
    "            new_state = np.reshape(new_state, (1,1,2))   #get the shape of state according to keras requirements\n",
    "#             print(\"State: \", new_state)\n",
    "#             proj = projection(new_state, self.final_state)\n",
    "#             print(\"projection: \", proj)\n",
    "#             proj_data.append(proj)\n",
    "            print(\"reward till now: \",reward_sum)\n",
    "#            print(\"probs: \", probs.shape)\n",
    "            dlogps.append(np.array(y).astype('float32') * probs)  # multiply one hot encoding to the probabilities\n",
    "#             print(\"dlogps before time step: \",(dlogps[0].shape))\n",
    "            del(probs, action) \n",
    "            print(\"time step: \",t)\n",
    "            t+=1\n",
    "            if(self.done):                         #### Done State\n",
    "                ep_number+=1\n",
    "                ep_x = np.vstack(states)                     # vertially stack the states we used to train the network on\n",
    "#                 print(\"length of states: \", len(ep_x))\n",
    "                ep_dlogp = np.vstack(dlogps)                 # vertically stack the action probabilities we got for the states above\n",
    "#                 print(\"dlogps: \", len(dlogps))\n",
    "                ep_reward = np.vstack(drs)                   # vertically stack the rewards corresponding to the state-action pairs\n",
    "                disc_rw = discounted_reward(ep_reward,self.gamma)\n",
    "                print(\"disc_rw: \", (disc_rw))\n",
    "#                 print(\"ep_dlogp: \", (ep_dlogp[0].shape))\n",
    "                disc_rw = disc_rw.astype('float32')\n",
    "#                 disc_rw -= np.mean(disc_rw)\n",
    "#                 disc_rw /= np.std(disc_rw)\n",
    "\n",
    "                tr_y_len = len(ep_dlogp)\n",
    "#                 print(\"ep_dlogp: \", len(ep_dlogp))\n",
    "                ep_dlogp*=disc_rw\n",
    "#                states, drs =[], []\n",
    "                if ep_number % batch_size == 0:\n",
    "\n",
    "#                     input_tr_y = prob_actions - self.learning_rate * ep_dlogp\n",
    "                    input_tr_y = ep_dlogp\n",
    "                    input_tr_y = np.reshape(input_tr_y, (tr_y_len,1,6))\n",
    "\n",
    "                    self.model.train_on_batch(ep_x, input_tr_y)\n",
    "                    dlogps, drs, states, prob_actions,proj_data, reward_data = [],[],[],[],[],[]\n",
    "                avg_reward.append((reward_sum))\n",
    "#                 if(ep_number%1000==0):\n",
    "#                     self.model.save(\"model_ep{:}.h5\".format(ep_number))\n",
    "#                 if len(avg_reward)>100: avg_reward.pop(0)\n",
    "                print('Episode {:} reward {:.2f}, Last 30ep Avg. rewards {:.2f}.'.format(\n",
    "                    ep_number,reward_sum,avg_reward[ep_number-1]))\n",
    "                env = Environment()\n",
    "                state = env.reset()\n",
    "                t=0\n",
    "                self.done=False\n",
    "#                 objgraph.show_most_common_types()\n",
    "\n",
    "        return avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['bit_flip_X(new_state)',\n",
    "           'bit_flip_Y(new_state)',\n",
    "           'hadamard_X(new_state)',\n",
    "           'hadamard_Y(new_state)',\n",
    "           'measurement(new_state[0],new_state[1])',\n",
    "           'nothing(new_state)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_exploration_rate(current_step, start, end, decay):\n",
    "        \n",
    "#         return end + (start - end)/math.exp(1.*current_step*decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: The `random_state` function is deprecated as of 0.13.0, and will be removed no earlier than 3 months after that release date. You should use the `random_statevector` function instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode number:  0\n",
      "reward till now:  0.0\n",
      "time step:  0\n",
      "episode number:  0\n",
      "reward till now:  0.0\n",
      "time step:  1\n",
      "episode number:  0\n",
      "reward till now:  0.0\n",
      "time step:  2\n",
      "episode number:  0\n",
      "reward till now:  0.0\n",
      "time step:  3\n",
      "episode number:  0\n",
      "reward till now:  -1.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 1 reward -1.00, Last 30ep Avg. rewards -1.00.\n",
      "episode number:  1\n",
      "reward till now:  -1.0\n",
      "time step:  0\n",
      "episode number:  1\n",
      "reward till now:  -1.0\n",
      "time step:  1\n",
      "episode number:  1\n",
      "reward till now:  -1.0\n",
      "time step:  2\n",
      "episode number:  1\n",
      "reward till now:  -1.0\n",
      "time step:  3\n",
      "episode number:  1\n",
      "reward till now:  -2.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 2 reward -2.00, Last 30ep Avg. rewards -2.00.\n",
      "episode number:  2\n",
      "reward till now:  -2.0\n",
      "time step:  0\n",
      "episode number:  2\n",
      "reward till now:  -2.0\n",
      "time step:  1\n",
      "episode number:  2\n",
      "reward till now:  -2.0\n",
      "time step:  2\n",
      "episode number:  2\n",
      "reward till now:  -2.0\n",
      "time step:  3\n",
      "episode number:  2\n",
      "reward till now:  -1.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 3 reward -1.00, Last 30ep Avg. rewards -1.00.\n",
      "episode number:  3\n",
      "reward till now:  0.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 4 reward 0.00, Last 30ep Avg. rewards 0.00.\n",
      "episode number:  4\n",
      "reward till now:  0.0\n",
      "time step:  0\n",
      "episode number:  4\n",
      "reward till now:  0.0\n",
      "time step:  1\n",
      "episode number:  4\n",
      "reward till now:  0.0\n",
      "time step:  2\n",
      "episode number:  4\n",
      "reward till now:  0.0\n",
      "time step:  3\n",
      "episode number:  4\n",
      "reward till now:  -1.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 5 reward -1.00, Last 30ep Avg. rewards -1.00.\n",
      "episode number:  5\n",
      "reward till now:  -1.0\n",
      "time step:  0\n",
      "episode number:  5\n",
      "reward till now:  -1.0\n",
      "time step:  1\n",
      "episode number:  5\n",
      "reward till now:  -1.0\n",
      "time step:  2\n",
      "episode number:  5\n",
      "reward till now:  -1.0\n",
      "time step:  3\n",
      "episode number:  5\n",
      "reward till now:  -2.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 6 reward -2.00, Last 30ep Avg. rewards -2.00.\n",
      "episode number:  6\n",
      "reward till now:  -2.0\n",
      "time step:  0\n",
      "episode number:  6\n",
      "reward till now:  -2.0\n",
      "time step:  1\n",
      "episode number:  6\n",
      "reward till now:  -2.0\n",
      "time step:  2\n",
      "episode number:  6\n",
      "reward till now:  -2.0\n",
      "time step:  3\n",
      "episode number:  6\n",
      "reward till now:  -3.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 7 reward -3.00, Last 30ep Avg. rewards -3.00.\n",
      "episode number:  7\n",
      "reward till now:  -3.0\n",
      "time step:  0\n",
      "episode number:  7\n",
      "reward till now:  -3.0\n",
      "time step:  1\n",
      "episode number:  7\n",
      "reward till now:  -3.0\n",
      "time step:  2\n",
      "episode number:  7\n",
      "reward till now:  -3.0\n",
      "time step:  3\n",
      "episode number:  7\n",
      "reward till now:  -4.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 8 reward -4.00, Last 30ep Avg. rewards -4.00.\n",
      "episode number:  8\n",
      "reward till now:  -4.0\n",
      "time step:  0\n",
      "episode number:  8\n",
      "reward till now:  -4.0\n",
      "time step:  1\n",
      "episode number:  8\n",
      "reward till now:  -4.0\n",
      "time step:  2\n",
      "episode number:  8\n",
      "reward till now:  -4.0\n",
      "time step:  3\n",
      "episode number:  8\n",
      "reward till now:  -5.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 9 reward -5.00, Last 30ep Avg. rewards -5.00.\n",
      "episode number:  9\n",
      "reward till now:  -5.0\n",
      "time step:  0\n",
      "episode number:  9\n",
      "reward till now:  -5.0\n",
      "time step:  1\n",
      "episode number:  9\n",
      "reward till now:  -5.0\n",
      "time step:  2\n",
      "episode number:  9\n",
      "reward till now:  -5.0\n",
      "time step:  3\n",
      "episode number:  9\n",
      "reward till now:  -6.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py:96: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: The `random_state` function is deprecated as of 0.13.0, and will be removed no earlier than 3 months after that release date. You should use the `random_statevector` function instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 reward -6.00, Last 30ep Avg. rewards -6.00.\n",
      "episode number:  10\n",
      "reward till now:  -5.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 11 reward -5.00, Last 30ep Avg. rewards -5.00.\n",
      "episode number:  11\n",
      "reward till now:  -4.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 12 reward -4.00, Last 30ep Avg. rewards -4.00.\n",
      "episode number:  12\n",
      "reward till now:  -4.0\n",
      "time step:  0\n",
      "episode number:  12\n",
      "reward till now:  -4.0\n",
      "time step:  1\n",
      "episode number:  12\n",
      "reward till now:  -4.0\n",
      "time step:  2\n",
      "episode number:  12\n",
      "reward till now:  -4.0\n",
      "time step:  3\n",
      "episode number:  12\n",
      "reward till now:  -3.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[1.        ]\n",
      " [1.        ]\n",
      " [0.81450625]\n",
      " [0.857375  ]\n",
      " [0.9025    ]\n",
      " [0.95      ]\n",
      " [1.        ]]\n",
      "Episode 13 reward -3.00, Last 30ep Avg. rewards -3.00.\n",
      "episode number:  13\n",
      "reward till now:  -3.0\n",
      "time step:  0\n",
      "episode number:  13\n",
      "reward till now:  -3.0\n",
      "time step:  1\n",
      "episode number:  13\n",
      "reward till now:  -3.0\n",
      "time step:  2\n",
      "episode number:  13\n",
      "reward till now:  -2.0\n",
      "time step:  3\n",
      "in discounted reward\n",
      "disc_rw:  [[1.        ]\n",
      " [1.        ]\n",
      " [0.81450625]\n",
      " [0.857375  ]\n",
      " [0.9025    ]\n",
      " [0.95      ]\n",
      " [1.        ]\n",
      " [0.857375  ]\n",
      " [0.9025    ]\n",
      " [0.95      ]\n",
      " [1.        ]]\n",
      "Episode 14 reward -2.00, Last 30ep Avg. rewards -2.00.\n",
      "episode number:  14\n",
      "reward till now:  -2.0\n",
      "time step:  0\n",
      "episode number:  14\n",
      "reward till now:  -2.0\n",
      "time step:  1\n",
      "episode number:  14\n",
      "reward till now:  -2.0\n",
      "time step:  2\n",
      "episode number:  14\n",
      "reward till now:  -2.0\n",
      "time step:  3\n",
      "episode number:  14\n",
      "reward till now:  -3.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 15 reward -3.00, Last 30ep Avg. rewards -3.00.\n",
      "episode number:  15\n",
      "reward till now:  -3.0\n",
      "time step:  0\n",
      "episode number:  15\n",
      "reward till now:  -3.0\n",
      "time step:  1\n",
      "episode number:  15\n",
      "reward till now:  -3.0\n",
      "time step:  2\n",
      "episode number:  15\n",
      "reward till now:  -3.0\n",
      "time step:  3\n",
      "episode number:  15\n",
      "reward till now:  -4.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 16 reward -4.00, Last 30ep Avg. rewards -4.00.\n",
      "episode number:  16\n",
      "reward till now:  -4.0\n",
      "time step:  0\n",
      "episode number:  16\n",
      "reward till now:  -4.0\n",
      "time step:  1\n",
      "episode number:  16\n",
      "reward till now:  -4.0\n",
      "time step:  2\n",
      "episode number:  16\n",
      "reward till now:  -4.0\n",
      "time step:  3\n",
      "episode number:  16\n",
      "reward till now:  -5.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 17 reward -5.00, Last 30ep Avg. rewards -5.00.\n",
      "episode number:  17\n",
      "reward till now:  -5.0\n",
      "time step:  0\n",
      "episode number:  17\n",
      "reward till now:  -5.0\n",
      "time step:  1\n",
      "episode number:  17\n",
      "reward till now:  -5.0\n",
      "time step:  2\n",
      "episode number:  17\n",
      "reward till now:  -5.0\n",
      "time step:  3\n",
      "episode number:  17\n",
      "reward till now:  -6.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 18 reward -6.00, Last 30ep Avg. rewards -6.00.\n",
      "episode number:  18\n",
      "reward till now:  -6.0\n",
      "time step:  0\n",
      "episode number:  18\n",
      "reward till now:  -6.0\n",
      "time step:  1\n",
      "episode number:  18\n",
      "reward till now:  -6.0\n",
      "time step:  2\n",
      "episode number:  18\n",
      "reward till now:  -6.0\n",
      "time step:  3\n",
      "episode number:  18\n",
      "reward till now:  -5.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 19 reward -5.00, Last 30ep Avg. rewards -5.00.\n",
      "episode number:  19\n",
      "reward till now:  -5.0\n",
      "time step:  0\n",
      "episode number:  19\n",
      "reward till now:  -5.0\n",
      "time step:  1\n",
      "episode number:  19\n",
      "reward till now:  -5.0\n",
      "time step:  2\n",
      "episode number:  19\n",
      "reward till now:  -5.0\n",
      "time step:  3\n",
      "episode number:  19\n",
      "reward till now:  -6.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 20 reward -6.00, Last 30ep Avg. rewards -6.00.\n",
      "episode number:  20\n",
      "reward till now:  -6.0\n",
      "time step:  0\n",
      "episode number:  20\n",
      "reward till now:  -6.0\n",
      "time step:  1\n",
      "episode number:  20\n",
      "reward till now:  -6.0\n",
      "time step:  2\n",
      "episode number:  20\n",
      "reward till now:  -6.0\n",
      "time step:  3\n",
      "episode number:  20\n",
      "reward till now:  -7.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 21 reward -7.00, Last 30ep Avg. rewards -7.00.\n",
      "episode number:  21\n",
      "reward till now:  -7.0\n",
      "time step:  0\n",
      "episode number:  21\n",
      "reward till now:  -7.0\n",
      "time step:  1\n",
      "episode number:  21\n",
      "reward till now:  -7.0\n",
      "time step:  2\n",
      "episode number:  21\n",
      "reward till now:  -7.0\n",
      "time step:  3\n",
      "episode number:  21\n",
      "reward till now:  -8.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 22 reward -8.00, Last 30ep Avg. rewards -8.00.\n",
      "episode number:  22\n",
      "reward till now:  -8.0\n",
      "time step:  0\n",
      "episode number:  22\n",
      "reward till now:  -8.0\n",
      "time step:  1\n",
      "episode number:  22\n",
      "reward till now:  -8.0\n",
      "time step:  2\n",
      "episode number:  22\n",
      "reward till now:  -8.0\n",
      "time step:  3\n",
      "episode number:  22\n",
      "reward till now:  -9.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 23 reward -9.00, Last 30ep Avg. rewards -9.00.\n",
      "episode number:  23\n",
      "reward till now:  -9.0\n",
      "time step:  0\n",
      "episode number:  23\n",
      "reward till now:  -9.0\n",
      "time step:  1\n",
      "episode number:  23\n",
      "reward till now:  -9.0\n",
      "time step:  2\n",
      "episode number:  23\n",
      "reward till now:  -9.0\n",
      "time step:  3\n",
      "episode number:  23\n",
      "reward till now:  -10.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 24 reward -10.00, Last 30ep Avg. rewards -10.00.\n",
      "episode number:  24\n",
      "reward till now:  -10.0\n",
      "time step:  0\n",
      "episode number:  24\n",
      "reward till now:  -10.0\n",
      "time step:  1\n",
      "episode number:  24\n",
      "reward till now:  -10.0\n",
      "time step:  2\n",
      "episode number:  24\n",
      "reward till now:  -10.0\n",
      "time step:  3\n",
      "episode number:  24\n",
      "reward till now:  -11.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 25 reward -11.00, Last 30ep Avg. rewards -11.00.\n",
      "episode number:  25\n",
      "reward till now:  -11.0\n",
      "time step:  0\n",
      "episode number:  25\n",
      "reward till now:  -11.0\n",
      "time step:  1\n",
      "episode number:  25\n",
      "reward till now:  -11.0\n",
      "time step:  2\n",
      "episode number:  25\n",
      "reward till now:  -11.0\n",
      "time step:  3\n",
      "episode number:  25\n",
      "reward till now:  -12.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 26 reward -12.00, Last 30ep Avg. rewards -12.00.\n",
      "episode number:  26\n",
      "reward till now:  -12.0\n",
      "time step:  0\n",
      "episode number:  26\n",
      "reward till now:  -12.0\n",
      "time step:  1\n",
      "episode number:  26\n",
      "reward till now:  -12.0\n",
      "time step:  2\n",
      "episode number:  26\n",
      "reward till now:  -12.0\n",
      "time step:  3\n",
      "episode number:  26\n",
      "reward till now:  -13.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 27 reward -13.00, Last 30ep Avg. rewards -13.00.\n",
      "episode number:  27\n",
      "reward till now:  -13.0\n",
      "time step:  0\n",
      "episode number:  27\n",
      "reward till now:  -13.0\n",
      "time step:  1\n",
      "episode number:  27\n",
      "reward till now:  -13.0\n",
      "time step:  2\n",
      "episode number:  27\n",
      "reward till now:  -13.0\n",
      "time step:  3\n",
      "episode number:  27\n",
      "reward till now:  -14.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 28 reward -14.00, Last 30ep Avg. rewards -14.00.\n",
      "episode number:  28\n",
      "reward till now:  -14.0\n",
      "time step:  0\n",
      "episode number:  28\n",
      "reward till now:  -14.0\n",
      "time step:  1\n",
      "episode number:  28\n",
      "reward till now:  -14.0\n",
      "time step:  2\n",
      "episode number:  28\n",
      "reward till now:  -14.0\n",
      "time step:  3\n",
      "episode number:  28\n",
      "reward till now:  -15.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 29 reward -15.00, Last 30ep Avg. rewards -15.00.\n",
      "episode number:  29\n",
      "reward till now:  -15.0\n",
      "time step:  0\n",
      "episode number:  29\n",
      "reward till now:  -15.0\n",
      "time step:  1\n",
      "episode number:  29\n",
      "reward till now:  -15.0\n",
      "time step:  2\n",
      "episode number:  29\n",
      "reward till now:  -15.0\n",
      "time step:  3\n",
      "episode number:  29\n",
      "reward till now:  -16.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 30 reward -16.00, Last 30ep Avg. rewards -16.00.\n",
      "episode number:  30\n",
      "reward till now:  -16.0\n",
      "time step:  0\n",
      "episode number:  30\n",
      "reward till now:  -16.0\n",
      "time step:  1\n",
      "episode number:  30\n",
      "reward till now:  -16.0\n",
      "time step:  2\n",
      "episode number:  30\n",
      "reward till now:  -16.0\n",
      "time step:  3\n",
      "episode number:  30\n",
      "reward till now:  -17.0\n",
      "time step:  4\n",
      "in discounted reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 31 reward -17.00, Last 30ep Avg. rewards -17.00.\n",
      "episode number:  31\n",
      "reward till now:  -17.0\n",
      "time step:  0\n",
      "episode number:  31\n",
      "reward till now:  -17.0\n",
      "time step:  1\n",
      "episode number:  31\n",
      "reward till now:  -17.0\n",
      "time step:  2\n",
      "episode number:  31\n",
      "reward till now:  -17.0\n",
      "time step:  3\n",
      "episode number:  31\n",
      "reward till now:  -18.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 32 reward -18.00, Last 30ep Avg. rewards -18.00.\n",
      "episode number:  32\n",
      "reward till now:  -18.0\n",
      "time step:  0\n",
      "episode number:  32\n",
      "reward till now:  -18.0\n",
      "time step:  1\n",
      "episode number:  32\n",
      "reward till now:  -18.0\n",
      "time step:  2\n",
      "episode number:  32\n",
      "reward till now:  -18.0\n",
      "time step:  3\n",
      "episode number:  32\n",
      "reward till now:  -19.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 33 reward -19.00, Last 30ep Avg. rewards -19.00.\n",
      "episode number:  33\n",
      "reward till now:  -19.0\n",
      "time step:  0\n",
      "episode number:  33\n",
      "reward till now:  -19.0\n",
      "time step:  1\n",
      "episode number:  33\n",
      "reward till now:  -19.0\n",
      "time step:  2\n",
      "episode number:  33\n",
      "reward till now:  -19.0\n",
      "time step:  3\n",
      "episode number:  33\n",
      "reward till now:  -20.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 34 reward -20.00, Last 30ep Avg. rewards -20.00.\n",
      "episode number:  34\n",
      "reward till now:  -20.0\n",
      "time step:  0\n",
      "episode number:  34\n",
      "reward till now:  -20.0\n",
      "time step:  1\n",
      "episode number:  34\n",
      "reward till now:  -20.0\n",
      "time step:  2\n",
      "episode number:  34\n",
      "reward till now:  -20.0\n",
      "time step:  3\n",
      "episode number:  34\n",
      "reward till now:  -21.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 35 reward -21.00, Last 30ep Avg. rewards -21.00.\n",
      "episode number:  35\n",
      "reward till now:  -21.0\n",
      "time step:  0\n",
      "episode number:  35\n",
      "reward till now:  -21.0\n",
      "time step:  1\n",
      "episode number:  35\n",
      "reward till now:  -21.0\n",
      "time step:  2\n",
      "episode number:  35\n",
      "reward till now:  -21.0\n",
      "time step:  3\n",
      "episode number:  35\n",
      "reward till now:  -22.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 36 reward -22.00, Last 30ep Avg. rewards -22.00.\n",
      "episode number:  36\n",
      "reward till now:  -22.0\n",
      "time step:  0\n",
      "episode number:  36\n",
      "reward till now:  -22.0\n",
      "time step:  1\n",
      "episode number:  36\n",
      "reward till now:  -22.0\n",
      "time step:  2\n",
      "episode number:  36\n",
      "reward till now:  -22.0\n",
      "time step:  3\n",
      "episode number:  36\n",
      "reward till now:  -23.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 37 reward -23.00, Last 30ep Avg. rewards -23.00.\n",
      "episode number:  37\n",
      "reward till now:  -23.0\n",
      "time step:  0\n",
      "episode number:  37\n",
      "reward till now:  -23.0\n",
      "time step:  1\n",
      "episode number:  37\n",
      "reward till now:  -23.0\n",
      "time step:  2\n",
      "episode number:  37\n",
      "reward till now:  -23.0\n",
      "time step:  3\n",
      "episode number:  37\n",
      "reward till now:  -24.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 38 reward -24.00, Last 30ep Avg. rewards -24.00.\n",
      "episode number:  38\n",
      "reward till now:  -24.0\n",
      "time step:  0\n",
      "episode number:  38\n",
      "reward till now:  -24.0\n",
      "time step:  1\n",
      "episode number:  38\n",
      "reward till now:  -24.0\n",
      "time step:  2\n",
      "episode number:  38\n",
      "reward till now:  -24.0\n",
      "time step:  3\n",
      "episode number:  38\n",
      "reward till now:  -25.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 39 reward -25.00, Last 30ep Avg. rewards -25.00.\n",
      "episode number:  39\n",
      "reward till now:  -25.0\n",
      "time step:  0\n",
      "episode number:  39\n",
      "reward till now:  -25.0\n",
      "time step:  1\n",
      "episode number:  39\n",
      "reward till now:  -25.0\n",
      "time step:  2\n",
      "episode number:  39\n",
      "reward till now:  -25.0\n",
      "time step:  3\n",
      "episode number:  39\n",
      "reward till now:  -26.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 40 reward -26.00, Last 30ep Avg. rewards -26.00.\n",
      "episode number:  40\n",
      "reward till now:  -26.0\n",
      "time step:  0\n",
      "episode number:  40\n",
      "reward till now:  -26.0\n",
      "time step:  1\n",
      "episode number:  40\n",
      "reward till now:  -26.0\n",
      "time step:  2\n",
      "episode number:  40\n",
      "reward till now:  -26.0\n",
      "time step:  3\n",
      "episode number:  40\n",
      "reward till now:  -27.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 41 reward -27.00, Last 30ep Avg. rewards -27.00.\n",
      "episode number:  41\n",
      "reward till now:  -27.0\n",
      "time step:  0\n",
      "episode number:  41\n",
      "reward till now:  -27.0\n",
      "time step:  1\n",
      "episode number:  41\n",
      "reward till now:  -27.0\n",
      "time step:  2\n",
      "episode number:  41\n",
      "reward till now:  -27.0\n",
      "time step:  3\n",
      "episode number:  41\n",
      "reward till now:  -28.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 42 reward -28.00, Last 30ep Avg. rewards -28.00.\n",
      "episode number:  42\n",
      "reward till now:  -28.0\n",
      "time step:  0\n",
      "episode number:  42\n",
      "reward till now:  -28.0\n",
      "time step:  1\n",
      "episode number:  42\n",
      "reward till now:  -28.0\n",
      "time step:  2\n",
      "episode number:  42\n",
      "reward till now:  -28.0\n",
      "time step:  3\n",
      "episode number:  42\n",
      "reward till now:  -29.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 43 reward -29.00, Last 30ep Avg. rewards -29.00.\n",
      "episode number:  43\n",
      "reward till now:  -29.0\n",
      "time step:  0\n",
      "episode number:  43\n",
      "reward till now:  -29.0\n",
      "time step:  1\n",
      "episode number:  43\n",
      "reward till now:  -29.0\n",
      "time step:  2\n",
      "episode number:  43\n",
      "reward till now:  -29.0\n",
      "time step:  3\n",
      "episode number:  43\n",
      "reward till now:  -30.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 44 reward -30.00, Last 30ep Avg. rewards -30.00.\n",
      "episode number:  44\n",
      "reward till now:  -30.0\n",
      "time step:  0\n",
      "episode number:  44\n",
      "reward till now:  -30.0\n",
      "time step:  1\n",
      "episode number:  44\n",
      "reward till now:  -30.0\n",
      "time step:  2\n",
      "episode number:  44\n",
      "reward till now:  -30.0\n",
      "time step:  3\n",
      "episode number:  44\n",
      "reward till now:  -29.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 45 reward -29.00, Last 30ep Avg. rewards -29.00.\n",
      "episode number:  45\n",
      "reward till now:  -28.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 46 reward -28.00, Last 30ep Avg. rewards -28.00.\n",
      "episode number:  46\n",
      "reward till now:  -28.0\n",
      "time step:  0\n",
      "episode number:  46\n",
      "reward till now:  -27.0\n",
      "time step:  1\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 47 reward -27.00, Last 30ep Avg. rewards -27.00.\n",
      "episode number:  47\n",
      "reward till now:  -27.0\n",
      "time step:  0\n",
      "episode number:  47\n",
      "reward till now:  -27.0\n",
      "time step:  1\n",
      "episode number:  47\n",
      "reward till now:  -27.0\n",
      "time step:  2\n",
      "episode number:  47\n",
      "reward till now:  -27.0\n",
      "time step:  3\n",
      "episode number:  47\n",
      "reward till now:  -28.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 48 reward -28.00, Last 30ep Avg. rewards -28.00.\n",
      "episode number:  48\n",
      "reward till now:  -28.0\n",
      "time step:  0\n",
      "episode number:  48\n",
      "reward till now:  -28.0\n",
      "time step:  1\n",
      "episode number:  48\n",
      "reward till now:  -28.0\n",
      "time step:  2\n",
      "episode number:  48\n",
      "reward till now:  -28.0\n",
      "time step:  3\n",
      "episode number:  48\n",
      "reward till now:  -29.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 49 reward -29.00, Last 30ep Avg. rewards -29.00.\n",
      "episode number:  49\n",
      "reward till now:  -29.0\n",
      "time step:  0\n",
      "episode number:  49\n",
      "reward till now:  -29.0\n",
      "time step:  1\n",
      "episode number:  49\n",
      "reward till now:  -29.0\n",
      "time step:  2\n",
      "episode number:  49\n",
      "reward till now:  -29.0\n",
      "time step:  3\n",
      "episode number:  49\n",
      "reward till now:  -30.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 50 reward -30.00, Last 30ep Avg. rewards -30.00.\n",
      "episode number:  50\n",
      "reward till now:  -30.0\n",
      "time step:  0\n",
      "episode number:  50\n",
      "reward till now:  -30.0\n",
      "time step:  1\n",
      "episode number:  50\n",
      "reward till now:  -30.0\n",
      "time step:  2\n",
      "episode number:  50\n",
      "reward till now:  -30.0\n",
      "time step:  3\n",
      "episode number:  50\n",
      "reward till now:  -31.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 51 reward -31.00, Last 30ep Avg. rewards -31.00.\n",
      "episode number:  51\n",
      "reward till now:  -31.0\n",
      "time step:  0\n",
      "episode number:  51\n",
      "reward till now:  -31.0\n",
      "time step:  1\n",
      "episode number:  51\n",
      "reward till now:  -31.0\n",
      "time step:  2\n",
      "episode number:  51\n",
      "reward till now:  -31.0\n",
      "time step:  3\n",
      "episode number:  51\n",
      "reward till now:  -32.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 52 reward -32.00, Last 30ep Avg. rewards -32.00.\n",
      "episode number:  52\n",
      "reward till now:  -32.0\n",
      "time step:  0\n",
      "episode number:  52\n",
      "reward till now:  -32.0\n",
      "time step:  1\n",
      "episode number:  52\n",
      "reward till now:  -32.0\n",
      "time step:  2\n",
      "episode number:  52\n",
      "reward till now:  -32.0\n",
      "time step:  3\n",
      "episode number:  52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -33.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 53 reward -33.00, Last 30ep Avg. rewards -33.00.\n",
      "episode number:  53\n",
      "reward till now:  -33.0\n",
      "time step:  0\n",
      "episode number:  53\n",
      "reward till now:  -33.0\n",
      "time step:  1\n",
      "episode number:  53\n",
      "reward till now:  -33.0\n",
      "time step:  2\n",
      "episode number:  53\n",
      "reward till now:  -33.0\n",
      "time step:  3\n",
      "episode number:  53\n",
      "reward till now:  -34.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 54 reward -34.00, Last 30ep Avg. rewards -34.00.\n",
      "episode number:  54\n",
      "reward till now:  -34.0\n",
      "time step:  0\n",
      "episode number:  54\n",
      "reward till now:  -34.0\n",
      "time step:  1\n",
      "episode number:  54\n",
      "reward till now:  -34.0\n",
      "time step:  2\n",
      "episode number:  54\n",
      "reward till now:  -34.0\n",
      "time step:  3\n",
      "episode number:  54\n",
      "reward till now:  -35.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 55 reward -35.00, Last 30ep Avg. rewards -35.00.\n",
      "episode number:  55\n",
      "reward till now:  -35.0\n",
      "time step:  0\n",
      "episode number:  55\n",
      "reward till now:  -35.0\n",
      "time step:  1\n",
      "episode number:  55\n",
      "reward till now:  -35.0\n",
      "time step:  2\n",
      "episode number:  55\n",
      "reward till now:  -35.0\n",
      "time step:  3\n",
      "episode number:  55\n",
      "reward till now:  -36.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 56 reward -36.00, Last 30ep Avg. rewards -36.00.\n",
      "episode number:  56\n",
      "reward till now:  -36.0\n",
      "time step:  0\n",
      "episode number:  56\n",
      "reward till now:  -36.0\n",
      "time step:  1\n",
      "episode number:  56\n",
      "reward till now:  -36.0\n",
      "time step:  2\n",
      "episode number:  56\n",
      "reward till now:  -36.0\n",
      "time step:  3\n",
      "episode number:  56\n",
      "reward till now:  -37.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 57 reward -37.00, Last 30ep Avg. rewards -37.00.\n",
      "episode number:  57\n",
      "reward till now:  -37.0\n",
      "time step:  0\n",
      "episode number:  57\n",
      "reward till now:  -37.0\n",
      "time step:  1\n",
      "episode number:  57\n",
      "reward till now:  -37.0\n",
      "time step:  2\n",
      "episode number:  57\n",
      "reward till now:  -37.0\n",
      "time step:  3\n",
      "episode number:  57\n",
      "reward till now:  -38.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 58 reward -38.00, Last 30ep Avg. rewards -38.00.\n",
      "episode number:  58\n",
      "reward till now:  -38.0\n",
      "time step:  0\n",
      "episode number:  58\n",
      "reward till now:  -38.0\n",
      "time step:  1\n",
      "episode number:  58\n",
      "reward till now:  -38.0\n",
      "time step:  2\n",
      "episode number:  58\n",
      "reward till now:  -38.0\n",
      "time step:  3\n",
      "episode number:  58\n",
      "reward till now:  -39.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 59 reward -39.00, Last 30ep Avg. rewards -39.00.\n",
      "episode number:  59\n",
      "reward till now:  -39.0\n",
      "time step:  0\n",
      "episode number:  59\n",
      "reward till now:  -39.0\n",
      "time step:  1\n",
      "episode number:  59\n",
      "reward till now:  -39.0\n",
      "time step:  2\n",
      "episode number:  59\n",
      "reward till now:  -39.0\n",
      "time step:  3\n",
      "episode number:  59\n",
      "reward till now:  -40.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 60 reward -40.00, Last 30ep Avg. rewards -40.00.\n",
      "episode number:  60\n",
      "reward till now:  -40.0\n",
      "time step:  0\n",
      "episode number:  60\n",
      "reward till now:  -40.0\n",
      "time step:  1\n",
      "episode number:  60\n",
      "reward till now:  -40.0\n",
      "time step:  2\n",
      "episode number:  60\n",
      "reward till now:  -40.0\n",
      "time step:  3\n",
      "episode number:  60\n",
      "reward till now:  -41.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 61 reward -41.00, Last 30ep Avg. rewards -41.00.\n",
      "episode number:  61\n",
      "reward till now:  -41.0\n",
      "time step:  0\n",
      "episode number:  61\n",
      "reward till now:  -41.0\n",
      "time step:  1\n",
      "episode number:  61\n",
      "reward till now:  -41.0\n",
      "time step:  2\n",
      "episode number:  61\n",
      "reward till now:  -41.0\n",
      "time step:  3\n",
      "episode number:  61\n",
      "reward till now:  -42.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 62 reward -42.00, Last 30ep Avg. rewards -42.00.\n",
      "episode number:  62\n",
      "reward till now:  -42.0\n",
      "time step:  0\n",
      "episode number:  62\n",
      "reward till now:  -42.0\n",
      "time step:  1\n",
      "episode number:  62\n",
      "reward till now:  -42.0\n",
      "time step:  2\n",
      "episode number:  62\n",
      "reward till now:  -42.0\n",
      "time step:  3\n",
      "episode number:  62\n",
      "reward till now:  -43.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 63 reward -43.00, Last 30ep Avg. rewards -43.00.\n",
      "episode number:  63\n",
      "reward till now:  -43.0\n",
      "time step:  0\n",
      "episode number:  63\n",
      "reward till now:  -43.0\n",
      "time step:  1\n",
      "episode number:  63\n",
      "reward till now:  -43.0\n",
      "time step:  2\n",
      "episode number:  63\n",
      "reward till now:  -43.0\n",
      "time step:  3\n",
      "episode number:  63\n",
      "reward till now:  -44.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 64 reward -44.00, Last 30ep Avg. rewards -44.00.\n",
      "episode number:  64\n",
      "reward till now:  -44.0\n",
      "time step:  0\n",
      "episode number:  64\n",
      "reward till now:  -44.0\n",
      "time step:  1\n",
      "episode number:  64\n",
      "reward till now:  -44.0\n",
      "time step:  2\n",
      "episode number:  64\n",
      "reward till now:  -44.0\n",
      "time step:  3\n",
      "episode number:  64\n",
      "reward till now:  -45.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 65 reward -45.00, Last 30ep Avg. rewards -45.00.\n",
      "episode number:  65\n",
      "reward till now:  -45.0\n",
      "time step:  0\n",
      "episode number:  65\n",
      "reward till now:  -45.0\n",
      "time step:  1\n",
      "episode number:  65\n",
      "reward till now:  -45.0\n",
      "time step:  2\n",
      "episode number:  65\n",
      "reward till now:  -45.0\n",
      "time step:  3\n",
      "episode number:  65\n",
      "reward till now:  -46.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 66 reward -46.00, Last 30ep Avg. rewards -46.00.\n",
      "episode number:  66\n",
      "reward till now:  -46.0\n",
      "time step:  0\n",
      "episode number:  66\n",
      "reward till now:  -46.0\n",
      "time step:  1\n",
      "episode number:  66\n",
      "reward till now:  -46.0\n",
      "time step:  2\n",
      "episode number:  66\n",
      "reward till now:  -46.0\n",
      "time step:  3\n",
      "episode number:  66\n",
      "reward till now:  -47.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 67 reward -47.00, Last 30ep Avg. rewards -47.00.\n",
      "episode number:  67\n",
      "reward till now:  -47.0\n",
      "time step:  0\n",
      "episode number:  67\n",
      "reward till now:  -46.0\n",
      "time step:  1\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 68 reward -46.00, Last 30ep Avg. rewards -46.00.\n",
      "episode number:  68\n",
      "reward till now:  -46.0\n",
      "time step:  0\n",
      "episode number:  68\n",
      "reward till now:  -46.0\n",
      "time step:  1\n",
      "episode number:  68\n",
      "reward till now:  -46.0\n",
      "time step:  2\n",
      "episode number:  68\n",
      "reward till now:  -46.0\n",
      "time step:  3\n",
      "episode number:  68\n",
      "reward till now:  -47.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 69 reward -47.00, Last 30ep Avg. rewards -47.00.\n",
      "episode number:  69\n",
      "reward till now:  -47.0\n",
      "time step:  0\n",
      "episode number:  69\n",
      "reward till now:  -47.0\n",
      "time step:  1\n",
      "episode number:  69\n",
      "reward till now:  -47.0\n",
      "time step:  2\n",
      "episode number:  69\n",
      "reward till now:  -47.0\n",
      "time step:  3\n",
      "episode number:  69\n",
      "reward till now:  -48.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 70 reward -48.00, Last 30ep Avg. rewards -48.00.\n",
      "episode number:  70\n",
      "reward till now:  -48.0\n",
      "time step:  0\n",
      "episode number:  70\n",
      "reward till now:  -48.0\n",
      "time step:  1\n",
      "episode number:  70\n",
      "reward till now:  -48.0\n",
      "time step:  2\n",
      "episode number:  70\n",
      "reward till now:  -48.0\n",
      "time step:  3\n",
      "episode number:  70\n",
      "reward till now:  -49.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 71 reward -49.00, Last 30ep Avg. rewards -49.00.\n",
      "episode number:  71\n",
      "reward till now:  -49.0\n",
      "time step:  0\n",
      "episode number:  71\n",
      "reward till now:  -49.0\n",
      "time step:  1\n",
      "episode number:  71\n",
      "reward till now:  -49.0\n",
      "time step:  2\n",
      "episode number:  71\n",
      "reward till now:  -49.0\n",
      "time step:  3\n",
      "episode number:  71\n",
      "reward till now:  -50.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 72 reward -50.00, Last 30ep Avg. rewards -50.00.\n",
      "episode number:  72\n",
      "reward till now:  -50.0\n",
      "time step:  0\n",
      "episode number:  72\n",
      "reward till now:  -50.0\n",
      "time step:  1\n",
      "episode number:  72\n",
      "reward till now:  -50.0\n",
      "time step:  2\n",
      "episode number:  72\n",
      "reward till now:  -50.0\n",
      "time step:  3\n",
      "episode number:  72\n",
      "reward till now:  -51.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 73 reward -51.00, Last 30ep Avg. rewards -51.00.\n",
      "episode number:  73\n",
      "reward till now:  -51.0\n",
      "time step:  0\n",
      "episode number:  73\n",
      "reward till now:  -51.0\n",
      "time step:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode number:  73\n",
      "reward till now:  -51.0\n",
      "time step:  2\n",
      "episode number:  73\n",
      "reward till now:  -51.0\n",
      "time step:  3\n",
      "episode number:  73\n",
      "reward till now:  -52.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 74 reward -52.00, Last 30ep Avg. rewards -52.00.\n",
      "episode number:  74\n",
      "reward till now:  -52.0\n",
      "time step:  0\n",
      "episode number:  74\n",
      "reward till now:  -52.0\n",
      "time step:  1\n",
      "episode number:  74\n",
      "reward till now:  -52.0\n",
      "time step:  2\n",
      "episode number:  74\n",
      "reward till now:  -52.0\n",
      "time step:  3\n",
      "episode number:  74\n",
      "reward till now:  -53.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 75 reward -53.00, Last 30ep Avg. rewards -53.00.\n",
      "episode number:  75\n",
      "reward till now:  -53.0\n",
      "time step:  0\n",
      "episode number:  75\n",
      "reward till now:  -53.0\n",
      "time step:  1\n",
      "episode number:  75\n",
      "reward till now:  -53.0\n",
      "time step:  2\n",
      "episode number:  75\n",
      "reward till now:  -53.0\n",
      "time step:  3\n",
      "episode number:  75\n",
      "reward till now:  -54.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 76 reward -54.00, Last 30ep Avg. rewards -54.00.\n",
      "episode number:  76\n",
      "reward till now:  -54.0\n",
      "time step:  0\n",
      "episode number:  76\n",
      "reward till now:  -54.0\n",
      "time step:  1\n",
      "episode number:  76\n",
      "reward till now:  -54.0\n",
      "time step:  2\n",
      "episode number:  76\n",
      "reward till now:  -54.0\n",
      "time step:  3\n",
      "episode number:  76\n",
      "reward till now:  -55.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 77 reward -55.00, Last 30ep Avg. rewards -55.00.\n",
      "episode number:  77\n",
      "reward till now:  -55.0\n",
      "time step:  0\n",
      "episode number:  77\n",
      "reward till now:  -55.0\n",
      "time step:  1\n",
      "episode number:  77\n",
      "reward till now:  -55.0\n",
      "time step:  2\n",
      "episode number:  77\n",
      "reward till now:  -55.0\n",
      "time step:  3\n",
      "episode number:  77\n",
      "reward till now:  -56.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 78 reward -56.00, Last 30ep Avg. rewards -56.00.\n",
      "episode number:  78\n",
      "reward till now:  -56.0\n",
      "time step:  0\n",
      "episode number:  78\n",
      "reward till now:  -56.0\n",
      "time step:  1\n",
      "episode number:  78\n",
      "reward till now:  -56.0\n",
      "time step:  2\n",
      "episode number:  78\n",
      "reward till now:  -56.0\n",
      "time step:  3\n",
      "episode number:  78\n",
      "reward till now:  -57.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 79 reward -57.00, Last 30ep Avg. rewards -57.00.\n",
      "episode number:  79\n",
      "reward till now:  -57.0\n",
      "time step:  0\n",
      "episode number:  79\n",
      "reward till now:  -57.0\n",
      "time step:  1\n",
      "episode number:  79\n",
      "reward till now:  -57.0\n",
      "time step:  2\n",
      "episode number:  79\n",
      "reward till now:  -57.0\n",
      "time step:  3\n",
      "episode number:  79\n",
      "reward till now:  -58.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 80 reward -58.00, Last 30ep Avg. rewards -58.00.\n",
      "episode number:  80\n",
      "reward till now:  -58.0\n",
      "time step:  0\n",
      "episode number:  80\n",
      "reward till now:  -58.0\n",
      "time step:  1\n",
      "episode number:  80\n",
      "reward till now:  -58.0\n",
      "time step:  2\n",
      "episode number:  80\n",
      "reward till now:  -58.0\n",
      "time step:  3\n",
      "episode number:  80\n",
      "reward till now:  -59.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 81 reward -59.00, Last 30ep Avg. rewards -59.00.\n",
      "episode number:  81\n",
      "reward till now:  -59.0\n",
      "time step:  0\n",
      "episode number:  81\n",
      "reward till now:  -59.0\n",
      "time step:  1\n",
      "episode number:  81\n",
      "reward till now:  -59.0\n",
      "time step:  2\n",
      "episode number:  81\n",
      "reward till now:  -59.0\n",
      "time step:  3\n",
      "episode number:  81\n",
      "reward till now:  -60.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 82 reward -60.00, Last 30ep Avg. rewards -60.00.\n",
      "episode number:  82\n",
      "reward till now:  -60.0\n",
      "time step:  0\n",
      "episode number:  82\n",
      "reward till now:  -60.0\n",
      "time step:  1\n",
      "episode number:  82\n",
      "reward till now:  -59.0\n",
      "time step:  2\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 83 reward -59.00, Last 30ep Avg. rewards -59.00.\n",
      "episode number:  83\n",
      "reward till now:  -59.0\n",
      "time step:  0\n",
      "episode number:  83\n",
      "reward till now:  -59.0\n",
      "time step:  1\n",
      "episode number:  83\n",
      "reward till now:  -59.0\n",
      "time step:  2\n",
      "episode number:  83\n",
      "reward till now:  -59.0\n",
      "time step:  3\n",
      "episode number:  83\n",
      "reward till now:  -60.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 84 reward -60.00, Last 30ep Avg. rewards -60.00.\n",
      "episode number:  84\n",
      "reward till now:  -60.0\n",
      "time step:  0\n",
      "episode number:  84\n",
      "reward till now:  -60.0\n",
      "time step:  1\n",
      "episode number:  84\n",
      "reward till now:  -60.0\n",
      "time step:  2\n",
      "episode number:  84\n",
      "reward till now:  -60.0\n",
      "time step:  3\n",
      "episode number:  84\n",
      "reward till now:  -61.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 85 reward -61.00, Last 30ep Avg. rewards -61.00.\n",
      "episode number:  85\n",
      "reward till now:  -61.0\n",
      "time step:  0\n",
      "episode number:  85\n",
      "reward till now:  -61.0\n",
      "time step:  1\n",
      "episode number:  85\n",
      "reward till now:  -61.0\n",
      "time step:  2\n",
      "episode number:  85\n",
      "reward till now:  -61.0\n",
      "time step:  3\n",
      "episode number:  85\n",
      "reward till now:  -62.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 86 reward -62.00, Last 30ep Avg. rewards -62.00.\n",
      "episode number:  86\n",
      "reward till now:  -62.0\n",
      "time step:  0\n",
      "episode number:  86\n",
      "reward till now:  -62.0\n",
      "time step:  1\n",
      "episode number:  86\n",
      "reward till now:  -62.0\n",
      "time step:  2\n",
      "episode number:  86\n",
      "reward till now:  -62.0\n",
      "time step:  3\n",
      "episode number:  86\n",
      "reward till now:  -61.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 87 reward -61.00, Last 30ep Avg. rewards -61.00.\n",
      "episode number:  87\n",
      "reward till now:  -61.0\n",
      "time step:  0\n",
      "episode number:  87\n",
      "reward till now:  -61.0\n",
      "time step:  1\n",
      "episode number:  87\n",
      "reward till now:  -61.0\n",
      "time step:  2\n",
      "episode number:  87\n",
      "reward till now:  -61.0\n",
      "time step:  3\n",
      "episode number:  87\n",
      "reward till now:  -62.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 88 reward -62.00, Last 30ep Avg. rewards -62.00.\n",
      "episode number:  88\n",
      "reward till now:  -62.0\n",
      "time step:  0\n",
      "episode number:  88\n",
      "reward till now:  -62.0\n",
      "time step:  1\n",
      "episode number:  88\n",
      "reward till now:  -61.0\n",
      "time step:  2\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 89 reward -61.00, Last 30ep Avg. rewards -61.00.\n",
      "episode number:  89\n",
      "reward till now:  -60.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.81450625]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 90 reward -60.00, Last 30ep Avg. rewards -60.00.\n",
      "episode number:  90\n",
      "reward till now:  -60.0\n",
      "time step:  0\n",
      "episode number:  90\n",
      "reward till now:  -60.0\n",
      "time step:  1\n",
      "episode number:  90\n",
      "reward till now:  -60.0\n",
      "time step:  2\n",
      "episode number:  90\n",
      "reward till now:  -60.0\n",
      "time step:  3\n",
      "episode number:  90\n",
      "reward till now:  -61.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 91 reward -61.00, Last 30ep Avg. rewards -61.00.\n",
      "episode number:  91\n",
      "reward till now:  -61.0\n",
      "time step:  0\n",
      "episode number:  91\n",
      "reward till now:  -60.0\n",
      "time step:  1\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 92 reward -60.00, Last 30ep Avg. rewards -60.00.\n",
      "episode number:  92\n",
      "reward till now:  -60.0\n",
      "time step:  0\n",
      "episode number:  92\n",
      "reward till now:  -60.0\n",
      "time step:  1\n",
      "episode number:  92\n",
      "reward till now:  -60.0\n",
      "time step:  2\n",
      "episode number:  92\n",
      "reward till now:  -60.0\n",
      "time step:  3\n",
      "episode number:  92\n",
      "reward till now:  -61.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 93 reward -61.00, Last 30ep Avg. rewards -61.00.\n",
      "episode number:  93\n",
      "reward till now:  -61.0\n",
      "time step:  0\n",
      "episode number:  93\n",
      "reward till now:  -61.0\n",
      "time step:  1\n",
      "episode number:  93\n",
      "reward till now:  -61.0\n",
      "time step:  2\n",
      "episode number:  93\n",
      "reward till now:  -61.0\n",
      "time step:  3\n",
      "episode number:  93\n",
      "reward till now:  -62.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 94 reward -62.00, Last 30ep Avg. rewards -62.00.\n",
      "episode number:  94\n",
      "reward till now:  -62.0\n",
      "time step:  0\n",
      "episode number:  94\n",
      "reward till now:  -62.0\n",
      "time step:  1\n",
      "episode number:  94\n",
      "reward till now:  -62.0\n",
      "time step:  2\n",
      "episode number:  94\n",
      "reward till now:  -62.0\n",
      "time step:  3\n",
      "episode number:  94\n",
      "reward till now:  -63.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 95 reward -63.00, Last 30ep Avg. rewards -63.00.\n",
      "episode number:  95\n",
      "reward till now:  -63.0\n",
      "time step:  0\n",
      "episode number:  95\n",
      "reward till now:  -63.0\n",
      "time step:  1\n",
      "episode number:  95\n",
      "reward till now:  -63.0\n",
      "time step:  2\n",
      "episode number:  95\n",
      "reward till now:  -63.0\n",
      "time step:  3\n",
      "episode number:  95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -64.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 96 reward -64.00, Last 30ep Avg. rewards -64.00.\n",
      "episode number:  96\n",
      "reward till now:  -64.0\n",
      "time step:  0\n",
      "episode number:  96\n",
      "reward till now:  -64.0\n",
      "time step:  1\n",
      "episode number:  96\n",
      "reward till now:  -64.0\n",
      "time step:  2\n",
      "episode number:  96\n",
      "reward till now:  -64.0\n",
      "time step:  3\n",
      "episode number:  96\n",
      "reward till now:  -65.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 97 reward -65.00, Last 30ep Avg. rewards -65.00.\n",
      "episode number:  97\n",
      "reward till now:  -65.0\n",
      "time step:  0\n",
      "episode number:  97\n",
      "reward till now:  -65.0\n",
      "time step:  1\n",
      "episode number:  97\n",
      "reward till now:  -65.0\n",
      "time step:  2\n",
      "episode number:  97\n",
      "reward till now:  -65.0\n",
      "time step:  3\n",
      "episode number:  97\n",
      "reward till now:  -66.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 98 reward -66.00, Last 30ep Avg. rewards -66.00.\n",
      "episode number:  98\n",
      "reward till now:  -66.0\n",
      "time step:  0\n",
      "episode number:  98\n",
      "reward till now:  -66.0\n",
      "time step:  1\n",
      "episode number:  98\n",
      "reward till now:  -66.0\n",
      "time step:  2\n",
      "episode number:  98\n",
      "reward till now:  -66.0\n",
      "time step:  3\n",
      "episode number:  98\n",
      "reward till now:  -67.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 99 reward -67.00, Last 30ep Avg. rewards -67.00.\n",
      "episode number:  99\n",
      "reward till now:  -67.0\n",
      "time step:  0\n",
      "episode number:  99\n",
      "reward till now:  -66.0\n",
      "time step:  1\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 100 reward -66.00, Last 30ep Avg. rewards -66.00.\n",
      "episode number:  100\n",
      "reward till now:  -66.0\n",
      "time step:  0\n",
      "episode number:  100\n",
      "reward till now:  -66.0\n",
      "time step:  1\n",
      "episode number:  100\n",
      "reward till now:  -66.0\n",
      "time step:  2\n",
      "episode number:  100\n",
      "reward till now:  -66.0\n",
      "time step:  3\n",
      "episode number:  100\n",
      "reward till now:  -67.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 101 reward -67.00, Last 30ep Avg. rewards -67.00.\n",
      "episode number:  101\n",
      "reward till now:  -67.0\n",
      "time step:  0\n",
      "episode number:  101\n",
      "reward till now:  -67.0\n",
      "time step:  1\n",
      "episode number:  101\n",
      "reward till now:  -67.0\n",
      "time step:  2\n",
      "episode number:  101\n",
      "reward till now:  -67.0\n",
      "time step:  3\n",
      "episode number:  101\n",
      "reward till now:  -68.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 102 reward -68.00, Last 30ep Avg. rewards -68.00.\n",
      "episode number:  102\n",
      "reward till now:  -68.0\n",
      "time step:  0\n",
      "episode number:  102\n",
      "reward till now:  -68.0\n",
      "time step:  1\n",
      "episode number:  102\n",
      "reward till now:  -68.0\n",
      "time step:  2\n",
      "episode number:  102\n",
      "reward till now:  -68.0\n",
      "time step:  3\n",
      "episode number:  102\n",
      "reward till now:  -69.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 103 reward -69.00, Last 30ep Avg. rewards -69.00.\n",
      "episode number:  103\n",
      "reward till now:  -69.0\n",
      "time step:  0\n",
      "episode number:  103\n",
      "reward till now:  -69.0\n",
      "time step:  1\n",
      "episode number:  103\n",
      "reward till now:  -69.0\n",
      "time step:  2\n",
      "episode number:  103\n",
      "reward till now:  -69.0\n",
      "time step:  3\n",
      "episode number:  103\n",
      "reward till now:  -70.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 104 reward -70.00, Last 30ep Avg. rewards -70.00.\n",
      "episode number:  104\n",
      "reward till now:  -70.0\n",
      "time step:  0\n",
      "episode number:  104\n",
      "reward till now:  -70.0\n",
      "time step:  1\n",
      "episode number:  104\n",
      "reward till now:  -70.0\n",
      "time step:  2\n",
      "episode number:  104\n",
      "reward till now:  -70.0\n",
      "time step:  3\n",
      "episode number:  104\n",
      "reward till now:  -71.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 105 reward -71.00, Last 30ep Avg. rewards -71.00.\n",
      "episode number:  105\n",
      "reward till now:  -71.0\n",
      "time step:  0\n",
      "episode number:  105\n",
      "reward till now:  -71.0\n",
      "time step:  1\n",
      "episode number:  105\n",
      "reward till now:  -71.0\n",
      "time step:  2\n",
      "episode number:  105\n",
      "reward till now:  -71.0\n",
      "time step:  3\n",
      "episode number:  105\n",
      "reward till now:  -72.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 106 reward -72.00, Last 30ep Avg. rewards -72.00.\n",
      "episode number:  106\n",
      "reward till now:  -72.0\n",
      "time step:  0\n",
      "episode number:  106\n",
      "reward till now:  -72.0\n",
      "time step:  1\n",
      "episode number:  106\n",
      "reward till now:  -72.0\n",
      "time step:  2\n",
      "episode number:  106\n",
      "reward till now:  -72.0\n",
      "time step:  3\n",
      "episode number:  106\n",
      "reward till now:  -73.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 107 reward -73.00, Last 30ep Avg. rewards -73.00.\n",
      "episode number:  107\n",
      "reward till now:  -73.0\n",
      "time step:  0\n",
      "episode number:  107\n",
      "reward till now:  -73.0\n",
      "time step:  1\n",
      "episode number:  107\n",
      "reward till now:  -73.0\n",
      "time step:  2\n",
      "episode number:  107\n",
      "reward till now:  -73.0\n",
      "time step:  3\n",
      "episode number:  107\n",
      "reward till now:  -74.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 108 reward -74.00, Last 30ep Avg. rewards -74.00.\n",
      "episode number:  108\n",
      "reward till now:  -74.0\n",
      "time step:  0\n",
      "episode number:  108\n",
      "reward till now:  -74.0\n",
      "time step:  1\n",
      "episode number:  108\n",
      "reward till now:  -74.0\n",
      "time step:  2\n",
      "episode number:  108\n",
      "reward till now:  -74.0\n",
      "time step:  3\n",
      "episode number:  108\n",
      "reward till now:  -75.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 109 reward -75.00, Last 30ep Avg. rewards -75.00.\n",
      "episode number:  109\n",
      "reward till now:  -75.0\n",
      "time step:  0\n",
      "episode number:  109\n",
      "reward till now:  -75.0\n",
      "time step:  1\n",
      "episode number:  109\n",
      "reward till now:  -75.0\n",
      "time step:  2\n",
      "episode number:  109\n",
      "reward till now:  -75.0\n",
      "time step:  3\n",
      "episode number:  109\n",
      "reward till now:  -76.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 110 reward -76.00, Last 30ep Avg. rewards -76.00.\n",
      "episode number:  110\n",
      "reward till now:  -76.0\n",
      "time step:  0\n",
      "episode number:  110\n",
      "reward till now:  -76.0\n",
      "time step:  1\n",
      "episode number:  110\n",
      "reward till now:  -76.0\n",
      "time step:  2\n",
      "episode number:  110\n",
      "reward till now:  -76.0\n",
      "time step:  3\n",
      "episode number:  110\n",
      "reward till now:  -77.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 111 reward -77.00, Last 30ep Avg. rewards -77.00.\n",
      "episode number:  111\n",
      "reward till now:  -77.0\n",
      "time step:  0\n",
      "episode number:  111\n",
      "reward till now:  -77.0\n",
      "time step:  1\n",
      "episode number:  111\n",
      "reward till now:  -77.0\n",
      "time step:  2\n",
      "episode number:  111\n",
      "reward till now:  -77.0\n",
      "time step:  3\n",
      "episode number:  111\n",
      "reward till now:  -78.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 112 reward -78.00, Last 30ep Avg. rewards -78.00.\n",
      "episode number:  112\n",
      "reward till now:  -78.0\n",
      "time step:  0\n",
      "episode number:  112\n",
      "reward till now:  -78.0\n",
      "time step:  1\n",
      "episode number:  112\n",
      "reward till now:  -78.0\n",
      "time step:  2\n",
      "episode number:  112\n",
      "reward till now:  -78.0\n",
      "time step:  3\n",
      "episode number:  112\n",
      "reward till now:  -79.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 113 reward -79.00, Last 30ep Avg. rewards -79.00.\n",
      "episode number:  113\n",
      "reward till now:  -79.0\n",
      "time step:  0\n",
      "episode number:  113\n",
      "reward till now:  -79.0\n",
      "time step:  1\n",
      "episode number:  113\n",
      "reward till now:  -79.0\n",
      "time step:  2\n",
      "episode number:  113\n",
      "reward till now:  -79.0\n",
      "time step:  3\n",
      "episode number:  113\n",
      "reward till now:  -80.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 114 reward -80.00, Last 30ep Avg. rewards -80.00.\n",
      "episode number:  114\n",
      "reward till now:  -80.0\n",
      "time step:  0\n",
      "episode number:  114\n",
      "reward till now:  -80.0\n",
      "time step:  1\n",
      "episode number:  114\n",
      "reward till now:  -80.0\n",
      "time step:  2\n",
      "episode number:  114\n",
      "reward till now:  -80.0\n",
      "time step:  3\n",
      "episode number:  114\n",
      "reward till now:  -81.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 115 reward -81.00, Last 30ep Avg. rewards -81.00.\n",
      "episode number:  115\n",
      "reward till now:  -81.0\n",
      "time step:  0\n",
      "episode number:  115\n",
      "reward till now:  -81.0\n",
      "time step:  1\n",
      "episode number:  115\n",
      "reward till now:  -81.0\n",
      "time step:  2\n",
      "episode number:  115\n",
      "reward till now:  -81.0\n",
      "time step:  3\n",
      "episode number:  115\n",
      "reward till now:  -82.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 116 reward -82.00, Last 30ep Avg. rewards -82.00.\n",
      "episode number:  116\n",
      "reward till now:  -82.0\n",
      "time step:  0\n",
      "episode number:  116\n",
      "reward till now:  -82.0\n",
      "time step:  1\n",
      "episode number:  116\n",
      "reward till now:  -82.0\n",
      "time step:  2\n",
      "episode number:  116\n",
      "reward till now:  -82.0\n",
      "time step:  3\n",
      "episode number:  116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -83.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 117 reward -83.00, Last 30ep Avg. rewards -83.00.\n",
      "episode number:  117\n",
      "reward till now:  -83.0\n",
      "time step:  0\n",
      "episode number:  117\n",
      "reward till now:  -83.0\n",
      "time step:  1\n",
      "episode number:  117\n",
      "reward till now:  -83.0\n",
      "time step:  2\n",
      "episode number:  117\n",
      "reward till now:  -83.0\n",
      "time step:  3\n",
      "episode number:  117\n",
      "reward till now:  -84.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 118 reward -84.00, Last 30ep Avg. rewards -84.00.\n",
      "episode number:  118\n",
      "reward till now:  -84.0\n",
      "time step:  0\n",
      "episode number:  118\n",
      "reward till now:  -84.0\n",
      "time step:  1\n",
      "episode number:  118\n",
      "reward till now:  -84.0\n",
      "time step:  2\n",
      "episode number:  118\n",
      "reward till now:  -84.0\n",
      "time step:  3\n",
      "episode number:  118\n",
      "reward till now:  -85.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 119 reward -85.00, Last 30ep Avg. rewards -85.00.\n",
      "episode number:  119\n",
      "reward till now:  -85.0\n",
      "time step:  0\n",
      "episode number:  119\n",
      "reward till now:  -85.0\n",
      "time step:  1\n",
      "episode number:  119\n",
      "reward till now:  -85.0\n",
      "time step:  2\n",
      "episode number:  119\n",
      "reward till now:  -85.0\n",
      "time step:  3\n",
      "episode number:  119\n",
      "reward till now:  -86.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 120 reward -86.00, Last 30ep Avg. rewards -86.00.\n",
      "episode number:  120\n",
      "reward till now:  -86.0\n",
      "time step:  0\n",
      "episode number:  120\n",
      "reward till now:  -86.0\n",
      "time step:  1\n",
      "episode number:  120\n",
      "reward till now:  -86.0\n",
      "time step:  2\n",
      "episode number:  120\n",
      "reward till now:  -86.0\n",
      "time step:  3\n",
      "episode number:  120\n",
      "reward till now:  -87.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 121 reward -87.00, Last 30ep Avg. rewards -87.00.\n",
      "episode number:  121\n",
      "reward till now:  -87.0\n",
      "time step:  0\n",
      "episode number:  121\n",
      "reward till now:  -87.0\n",
      "time step:  1\n",
      "episode number:  121\n",
      "reward till now:  -87.0\n",
      "time step:  2\n",
      "episode number:  121\n",
      "reward till now:  -87.0\n",
      "time step:  3\n",
      "episode number:  121\n",
      "reward till now:  -88.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 122 reward -88.00, Last 30ep Avg. rewards -88.00.\n",
      "episode number:  122\n",
      "reward till now:  -88.0\n",
      "time step:  0\n",
      "episode number:  122\n",
      "reward till now:  -88.0\n",
      "time step:  1\n",
      "episode number:  122\n",
      "reward till now:  -88.0\n",
      "time step:  2\n",
      "episode number:  122\n",
      "reward till now:  -88.0\n",
      "time step:  3\n",
      "episode number:  122\n",
      "reward till now:  -89.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 123 reward -89.00, Last 30ep Avg. rewards -89.00.\n",
      "episode number:  123\n",
      "reward till now:  -89.0\n",
      "time step:  0\n",
      "episode number:  123\n",
      "reward till now:  -89.0\n",
      "time step:  1\n",
      "episode number:  123\n",
      "reward till now:  -89.0\n",
      "time step:  2\n",
      "episode number:  123\n",
      "reward till now:  -89.0\n",
      "time step:  3\n",
      "episode number:  123\n",
      "reward till now:  -90.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 124 reward -90.00, Last 30ep Avg. rewards -90.00.\n",
      "episode number:  124\n",
      "reward till now:  -90.0\n",
      "time step:  0\n",
      "episode number:  124\n",
      "reward till now:  -90.0\n",
      "time step:  1\n",
      "episode number:  124\n",
      "reward till now:  -90.0\n",
      "time step:  2\n",
      "episode number:  124\n",
      "reward till now:  -90.0\n",
      "time step:  3\n",
      "episode number:  124\n",
      "reward till now:  -91.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 125 reward -91.00, Last 30ep Avg. rewards -91.00.\n",
      "episode number:  125\n",
      "reward till now:  -91.0\n",
      "time step:  0\n",
      "episode number:  125\n",
      "reward till now:  -91.0\n",
      "time step:  1\n",
      "episode number:  125\n",
      "reward till now:  -91.0\n",
      "time step:  2\n",
      "episode number:  125\n",
      "reward till now:  -90.0\n",
      "time step:  3\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 126 reward -90.00, Last 30ep Avg. rewards -90.00.\n",
      "episode number:  126\n",
      "reward till now:  -90.0\n",
      "time step:  0\n",
      "episode number:  126\n",
      "reward till now:  -90.0\n",
      "time step:  1\n",
      "episode number:  126\n",
      "reward till now:  -90.0\n",
      "time step:  2\n",
      "episode number:  126\n",
      "reward till now:  -90.0\n",
      "time step:  3\n",
      "episode number:  126\n",
      "reward till now:  -91.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 127 reward -91.00, Last 30ep Avg. rewards -91.00.\n",
      "episode number:  127\n",
      "reward till now:  -91.0\n",
      "time step:  0\n",
      "episode number:  127\n",
      "reward till now:  -91.0\n",
      "time step:  1\n",
      "episode number:  127\n",
      "reward till now:  -91.0\n",
      "time step:  2\n",
      "episode number:  127\n",
      "reward till now:  -91.0\n",
      "time step:  3\n",
      "episode number:  127\n",
      "reward till now:  -92.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 128 reward -92.00, Last 30ep Avg. rewards -92.00.\n",
      "episode number:  128\n",
      "reward till now:  -92.0\n",
      "time step:  0\n",
      "episode number:  128\n",
      "reward till now:  -92.0\n",
      "time step:  1\n",
      "episode number:  128\n",
      "reward till now:  -92.0\n",
      "time step:  2\n",
      "episode number:  128\n",
      "reward till now:  -92.0\n",
      "time step:  3\n",
      "episode number:  128\n",
      "reward till now:  -93.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 129 reward -93.00, Last 30ep Avg. rewards -93.00.\n",
      "episode number:  129\n",
      "reward till now:  -93.0\n",
      "time step:  0\n",
      "episode number:  129\n",
      "reward till now:  -93.0\n",
      "time step:  1\n",
      "episode number:  129\n",
      "reward till now:  -93.0\n",
      "time step:  2\n",
      "episode number:  129\n",
      "reward till now:  -93.0\n",
      "time step:  3\n",
      "episode number:  129\n",
      "reward till now:  -94.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 130 reward -94.00, Last 30ep Avg. rewards -94.00.\n",
      "episode number:  130\n",
      "reward till now:  -94.0\n",
      "time step:  0\n",
      "episode number:  130\n",
      "reward till now:  -94.0\n",
      "time step:  1\n",
      "episode number:  130\n",
      "reward till now:  -94.0\n",
      "time step:  2\n",
      "episode number:  130\n",
      "reward till now:  -93.0\n",
      "time step:  3\n",
      "in discounted reward\n",
      "disc_rw:  [[0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]]\n",
      "Episode 131 reward -93.00, Last 30ep Avg. rewards -93.00.\n",
      "episode number:  131\n",
      "reward till now:  -92.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 132 reward -92.00, Last 30ep Avg. rewards -92.00.\n",
      "episode number:  132\n",
      "reward till now:  -91.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 133 reward -91.00, Last 30ep Avg. rewards -91.00.\n",
      "episode number:  133\n",
      "reward till now:  -90.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 134 reward -90.00, Last 30ep Avg. rewards -90.00.\n",
      "episode number:  134\n",
      "reward till now:  -89.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 135 reward -89.00, Last 30ep Avg. rewards -89.00.\n",
      "episode number:  135\n",
      "reward till now:  -88.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 136 reward -88.00, Last 30ep Avg. rewards -88.00.\n",
      "episode number:  136\n",
      "reward till now:  -88.0\n",
      "time step:  0\n",
      "episode number:  136\n",
      "reward till now:  -88.0\n",
      "time step:  1\n",
      "episode number:  136\n",
      "reward till now:  -88.0\n",
      "time step:  2\n",
      "episode number:  136\n",
      "reward till now:  -88.0\n",
      "time step:  3\n",
      "episode number:  136\n",
      "reward till now:  -89.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 137 reward -89.00, Last 30ep Avg. rewards -89.00.\n",
      "episode number:  137\n",
      "reward till now:  -89.0\n",
      "time step:  0\n",
      "episode number:  137\n",
      "reward till now:  -89.0\n",
      "time step:  1\n",
      "episode number:  137\n",
      "reward till now:  -89.0\n",
      "time step:  2\n",
      "episode number:  137\n",
      "reward till now:  -89.0\n",
      "time step:  3\n",
      "episode number:  137\n",
      "reward till now:  -90.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 138 reward -90.00, Last 30ep Avg. rewards -90.00.\n",
      "episode number:  138\n",
      "reward till now:  -90.0\n",
      "time step:  0\n",
      "episode number:  138\n",
      "reward till now:  -90.0\n",
      "time step:  1\n",
      "episode number:  138\n",
      "reward till now:  -90.0\n",
      "time step:  2\n",
      "episode number:  138\n",
      "reward till now:  -90.0\n",
      "time step:  3\n",
      "episode number:  138\n",
      "reward till now:  -91.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 139 reward -91.00, Last 30ep Avg. rewards -91.00.\n",
      "episode number:  139\n",
      "reward till now:  -91.0\n",
      "time step:  0\n",
      "episode number:  139\n",
      "reward till now:  -91.0\n",
      "time step:  1\n",
      "episode number:  139\n",
      "reward till now:  -91.0\n",
      "time step:  2\n",
      "episode number:  139\n",
      "reward till now:  -91.0\n",
      "time step:  3\n",
      "episode number:  139\n",
      "reward till now:  -92.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 0.857375  ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 140 reward -92.00, Last 30ep Avg. rewards -92.00.\n",
      "episode number:  140\n",
      "reward till now:  -92.0\n",
      "time step:  0\n",
      "episode number:  140\n",
      "reward till now:  -92.0\n",
      "time step:  1\n",
      "episode number:  140\n",
      "reward till now:  -91.0\n",
      "time step:  2\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025]\n",
      " [0.95  ]\n",
      " [1.    ]]\n",
      "Episode 141 reward -91.00, Last 30ep Avg. rewards -91.00.\n",
      "episode number:  141\n",
      "reward till now:  -90.0\n",
      "time step:  0\n",
      "in discounted reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc_rw:  [[0.9025]\n",
      " [0.95  ]\n",
      " [1.    ]\n",
      " [1.    ]]\n",
      "Episode 142 reward -90.00, Last 30ep Avg. rewards -90.00.\n",
      "episode number:  142\n",
      "reward till now:  -89.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025]\n",
      " [0.95  ]\n",
      " [1.    ]\n",
      " [1.    ]\n",
      " [1.    ]]\n",
      "Episode 143 reward -89.00, Last 30ep Avg. rewards -89.00.\n",
      "episode number:  143\n",
      "reward till now:  -88.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025]\n",
      " [0.95  ]\n",
      " [1.    ]\n",
      " [1.    ]\n",
      " [1.    ]\n",
      " [1.    ]]\n",
      "Episode 144 reward -88.00, Last 30ep Avg. rewards -88.00.\n",
      "episode number:  144\n",
      "reward till now:  -88.0\n",
      "time step:  0\n",
      "episode number:  144\n",
      "reward till now:  -88.0\n",
      "time step:  1\n",
      "episode number:  144\n",
      "reward till now:  -88.0\n",
      "time step:  2\n",
      "episode number:  144\n",
      "reward till now:  -88.0\n",
      "time step:  3\n",
      "episode number:  144\n",
      "reward till now:  -89.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 145 reward -89.00, Last 30ep Avg. rewards -89.00.\n",
      "episode number:  145\n",
      "reward till now:  -89.0\n",
      "time step:  0\n",
      "episode number:  145\n",
      "reward till now:  -89.0\n",
      "time step:  1\n",
      "episode number:  145\n",
      "reward till now:  -88.0\n",
      "time step:  2\n",
      "in discounted reward\n",
      "disc_rw:  [[ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 146 reward -88.00, Last 30ep Avg. rewards -88.00.\n",
      "episode number:  146\n",
      "reward till now:  -87.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 147 reward -87.00, Last 30ep Avg. rewards -87.00.\n",
      "episode number:  147\n",
      "reward till now:  -86.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 148 reward -86.00, Last 30ep Avg. rewards -86.00.\n",
      "episode number:  148\n",
      "reward till now:  -85.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 149 reward -85.00, Last 30ep Avg. rewards -85.00.\n",
      "episode number:  149\n",
      "reward till now:  -84.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 150 reward -84.00, Last 30ep Avg. rewards -84.00.\n",
      "episode number:  150\n",
      "reward till now:  -83.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 151 reward -83.00, Last 30ep Avg. rewards -83.00.\n",
      "episode number:  151\n",
      "reward till now:  -82.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 152 reward -82.00, Last 30ep Avg. rewards -82.00.\n",
      "episode number:  152\n",
      "reward till now:  -82.0\n",
      "time step:  0\n",
      "episode number:  152\n",
      "reward till now:  -82.0\n",
      "time step:  1\n",
      "episode number:  152\n",
      "reward till now:  -82.0\n",
      "time step:  2\n",
      "episode number:  152\n",
      "reward till now:  -82.0\n",
      "time step:  3\n",
      "episode number:  152\n",
      "reward till now:  -83.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 153 reward -83.00, Last 30ep Avg. rewards -83.00.\n",
      "episode number:  153\n",
      "reward till now:  -83.0\n",
      "time step:  0\n",
      "episode number:  153\n",
      "reward till now:  -83.0\n",
      "time step:  1\n",
      "episode number:  153\n",
      "reward till now:  -83.0\n",
      "time step:  2\n",
      "episode number:  153\n",
      "reward till now:  -83.0\n",
      "time step:  3\n",
      "episode number:  153\n",
      "reward till now:  -84.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 154 reward -84.00, Last 30ep Avg. rewards -84.00.\n",
      "episode number:  154\n",
      "reward till now:  -84.0\n",
      "time step:  0\n",
      "episode number:  154\n",
      "reward till now:  -84.0\n",
      "time step:  1\n",
      "episode number:  154\n",
      "reward till now:  -84.0\n",
      "time step:  2\n",
      "episode number:  154\n",
      "reward till now:  -84.0\n",
      "time step:  3\n",
      "episode number:  154\n",
      "reward till now:  -85.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 155 reward -85.00, Last 30ep Avg. rewards -85.00.\n",
      "episode number:  155\n",
      "reward till now:  -85.0\n",
      "time step:  0\n",
      "episode number:  155\n",
      "reward till now:  -85.0\n",
      "time step:  1\n",
      "episode number:  155\n",
      "reward till now:  -85.0\n",
      "time step:  2\n",
      "episode number:  155\n",
      "reward till now:  -85.0\n",
      "time step:  3\n",
      "episode number:  155\n",
      "reward till now:  -86.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 156 reward -86.00, Last 30ep Avg. rewards -86.00.\n",
      "episode number:  156\n",
      "reward till now:  -86.0\n",
      "time step:  0\n",
      "episode number:  156\n",
      "reward till now:  -86.0\n",
      "time step:  1\n",
      "episode number:  156\n",
      "reward till now:  -86.0\n",
      "time step:  2\n",
      "episode number:  156\n",
      "reward till now:  -86.0\n",
      "time step:  3\n",
      "episode number:  156\n",
      "reward till now:  -87.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 157 reward -87.00, Last 30ep Avg. rewards -87.00.\n",
      "episode number:  157\n",
      "reward till now:  -87.0\n",
      "time step:  0\n",
      "episode number:  157\n",
      "reward till now:  -87.0\n",
      "time step:  1\n",
      "episode number:  157\n",
      "reward till now:  -87.0\n",
      "time step:  2\n",
      "episode number:  157\n",
      "reward till now:  -87.0\n",
      "time step:  3\n",
      "episode number:  157\n",
      "reward till now:  -88.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 158 reward -88.00, Last 30ep Avg. rewards -88.00.\n",
      "episode number:  158\n",
      "reward till now:  -88.0\n",
      "time step:  0\n",
      "episode number:  158\n",
      "reward till now:  -88.0\n",
      "time step:  1\n",
      "episode number:  158\n",
      "reward till now:  -88.0\n",
      "time step:  2\n",
      "episode number:  158\n",
      "reward till now:  -88.0\n",
      "time step:  3\n",
      "episode number:  158\n",
      "reward till now:  -89.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 159 reward -89.00, Last 30ep Avg. rewards -89.00.\n",
      "episode number:  159\n",
      "reward till now:  -89.0\n",
      "time step:  0\n",
      "episode number:  159\n",
      "reward till now:  -89.0\n",
      "time step:  1\n",
      "episode number:  159\n",
      "reward till now:  -89.0\n",
      "time step:  2\n",
      "episode number:  159\n",
      "reward till now:  -89.0\n",
      "time step:  3\n",
      "episode number:  159\n",
      "reward till now:  -90.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 160 reward -90.00, Last 30ep Avg. rewards -90.00.\n",
      "episode number:  160\n",
      "reward till now:  -90.0\n",
      "time step:  0\n",
      "episode number:  160\n",
      "reward till now:  -90.0\n",
      "time step:  1\n",
      "episode number:  160\n",
      "reward till now:  -90.0\n",
      "time step:  2\n",
      "episode number:  160\n",
      "reward till now:  -90.0\n",
      "time step:  3\n",
      "episode number:  160\n",
      "reward till now:  -91.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 161 reward -91.00, Last 30ep Avg. rewards -91.00.\n",
      "episode number:  161\n",
      "reward till now:  -91.0\n",
      "time step:  0\n",
      "episode number:  161\n",
      "reward till now:  -91.0\n",
      "time step:  1\n",
      "episode number:  161\n",
      "reward till now:  -91.0\n",
      "time step:  2\n",
      "episode number:  161\n",
      "reward till now:  -91.0\n",
      "time step:  3\n",
      "episode number:  161\n",
      "reward till now:  -92.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 162 reward -92.00, Last 30ep Avg. rewards -92.00.\n",
      "episode number:  162\n",
      "reward till now:  -92.0\n",
      "time step:  0\n",
      "episode number:  162\n",
      "reward till now:  -92.0\n",
      "time step:  1\n",
      "episode number:  162\n",
      "reward till now:  -92.0\n",
      "time step:  2\n",
      "episode number:  162\n",
      "reward till now:  -92.0\n",
      "time step:  3\n",
      "episode number:  162\n",
      "reward till now:  -93.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 163 reward -93.00, Last 30ep Avg. rewards -93.00.\n",
      "episode number:  163\n",
      "reward till now:  -93.0\n",
      "time step:  0\n",
      "episode number:  163\n",
      "reward till now:  -93.0\n",
      "time step:  1\n",
      "episode number:  163\n",
      "reward till now:  -93.0\n",
      "time step:  2\n",
      "episode number:  163\n",
      "reward till now:  -93.0\n",
      "time step:  3\n",
      "episode number:  163\n",
      "reward till now:  -94.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 164 reward -94.00, Last 30ep Avg. rewards -94.00.\n",
      "episode number:  164\n",
      "reward till now:  -94.0\n",
      "time step:  0\n",
      "episode number:  164\n",
      "reward till now:  -94.0\n",
      "time step:  1\n",
      "episode number:  164\n",
      "reward till now:  -94.0\n",
      "time step:  2\n",
      "episode number:  164\n",
      "reward till now:  -94.0\n",
      "time step:  3\n",
      "episode number:  164\n",
      "reward till now:  -95.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 165 reward -95.00, Last 30ep Avg. rewards -95.00.\n",
      "episode number:  165\n",
      "reward till now:  -95.0\n",
      "time step:  0\n",
      "episode number:  165\n",
      "reward till now:  -95.0\n",
      "time step:  1\n",
      "episode number:  165\n",
      "reward till now:  -95.0\n",
      "time step:  2\n",
      "episode number:  165\n",
      "reward till now:  -95.0\n",
      "time step:  3\n",
      "episode number:  165\n",
      "reward till now:  -96.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 166 reward -96.00, Last 30ep Avg. rewards -96.00.\n",
      "episode number:  166\n",
      "reward till now:  -96.0\n",
      "time step:  0\n",
      "episode number:  166\n",
      "reward till now:  -96.0\n",
      "time step:  1\n",
      "episode number:  166\n",
      "reward till now:  -96.0\n",
      "time step:  2\n",
      "episode number:  166\n",
      "reward till now:  -96.0\n",
      "time step:  3\n",
      "episode number:  166\n",
      "reward till now:  -97.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 167 reward -97.00, Last 30ep Avg. rewards -97.00.\n",
      "episode number:  167\n",
      "reward till now:  -97.0\n",
      "time step:  0\n",
      "episode number:  167\n",
      "reward till now:  -97.0\n",
      "time step:  1\n",
      "episode number:  167\n",
      "reward till now:  -97.0\n",
      "time step:  2\n",
      "episode number:  167\n",
      "reward till now:  -97.0\n",
      "time step:  3\n",
      "episode number:  167\n",
      "reward till now:  -98.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 168 reward -98.00, Last 30ep Avg. rewards -98.00.\n",
      "episode number:  168\n",
      "reward till now:  -98.0\n",
      "time step:  0\n",
      "episode number:  168\n",
      "reward till now:  -98.0\n",
      "time step:  1\n",
      "episode number:  168\n",
      "reward till now:  -98.0\n",
      "time step:  2\n",
      "episode number:  168\n",
      "reward till now:  -98.0\n",
      "time step:  3\n",
      "episode number:  168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -99.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 169 reward -99.00, Last 30ep Avg. rewards -99.00.\n",
      "episode number:  169\n",
      "reward till now:  -99.0\n",
      "time step:  0\n",
      "episode number:  169\n",
      "reward till now:  -99.0\n",
      "time step:  1\n",
      "episode number:  169\n",
      "reward till now:  -99.0\n",
      "time step:  2\n",
      "episode number:  169\n",
      "reward till now:  -99.0\n",
      "time step:  3\n",
      "episode number:  169\n",
      "reward till now:  -100.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 170 reward -100.00, Last 30ep Avg. rewards -100.00.\n",
      "episode number:  170\n",
      "reward till now:  -100.0\n",
      "time step:  0\n",
      "episode number:  170\n",
      "reward till now:  -100.0\n",
      "time step:  1\n",
      "episode number:  170\n",
      "reward till now:  -99.0\n",
      "time step:  2\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025]\n",
      " [0.95  ]\n",
      " [1.    ]]\n",
      "Episode 171 reward -99.00, Last 30ep Avg. rewards -99.00.\n",
      "episode number:  171\n",
      "reward till now:  -98.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025]\n",
      " [0.95  ]\n",
      " [1.    ]\n",
      " [1.    ]]\n",
      "Episode 172 reward -98.00, Last 30ep Avg. rewards -98.00.\n",
      "episode number:  172\n",
      "reward till now:  -97.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025]\n",
      " [0.95  ]\n",
      " [1.    ]\n",
      " [1.    ]\n",
      " [1.    ]]\n",
      "Episode 173 reward -97.00, Last 30ep Avg. rewards -97.00.\n",
      "episode number:  173\n",
      "reward till now:  -97.0\n",
      "time step:  0\n",
      "episode number:  173\n",
      "reward till now:  -97.0\n",
      "time step:  1\n",
      "episode number:  173\n",
      "reward till now:  -97.0\n",
      "time step:  2\n",
      "episode number:  173\n",
      "reward till now:  -96.0\n",
      "time step:  3\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]]\n",
      "Episode 174 reward -96.00, Last 30ep Avg. rewards -96.00.\n",
      "episode number:  174\n",
      "reward till now:  -95.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 175 reward -95.00, Last 30ep Avg. rewards -95.00.\n",
      "episode number:  175\n",
      "reward till now:  -94.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 176 reward -94.00, Last 30ep Avg. rewards -94.00.\n",
      "episode number:  176\n",
      "reward till now:  -93.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 177 reward -93.00, Last 30ep Avg. rewards -93.00.\n",
      "episode number:  177\n",
      "reward till now:  -92.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 178 reward -92.00, Last 30ep Avg. rewards -92.00.\n",
      "episode number:  178\n",
      "reward till now:  -91.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 179 reward -91.00, Last 30ep Avg. rewards -91.00.\n",
      "episode number:  179\n",
      "reward till now:  -90.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [0.857375]\n",
      " [0.9025  ]\n",
      " [0.95    ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]\n",
      " [1.      ]]\n",
      "Episode 180 reward -90.00, Last 30ep Avg. rewards -90.00.\n",
      "episode number:  180\n",
      "reward till now:  -89.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 181 reward -89.00, Last 30ep Avg. rewards -89.00.\n",
      "episode number:  181\n",
      "reward till now:  -88.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 182 reward -88.00, Last 30ep Avg. rewards -88.00.\n",
      "episode number:  182\n",
      "reward till now:  -87.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 183 reward -87.00, Last 30ep Avg. rewards -87.00.\n",
      "episode number:  183\n",
      "reward till now:  -86.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 184 reward -86.00, Last 30ep Avg. rewards -86.00.\n",
      "episode number:  184\n",
      "reward till now:  -85.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 185 reward -85.00, Last 30ep Avg. rewards -85.00.\n",
      "episode number:  185\n",
      "reward till now:  -84.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 186 reward -84.00, Last 30ep Avg. rewards -84.00.\n",
      "episode number:  186\n",
      "reward till now:  -83.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 187 reward -83.00, Last 30ep Avg. rewards -83.00.\n",
      "episode number:  187\n",
      "reward till now:  -82.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 188 reward -82.00, Last 30ep Avg. rewards -82.00.\n",
      "episode number:  188\n",
      "reward till now:  -81.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 189 reward -81.00, Last 30ep Avg. rewards -81.00.\n",
      "episode number:  189\n",
      "reward till now:  -80.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 190 reward -80.00, Last 30ep Avg. rewards -80.00.\n",
      "episode number:  190\n",
      "reward till now:  -79.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 191 reward -79.00, Last 30ep Avg. rewards -79.00.\n",
      "episode number:  191\n",
      "reward till now:  -78.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 192 reward -78.00, Last 30ep Avg. rewards -78.00.\n",
      "episode number:  192\n",
      "reward till now:  -77.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 193 reward -77.00, Last 30ep Avg. rewards -77.00.\n",
      "episode number:  193\n",
      "reward till now:  -76.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 194 reward -76.00, Last 30ep Avg. rewards -76.00.\n",
      "episode number:  194\n",
      "reward till now:  -75.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 195 reward -75.00, Last 30ep Avg. rewards -75.00.\n",
      "episode number:  195\n",
      "reward till now:  -74.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 196 reward -74.00, Last 30ep Avg. rewards -74.00.\n",
      "episode number:  196\n",
      "reward till now:  -73.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 197 reward -73.00, Last 30ep Avg. rewards -73.00.\n",
      "episode number:  197\n",
      "reward till now:  -72.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 198 reward -72.00, Last 30ep Avg. rewards -72.00.\n",
      "episode number:  198\n",
      "reward till now:  -71.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 199 reward -71.00, Last 30ep Avg. rewards -71.00.\n",
      "episode number:  199\n",
      "reward till now:  -70.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 200 reward -70.00, Last 30ep Avg. rewards -70.00.\n",
      "episode number:  200\n",
      "reward till now:  -69.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 201 reward -69.00, Last 30ep Avg. rewards -69.00.\n",
      "episode number:  201\n",
      "reward till now:  -68.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 202 reward -68.00, Last 30ep Avg. rewards -68.00.\n",
      "episode number:  202\n",
      "reward till now:  -67.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 203 reward -67.00, Last 30ep Avg. rewards -67.00.\n",
      "episode number:  203\n",
      "reward till now:  -66.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 204 reward -66.00, Last 30ep Avg. rewards -66.00.\n",
      "episode number:  204\n",
      "reward till now:  -65.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 205 reward -65.00, Last 30ep Avg. rewards -65.00.\n",
      "episode number:  205\n",
      "reward till now:  -64.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 206 reward -64.00, Last 30ep Avg. rewards -64.00.\n",
      "episode number:  206\n",
      "reward till now:  -63.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 207 reward -63.00, Last 30ep Avg. rewards -63.00.\n",
      "episode number:  207\n",
      "reward till now:  -62.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 208 reward -62.00, Last 30ep Avg. rewards -62.00.\n",
      "episode number:  208\n",
      "reward till now:  -61.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 209 reward -61.00, Last 30ep Avg. rewards -61.00.\n",
      "episode number:  209\n",
      "reward till now:  -60.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 210 reward -60.00, Last 30ep Avg. rewards -60.00.\n",
      "episode number:  210\n",
      "reward till now:  -59.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 211 reward -59.00, Last 30ep Avg. rewards -59.00.\n",
      "episode number:  211\n",
      "reward till now:  -58.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 212 reward -58.00, Last 30ep Avg. rewards -58.00.\n",
      "episode number:  212\n",
      "reward till now:  -57.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 213 reward -57.00, Last 30ep Avg. rewards -57.00.\n",
      "episode number:  213\n",
      "reward till now:  -57.0\n",
      "time step:  0\n",
      "episode number:  213\n",
      "reward till now:  -57.0\n",
      "time step:  1\n",
      "episode number:  213\n",
      "reward till now:  -57.0\n",
      "time step:  2\n",
      "episode number:  213\n",
      "reward till now:  -57.0\n",
      "time step:  3\n",
      "episode number:  213\n",
      "reward till now:  -58.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 214 reward -58.00, Last 30ep Avg. rewards -58.00.\n",
      "episode number:  214\n",
      "reward till now:  -58.0\n",
      "time step:  0\n",
      "episode number:  214\n",
      "reward till now:  -58.0\n",
      "time step:  1\n",
      "episode number:  214\n",
      "reward till now:  -58.0\n",
      "time step:  2\n",
      "episode number:  214\n",
      "reward till now:  -58.0\n",
      "time step:  3\n",
      "episode number:  214\n",
      "reward till now:  -59.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 215 reward -59.00, Last 30ep Avg. rewards -59.00.\n",
      "episode number:  215\n",
      "reward till now:  -59.0\n",
      "time step:  0\n",
      "episode number:  215\n",
      "reward till now:  -59.0\n",
      "time step:  1\n",
      "episode number:  215\n",
      "reward till now:  -59.0\n",
      "time step:  2\n",
      "episode number:  215\n",
      "reward till now:  -59.0\n",
      "time step:  3\n",
      "episode number:  215\n",
      "reward till now:  -60.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 216 reward -60.00, Last 30ep Avg. rewards -60.00.\n",
      "episode number:  216\n",
      "reward till now:  -60.0\n",
      "time step:  0\n",
      "episode number:  216\n",
      "reward till now:  -60.0\n",
      "time step:  1\n",
      "episode number:  216\n",
      "reward till now:  -60.0\n",
      "time step:  2\n",
      "episode number:  216\n",
      "reward till now:  -60.0\n",
      "time step:  3\n",
      "episode number:  216\n",
      "reward till now:  -61.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 217 reward -61.00, Last 30ep Avg. rewards -61.00.\n",
      "episode number:  217\n",
      "reward till now:  -61.0\n",
      "time step:  0\n",
      "episode number:  217\n",
      "reward till now:  -61.0\n",
      "time step:  1\n",
      "episode number:  217\n",
      "reward till now:  -61.0\n",
      "time step:  2\n",
      "episode number:  217\n",
      "reward till now:  -61.0\n",
      "time step:  3\n",
      "episode number:  217\n",
      "reward till now:  -62.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 218 reward -62.00, Last 30ep Avg. rewards -62.00.\n",
      "episode number:  218\n",
      "reward till now:  -62.0\n",
      "time step:  0\n",
      "episode number:  218\n",
      "reward till now:  -62.0\n",
      "time step:  1\n",
      "episode number:  218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -62.0\n",
      "time step:  2\n",
      "episode number:  218\n",
      "reward till now:  -62.0\n",
      "time step:  3\n",
      "episode number:  218\n",
      "reward till now:  -63.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 219 reward -63.00, Last 30ep Avg. rewards -63.00.\n",
      "episode number:  219\n",
      "reward till now:  -63.0\n",
      "time step:  0\n",
      "episode number:  219\n",
      "reward till now:  -63.0\n",
      "time step:  1\n",
      "episode number:  219\n",
      "reward till now:  -63.0\n",
      "time step:  2\n",
      "episode number:  219\n",
      "reward till now:  -63.0\n",
      "time step:  3\n",
      "episode number:  219\n",
      "reward till now:  -64.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 220 reward -64.00, Last 30ep Avg. rewards -64.00.\n",
      "episode number:  220\n",
      "reward till now:  -64.0\n",
      "time step:  0\n",
      "episode number:  220\n",
      "reward till now:  -64.0\n",
      "time step:  1\n",
      "episode number:  220\n",
      "reward till now:  -64.0\n",
      "time step:  2\n",
      "episode number:  220\n",
      "reward till now:  -64.0\n",
      "time step:  3\n",
      "episode number:  220\n",
      "reward till now:  -65.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 221 reward -65.00, Last 30ep Avg. rewards -65.00.\n",
      "episode number:  221\n",
      "reward till now:  -65.0\n",
      "time step:  0\n",
      "episode number:  221\n",
      "reward till now:  -65.0\n",
      "time step:  1\n",
      "episode number:  221\n",
      "reward till now:  -65.0\n",
      "time step:  2\n",
      "episode number:  221\n",
      "reward till now:  -65.0\n",
      "time step:  3\n",
      "episode number:  221\n",
      "reward till now:  -66.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 222 reward -66.00, Last 30ep Avg. rewards -66.00.\n",
      "episode number:  222\n",
      "reward till now:  -66.0\n",
      "time step:  0\n",
      "episode number:  222\n",
      "reward till now:  -66.0\n",
      "time step:  1\n",
      "episode number:  222\n",
      "reward till now:  -66.0\n",
      "time step:  2\n",
      "episode number:  222\n",
      "reward till now:  -66.0\n",
      "time step:  3\n",
      "episode number:  222\n",
      "reward till now:  -67.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 223 reward -67.00, Last 30ep Avg. rewards -67.00.\n",
      "episode number:  223\n",
      "reward till now:  -67.0\n",
      "time step:  0\n",
      "episode number:  223\n",
      "reward till now:  -67.0\n",
      "time step:  1\n",
      "episode number:  223\n",
      "reward till now:  -67.0\n",
      "time step:  2\n",
      "episode number:  223\n",
      "reward till now:  -67.0\n",
      "time step:  3\n",
      "episode number:  223\n",
      "reward till now:  -68.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 224 reward -68.00, Last 30ep Avg. rewards -68.00.\n",
      "episode number:  224\n",
      "reward till now:  -68.0\n",
      "time step:  0\n",
      "episode number:  224\n",
      "reward till now:  -68.0\n",
      "time step:  1\n",
      "episode number:  224\n",
      "reward till now:  -68.0\n",
      "time step:  2\n",
      "episode number:  224\n",
      "reward till now:  -68.0\n",
      "time step:  3\n",
      "episode number:  224\n",
      "reward till now:  -69.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 225 reward -69.00, Last 30ep Avg. rewards -69.00.\n",
      "episode number:  225\n",
      "reward till now:  -69.0\n",
      "time step:  0\n",
      "episode number:  225\n",
      "reward till now:  -69.0\n",
      "time step:  1\n",
      "episode number:  225\n",
      "reward till now:  -69.0\n",
      "time step:  2\n",
      "episode number:  225\n",
      "reward till now:  -69.0\n",
      "time step:  3\n",
      "episode number:  225\n",
      "reward till now:  -70.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 226 reward -70.00, Last 30ep Avg. rewards -70.00.\n",
      "episode number:  226\n",
      "reward till now:  -70.0\n",
      "time step:  0\n",
      "episode number:  226\n",
      "reward till now:  -70.0\n",
      "time step:  1\n",
      "episode number:  226\n",
      "reward till now:  -70.0\n",
      "time step:  2\n",
      "episode number:  226\n",
      "reward till now:  -70.0\n",
      "time step:  3\n",
      "episode number:  226\n",
      "reward till now:  -71.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 227 reward -71.00, Last 30ep Avg. rewards -71.00.\n",
      "episode number:  227\n",
      "reward till now:  -71.0\n",
      "time step:  0\n",
      "episode number:  227\n",
      "reward till now:  -71.0\n",
      "time step:  1\n",
      "episode number:  227\n",
      "reward till now:  -71.0\n",
      "time step:  2\n",
      "episode number:  227\n",
      "reward till now:  -71.0\n",
      "time step:  3\n",
      "episode number:  227\n",
      "reward till now:  -72.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 228 reward -72.00, Last 30ep Avg. rewards -72.00.\n",
      "episode number:  228\n",
      "reward till now:  -72.0\n",
      "time step:  0\n",
      "episode number:  228\n",
      "reward till now:  -72.0\n",
      "time step:  1\n",
      "episode number:  228\n",
      "reward till now:  -72.0\n",
      "time step:  2\n",
      "episode number:  228\n",
      "reward till now:  -72.0\n",
      "time step:  3\n",
      "episode number:  228\n",
      "reward till now:  -73.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 229 reward -73.00, Last 30ep Avg. rewards -73.00.\n",
      "episode number:  229\n",
      "reward till now:  -73.0\n",
      "time step:  0\n",
      "episode number:  229\n",
      "reward till now:  -73.0\n",
      "time step:  1\n",
      "episode number:  229\n",
      "reward till now:  -73.0\n",
      "time step:  2\n",
      "episode number:  229\n",
      "reward till now:  -73.0\n",
      "time step:  3\n",
      "episode number:  229\n",
      "reward till now:  -74.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 230 reward -74.00, Last 30ep Avg. rewards -74.00.\n",
      "episode number:  230\n",
      "reward till now:  -74.0\n",
      "time step:  0\n",
      "episode number:  230\n",
      "reward till now:  -74.0\n",
      "time step:  1\n",
      "episode number:  230\n",
      "reward till now:  -74.0\n",
      "time step:  2\n",
      "episode number:  230\n",
      "reward till now:  -74.0\n",
      "time step:  3\n",
      "episode number:  230\n",
      "reward till now:  -75.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 231 reward -75.00, Last 30ep Avg. rewards -75.00.\n",
      "episode number:  231\n",
      "reward till now:  -75.0\n",
      "time step:  0\n",
      "episode number:  231\n",
      "reward till now:  -75.0\n",
      "time step:  1\n",
      "episode number:  231\n",
      "reward till now:  -75.0\n",
      "time step:  2\n",
      "episode number:  231\n",
      "reward till now:  -75.0\n",
      "time step:  3\n",
      "episode number:  231\n",
      "reward till now:  -76.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 232 reward -76.00, Last 30ep Avg. rewards -76.00.\n",
      "episode number:  232\n",
      "reward till now:  -76.0\n",
      "time step:  0\n",
      "episode number:  232\n",
      "reward till now:  -76.0\n",
      "time step:  1\n",
      "episode number:  232\n",
      "reward till now:  -76.0\n",
      "time step:  2\n",
      "episode number:  232\n",
      "reward till now:  -76.0\n",
      "time step:  3\n",
      "episode number:  232\n",
      "reward till now:  -77.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 233 reward -77.00, Last 30ep Avg. rewards -77.00.\n",
      "episode number:  233\n",
      "reward till now:  -77.0\n",
      "time step:  0\n",
      "episode number:  233\n",
      "reward till now:  -77.0\n",
      "time step:  1\n",
      "episode number:  233\n",
      "reward till now:  -77.0\n",
      "time step:  2\n",
      "episode number:  233\n",
      "reward till now:  -77.0\n",
      "time step:  3\n",
      "episode number:  233\n",
      "reward till now:  -78.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 234 reward -78.00, Last 30ep Avg. rewards -78.00.\n",
      "episode number:  234\n",
      "reward till now:  -78.0\n",
      "time step:  0\n",
      "episode number:  234\n",
      "reward till now:  -78.0\n",
      "time step:  1\n",
      "episode number:  234\n",
      "reward till now:  -78.0\n",
      "time step:  2\n",
      "episode number:  234\n",
      "reward till now:  -78.0\n",
      "time step:  3\n",
      "episode number:  234\n",
      "reward till now:  -79.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 235 reward -79.00, Last 30ep Avg. rewards -79.00.\n",
      "episode number:  235\n",
      "reward till now:  -79.0\n",
      "time step:  0\n",
      "episode number:  235\n",
      "reward till now:  -79.0\n",
      "time step:  1\n",
      "episode number:  235\n",
      "reward till now:  -79.0\n",
      "time step:  2\n",
      "episode number:  235\n",
      "reward till now:  -79.0\n",
      "time step:  3\n",
      "episode number:  235\n",
      "reward till now:  -80.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 236 reward -80.00, Last 30ep Avg. rewards -80.00.\n",
      "episode number:  236\n",
      "reward till now:  -80.0\n",
      "time step:  0\n",
      "episode number:  236\n",
      "reward till now:  -80.0\n",
      "time step:  1\n",
      "episode number:  236\n",
      "reward till now:  -80.0\n",
      "time step:  2\n",
      "episode number:  236\n",
      "reward till now:  -80.0\n",
      "time step:  3\n",
      "episode number:  236\n",
      "reward till now:  -81.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 237 reward -81.00, Last 30ep Avg. rewards -81.00.\n",
      "episode number:  237\n",
      "reward till now:  -81.0\n",
      "time step:  0\n",
      "episode number:  237\n",
      "reward till now:  -81.0\n",
      "time step:  1\n",
      "episode number:  237\n",
      "reward till now:  -81.0\n",
      "time step:  2\n",
      "episode number:  237\n",
      "reward till now:  -81.0\n",
      "time step:  3\n",
      "episode number:  237\n",
      "reward till now:  -82.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 238 reward -82.00, Last 30ep Avg. rewards -82.00.\n",
      "episode number:  238\n",
      "reward till now:  -82.0\n",
      "time step:  0\n",
      "episode number:  238\n",
      "reward till now:  -82.0\n",
      "time step:  1\n",
      "episode number:  238\n",
      "reward till now:  -82.0\n",
      "time step:  2\n",
      "episode number:  238\n",
      "reward till now:  -82.0\n",
      "time step:  3\n",
      "episode number:  238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -83.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 239 reward -83.00, Last 30ep Avg. rewards -83.00.\n",
      "episode number:  239\n",
      "reward till now:  -83.0\n",
      "time step:  0\n",
      "episode number:  239\n",
      "reward till now:  -83.0\n",
      "time step:  1\n",
      "episode number:  239\n",
      "reward till now:  -83.0\n",
      "time step:  2\n",
      "episode number:  239\n",
      "reward till now:  -83.0\n",
      "time step:  3\n",
      "episode number:  239\n",
      "reward till now:  -84.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 240 reward -84.00, Last 30ep Avg. rewards -84.00.\n",
      "episode number:  240\n",
      "reward till now:  -84.0\n",
      "time step:  0\n",
      "episode number:  240\n",
      "reward till now:  -84.0\n",
      "time step:  1\n",
      "episode number:  240\n",
      "reward till now:  -84.0\n",
      "time step:  2\n",
      "episode number:  240\n",
      "reward till now:  -84.0\n",
      "time step:  3\n",
      "episode number:  240\n",
      "reward till now:  -85.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 241 reward -85.00, Last 30ep Avg. rewards -85.00.\n",
      "episode number:  241\n",
      "reward till now:  -85.0\n",
      "time step:  0\n",
      "episode number:  241\n",
      "reward till now:  -85.0\n",
      "time step:  1\n",
      "episode number:  241\n",
      "reward till now:  -85.0\n",
      "time step:  2\n",
      "episode number:  241\n",
      "reward till now:  -85.0\n",
      "time step:  3\n",
      "episode number:  241\n",
      "reward till now:  -86.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 242 reward -86.00, Last 30ep Avg. rewards -86.00.\n",
      "episode number:  242\n",
      "reward till now:  -86.0\n",
      "time step:  0\n",
      "episode number:  242\n",
      "reward till now:  -86.0\n",
      "time step:  1\n",
      "episode number:  242\n",
      "reward till now:  -86.0\n",
      "time step:  2\n",
      "episode number:  242\n",
      "reward till now:  -86.0\n",
      "time step:  3\n",
      "episode number:  242\n",
      "reward till now:  -87.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 243 reward -87.00, Last 30ep Avg. rewards -87.00.\n",
      "episode number:  243\n",
      "reward till now:  -87.0\n",
      "time step:  0\n",
      "episode number:  243\n",
      "reward till now:  -87.0\n",
      "time step:  1\n",
      "episode number:  243\n",
      "reward till now:  -87.0\n",
      "time step:  2\n",
      "episode number:  243\n",
      "reward till now:  -87.0\n",
      "time step:  3\n",
      "episode number:  243\n",
      "reward till now:  -88.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 244 reward -88.00, Last 30ep Avg. rewards -88.00.\n",
      "episode number:  244\n",
      "reward till now:  -88.0\n",
      "time step:  0\n",
      "episode number:  244\n",
      "reward till now:  -88.0\n",
      "time step:  1\n",
      "episode number:  244\n",
      "reward till now:  -88.0\n",
      "time step:  2\n",
      "episode number:  244\n",
      "reward till now:  -88.0\n",
      "time step:  3\n",
      "episode number:  244\n",
      "reward till now:  -89.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 245 reward -89.00, Last 30ep Avg. rewards -89.00.\n",
      "episode number:  245\n",
      "reward till now:  -89.0\n",
      "time step:  0\n",
      "episode number:  245\n",
      "reward till now:  -89.0\n",
      "time step:  1\n",
      "episode number:  245\n",
      "reward till now:  -89.0\n",
      "time step:  2\n",
      "episode number:  245\n",
      "reward till now:  -89.0\n",
      "time step:  3\n",
      "episode number:  245\n",
      "reward till now:  -90.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 246 reward -90.00, Last 30ep Avg. rewards -90.00.\n",
      "episode number:  246\n",
      "reward till now:  -90.0\n",
      "time step:  0\n",
      "episode number:  246\n",
      "reward till now:  -90.0\n",
      "time step:  1\n",
      "episode number:  246\n",
      "reward till now:  -90.0\n",
      "time step:  2\n",
      "episode number:  246\n",
      "reward till now:  -90.0\n",
      "time step:  3\n",
      "episode number:  246\n",
      "reward till now:  -91.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 247 reward -91.00, Last 30ep Avg. rewards -91.00.\n",
      "episode number:  247\n",
      "reward till now:  -91.0\n",
      "time step:  0\n",
      "episode number:  247\n",
      "reward till now:  -91.0\n",
      "time step:  1\n",
      "episode number:  247\n",
      "reward till now:  -91.0\n",
      "time step:  2\n",
      "episode number:  247\n",
      "reward till now:  -91.0\n",
      "time step:  3\n",
      "episode number:  247\n",
      "reward till now:  -92.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 248 reward -92.00, Last 30ep Avg. rewards -92.00.\n",
      "episode number:  248\n",
      "reward till now:  -92.0\n",
      "time step:  0\n",
      "episode number:  248\n",
      "reward till now:  -92.0\n",
      "time step:  1\n",
      "episode number:  248\n",
      "reward till now:  -92.0\n",
      "time step:  2\n",
      "episode number:  248\n",
      "reward till now:  -92.0\n",
      "time step:  3\n",
      "episode number:  248\n",
      "reward till now:  -93.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 249 reward -93.00, Last 30ep Avg. rewards -93.00.\n",
      "episode number:  249\n",
      "reward till now:  -93.0\n",
      "time step:  0\n",
      "episode number:  249\n",
      "reward till now:  -93.0\n",
      "time step:  1\n",
      "episode number:  249\n",
      "reward till now:  -93.0\n",
      "time step:  2\n",
      "episode number:  249\n",
      "reward till now:  -93.0\n",
      "time step:  3\n",
      "episode number:  249\n",
      "reward till now:  -94.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 250 reward -94.00, Last 30ep Avg. rewards -94.00.\n",
      "episode number:  250\n",
      "reward till now:  -94.0\n",
      "time step:  0\n",
      "episode number:  250\n",
      "reward till now:  -94.0\n",
      "time step:  1\n",
      "episode number:  250\n",
      "reward till now:  -94.0\n",
      "time step:  2\n",
      "episode number:  250\n",
      "reward till now:  -94.0\n",
      "time step:  3\n",
      "episode number:  250\n",
      "reward till now:  -95.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 251 reward -95.00, Last 30ep Avg. rewards -95.00.\n",
      "episode number:  251\n",
      "reward till now:  -95.0\n",
      "time step:  0\n",
      "episode number:  251\n",
      "reward till now:  -95.0\n",
      "time step:  1\n",
      "episode number:  251\n",
      "reward till now:  -95.0\n",
      "time step:  2\n",
      "episode number:  251\n",
      "reward till now:  -95.0\n",
      "time step:  3\n",
      "episode number:  251\n",
      "reward till now:  -96.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 252 reward -96.00, Last 30ep Avg. rewards -96.00.\n",
      "episode number:  252\n",
      "reward till now:  -96.0\n",
      "time step:  0\n",
      "episode number:  252\n",
      "reward till now:  -96.0\n",
      "time step:  1\n",
      "episode number:  252\n",
      "reward till now:  -96.0\n",
      "time step:  2\n",
      "episode number:  252\n",
      "reward till now:  -96.0\n",
      "time step:  3\n",
      "episode number:  252\n",
      "reward till now:  -97.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 253 reward -97.00, Last 30ep Avg. rewards -97.00.\n",
      "episode number:  253\n",
      "reward till now:  -97.0\n",
      "time step:  0\n",
      "episode number:  253\n",
      "reward till now:  -97.0\n",
      "time step:  1\n",
      "episode number:  253\n",
      "reward till now:  -97.0\n",
      "time step:  2\n",
      "episode number:  253\n",
      "reward till now:  -97.0\n",
      "time step:  3\n",
      "episode number:  253\n",
      "reward till now:  -98.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 254 reward -98.00, Last 30ep Avg. rewards -98.00.\n",
      "episode number:  254\n",
      "reward till now:  -98.0\n",
      "time step:  0\n",
      "episode number:  254\n",
      "reward till now:  -98.0\n",
      "time step:  1\n",
      "episode number:  254\n",
      "reward till now:  -98.0\n",
      "time step:  2\n",
      "episode number:  254\n",
      "reward till now:  -98.0\n",
      "time step:  3\n",
      "episode number:  254\n",
      "reward till now:  -99.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 255 reward -99.00, Last 30ep Avg. rewards -99.00.\n",
      "episode number:  255\n",
      "reward till now:  -99.0\n",
      "time step:  0\n",
      "episode number:  255\n",
      "reward till now:  -99.0\n",
      "time step:  1\n",
      "episode number:  255\n",
      "reward till now:  -99.0\n",
      "time step:  2\n",
      "episode number:  255\n",
      "reward till now:  -99.0\n",
      "time step:  3\n",
      "episode number:  255\n",
      "reward till now:  -100.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 256 reward -100.00, Last 30ep Avg. rewards -100.00.\n",
      "episode number:  256\n",
      "reward till now:  -100.0\n",
      "time step:  0\n",
      "episode number:  256\n",
      "reward till now:  -100.0\n",
      "time step:  1\n",
      "episode number:  256\n",
      "reward till now:  -100.0\n",
      "time step:  2\n",
      "episode number:  256\n",
      "reward till now:  -100.0\n",
      "time step:  3\n",
      "episode number:  256\n",
      "reward till now:  -101.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 257 reward -101.00, Last 30ep Avg. rewards -101.00.\n",
      "episode number:  257\n",
      "reward till now:  -101.0\n",
      "time step:  0\n",
      "episode number:  257\n",
      "reward till now:  -101.0\n",
      "time step:  1\n",
      "episode number:  257\n",
      "reward till now:  -101.0\n",
      "time step:  2\n",
      "episode number:  257\n",
      "reward till now:  -101.0\n",
      "time step:  3\n",
      "episode number:  257\n",
      "reward till now:  -102.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 258 reward -102.00, Last 30ep Avg. rewards -102.00.\n",
      "episode number:  258\n",
      "reward till now:  -102.0\n",
      "time step:  0\n",
      "episode number:  258\n",
      "reward till now:  -102.0\n",
      "time step:  1\n",
      "episode number:  258\n",
      "reward till now:  -102.0\n",
      "time step:  2\n",
      "episode number:  258\n",
      "reward till now:  -102.0\n",
      "time step:  3\n",
      "episode number:  258\n",
      "reward till now:  -103.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 259 reward -103.00, Last 30ep Avg. rewards -103.00.\n",
      "episode number:  259\n",
      "reward till now:  -103.0\n",
      "time step:  0\n",
      "episode number:  259\n",
      "reward till now:  -103.0\n",
      "time step:  1\n",
      "episode number:  259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -103.0\n",
      "time step:  2\n",
      "episode number:  259\n",
      "reward till now:  -103.0\n",
      "time step:  3\n",
      "episode number:  259\n",
      "reward till now:  -104.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 260 reward -104.00, Last 30ep Avg. rewards -104.00.\n",
      "episode number:  260\n",
      "reward till now:  -104.0\n",
      "time step:  0\n",
      "episode number:  260\n",
      "reward till now:  -104.0\n",
      "time step:  1\n",
      "episode number:  260\n",
      "reward till now:  -104.0\n",
      "time step:  2\n",
      "episode number:  260\n",
      "reward till now:  -104.0\n",
      "time step:  3\n",
      "episode number:  260\n",
      "reward till now:  -105.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 261 reward -105.00, Last 30ep Avg. rewards -105.00.\n",
      "episode number:  261\n",
      "reward till now:  -105.0\n",
      "time step:  0\n",
      "episode number:  261\n",
      "reward till now:  -105.0\n",
      "time step:  1\n",
      "episode number:  261\n",
      "reward till now:  -105.0\n",
      "time step:  2\n",
      "episode number:  261\n",
      "reward till now:  -105.0\n",
      "time step:  3\n",
      "episode number:  261\n",
      "reward till now:  -106.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 262 reward -106.00, Last 30ep Avg. rewards -106.00.\n",
      "episode number:  262\n",
      "reward till now:  -106.0\n",
      "time step:  0\n",
      "episode number:  262\n",
      "reward till now:  -106.0\n",
      "time step:  1\n",
      "episode number:  262\n",
      "reward till now:  -106.0\n",
      "time step:  2\n",
      "episode number:  262\n",
      "reward till now:  -106.0\n",
      "time step:  3\n",
      "episode number:  262\n",
      "reward till now:  -107.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 263 reward -107.00, Last 30ep Avg. rewards -107.00.\n",
      "episode number:  263\n",
      "reward till now:  -107.0\n",
      "time step:  0\n",
      "episode number:  263\n",
      "reward till now:  -107.0\n",
      "time step:  1\n",
      "episode number:  263\n",
      "reward till now:  -107.0\n",
      "time step:  2\n",
      "episode number:  263\n",
      "reward till now:  -107.0\n",
      "time step:  3\n",
      "episode number:  263\n",
      "reward till now:  -108.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 264 reward -108.00, Last 30ep Avg. rewards -108.00.\n",
      "episode number:  264\n",
      "reward till now:  -108.0\n",
      "time step:  0\n",
      "episode number:  264\n",
      "reward till now:  -108.0\n",
      "time step:  1\n",
      "episode number:  264\n",
      "reward till now:  -108.0\n",
      "time step:  2\n",
      "episode number:  264\n",
      "reward till now:  -108.0\n",
      "time step:  3\n",
      "episode number:  264\n",
      "reward till now:  -109.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 265 reward -109.00, Last 30ep Avg. rewards -109.00.\n",
      "episode number:  265\n",
      "reward till now:  -109.0\n",
      "time step:  0\n",
      "episode number:  265\n",
      "reward till now:  -109.0\n",
      "time step:  1\n",
      "episode number:  265\n",
      "reward till now:  -109.0\n",
      "time step:  2\n",
      "episode number:  265\n",
      "reward till now:  -109.0\n",
      "time step:  3\n",
      "episode number:  265\n",
      "reward till now:  -110.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 266 reward -110.00, Last 30ep Avg. rewards -110.00.\n",
      "episode number:  266\n",
      "reward till now:  -110.0\n",
      "time step:  0\n",
      "episode number:  266\n",
      "reward till now:  -110.0\n",
      "time step:  1\n",
      "episode number:  266\n",
      "reward till now:  -110.0\n",
      "time step:  2\n",
      "episode number:  266\n",
      "reward till now:  -110.0\n",
      "time step:  3\n",
      "episode number:  266\n",
      "reward till now:  -111.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 267 reward -111.00, Last 30ep Avg. rewards -111.00.\n",
      "episode number:  267\n",
      "reward till now:  -111.0\n",
      "time step:  0\n",
      "episode number:  267\n",
      "reward till now:  -111.0\n",
      "time step:  1\n",
      "episode number:  267\n",
      "reward till now:  -111.0\n",
      "time step:  2\n",
      "episode number:  267\n",
      "reward till now:  -111.0\n",
      "time step:  3\n",
      "episode number:  267\n",
      "reward till now:  -112.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 268 reward -112.00, Last 30ep Avg. rewards -112.00.\n",
      "episode number:  268\n",
      "reward till now:  -112.0\n",
      "time step:  0\n",
      "episode number:  268\n",
      "reward till now:  -112.0\n",
      "time step:  1\n",
      "episode number:  268\n",
      "reward till now:  -112.0\n",
      "time step:  2\n",
      "episode number:  268\n",
      "reward till now:  -112.0\n",
      "time step:  3\n",
      "episode number:  268\n",
      "reward till now:  -113.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 269 reward -113.00, Last 30ep Avg. rewards -113.00.\n",
      "episode number:  269\n",
      "reward till now:  -113.0\n",
      "time step:  0\n",
      "episode number:  269\n",
      "reward till now:  -113.0\n",
      "time step:  1\n",
      "episode number:  269\n",
      "reward till now:  -113.0\n",
      "time step:  2\n",
      "episode number:  269\n",
      "reward till now:  -113.0\n",
      "time step:  3\n",
      "episode number:  269\n",
      "reward till now:  -114.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 270 reward -114.00, Last 30ep Avg. rewards -114.00.\n",
      "episode number:  270\n",
      "reward till now:  -114.0\n",
      "time step:  0\n",
      "episode number:  270\n",
      "reward till now:  -114.0\n",
      "time step:  1\n",
      "episode number:  270\n",
      "reward till now:  -114.0\n",
      "time step:  2\n",
      "episode number:  270\n",
      "reward till now:  -114.0\n",
      "time step:  3\n",
      "episode number:  270\n",
      "reward till now:  -115.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 271 reward -115.00, Last 30ep Avg. rewards -115.00.\n",
      "episode number:  271\n",
      "reward till now:  -115.0\n",
      "time step:  0\n",
      "episode number:  271\n",
      "reward till now:  -115.0\n",
      "time step:  1\n",
      "episode number:  271\n",
      "reward till now:  -115.0\n",
      "time step:  2\n",
      "episode number:  271\n",
      "reward till now:  -115.0\n",
      "time step:  3\n",
      "episode number:  271\n",
      "reward till now:  -116.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 272 reward -116.00, Last 30ep Avg. rewards -116.00.\n",
      "episode number:  272\n",
      "reward till now:  -116.0\n",
      "time step:  0\n",
      "episode number:  272\n",
      "reward till now:  -116.0\n",
      "time step:  1\n",
      "episode number:  272\n",
      "reward till now:  -116.0\n",
      "time step:  2\n",
      "episode number:  272\n",
      "reward till now:  -116.0\n",
      "time step:  3\n",
      "episode number:  272\n",
      "reward till now:  -117.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 273 reward -117.00, Last 30ep Avg. rewards -117.00.\n",
      "episode number:  273\n",
      "reward till now:  -117.0\n",
      "time step:  0\n",
      "episode number:  273\n",
      "reward till now:  -117.0\n",
      "time step:  1\n",
      "episode number:  273\n",
      "reward till now:  -117.0\n",
      "time step:  2\n",
      "episode number:  273\n",
      "reward till now:  -117.0\n",
      "time step:  3\n",
      "episode number:  273\n",
      "reward till now:  -118.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 274 reward -118.00, Last 30ep Avg. rewards -118.00.\n",
      "episode number:  274\n",
      "reward till now:  -118.0\n",
      "time step:  0\n",
      "episode number:  274\n",
      "reward till now:  -118.0\n",
      "time step:  1\n",
      "episode number:  274\n",
      "reward till now:  -118.0\n",
      "time step:  2\n",
      "episode number:  274\n",
      "reward till now:  -118.0\n",
      "time step:  3\n",
      "episode number:  274\n",
      "reward till now:  -119.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 275 reward -119.00, Last 30ep Avg. rewards -119.00.\n",
      "episode number:  275\n",
      "reward till now:  -119.0\n",
      "time step:  0\n",
      "episode number:  275\n",
      "reward till now:  -119.0\n",
      "time step:  1\n",
      "episode number:  275\n",
      "reward till now:  -119.0\n",
      "time step:  2\n",
      "episode number:  275\n",
      "reward till now:  -119.0\n",
      "time step:  3\n",
      "episode number:  275\n",
      "reward till now:  -120.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 276 reward -120.00, Last 30ep Avg. rewards -120.00.\n",
      "episode number:  276\n",
      "reward till now:  -120.0\n",
      "time step:  0\n",
      "episode number:  276\n",
      "reward till now:  -120.0\n",
      "time step:  1\n",
      "episode number:  276\n",
      "reward till now:  -120.0\n",
      "time step:  2\n",
      "episode number:  276\n",
      "reward till now:  -120.0\n",
      "time step:  3\n",
      "episode number:  276\n",
      "reward till now:  -121.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 277 reward -121.00, Last 30ep Avg. rewards -121.00.\n",
      "episode number:  277\n",
      "reward till now:  -121.0\n",
      "time step:  0\n",
      "episode number:  277\n",
      "reward till now:  -121.0\n",
      "time step:  1\n",
      "episode number:  277\n",
      "reward till now:  -121.0\n",
      "time step:  2\n",
      "episode number:  277\n",
      "reward till now:  -121.0\n",
      "time step:  3\n",
      "episode number:  277\n",
      "reward till now:  -122.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 278 reward -122.00, Last 30ep Avg. rewards -122.00.\n",
      "episode number:  278\n",
      "reward till now:  -122.0\n",
      "time step:  0\n",
      "episode number:  278\n",
      "reward till now:  -122.0\n",
      "time step:  1\n",
      "episode number:  278\n",
      "reward till now:  -122.0\n",
      "time step:  2\n",
      "episode number:  278\n",
      "reward till now:  -122.0\n",
      "time step:  3\n",
      "episode number:  278\n",
      "reward till now:  -123.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 279 reward -123.00, Last 30ep Avg. rewards -123.00.\n",
      "episode number:  279\n",
      "reward till now:  -123.0\n",
      "time step:  0\n",
      "episode number:  279\n",
      "reward till now:  -123.0\n",
      "time step:  1\n",
      "episode number:  279\n",
      "reward till now:  -123.0\n",
      "time step:  2\n",
      "episode number:  279\n",
      "reward till now:  -123.0\n",
      "time step:  3\n",
      "episode number:  279\n",
      "reward till now:  -124.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 280 reward -124.00, Last 30ep Avg. rewards -124.00.\n",
      "episode number:  280\n",
      "reward till now:  -124.0\n",
      "time step:  0\n",
      "episode number:  280\n",
      "reward till now:  -124.0\n",
      "time step:  1\n",
      "episode number:  280\n",
      "reward till now:  -124.0\n",
      "time step:  2\n",
      "episode number:  280\n",
      "reward till now:  -124.0\n",
      "time step:  3\n",
      "episode number:  280\n",
      "reward till now:  -125.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 281 reward -125.00, Last 30ep Avg. rewards -125.00.\n",
      "episode number:  281\n",
      "reward till now:  -125.0\n",
      "time step:  0\n",
      "episode number:  281\n",
      "reward till now:  -125.0\n",
      "time step:  1\n",
      "episode number:  281\n",
      "reward till now:  -125.0\n",
      "time step:  2\n",
      "episode number:  281\n",
      "reward till now:  -125.0\n",
      "time step:  3\n",
      "episode number:  281\n",
      "reward till now:  -126.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 282 reward -126.00, Last 30ep Avg. rewards -126.00.\n",
      "episode number:  282\n",
      "reward till now:  -126.0\n",
      "time step:  0\n",
      "episode number:  282\n",
      "reward till now:  -126.0\n",
      "time step:  1\n",
      "episode number:  282\n",
      "reward till now:  -126.0\n",
      "time step:  2\n",
      "episode number:  282\n",
      "reward till now:  -126.0\n",
      "time step:  3\n",
      "episode number:  282\n",
      "reward till now:  -127.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 283 reward -127.00, Last 30ep Avg. rewards -127.00.\n",
      "episode number:  283\n",
      "reward till now:  -127.0\n",
      "time step:  0\n",
      "episode number:  283\n",
      "reward till now:  -127.0\n",
      "time step:  1\n",
      "episode number:  283\n",
      "reward till now:  -127.0\n",
      "time step:  2\n",
      "episode number:  283\n",
      "reward till now:  -127.0\n",
      "time step:  3\n",
      "episode number:  283\n",
      "reward till now:  -128.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 284 reward -128.00, Last 30ep Avg. rewards -128.00.\n",
      "episode number:  284\n",
      "reward till now:  -128.0\n",
      "time step:  0\n",
      "episode number:  284\n",
      "reward till now:  -128.0\n",
      "time step:  1\n",
      "episode number:  284\n",
      "reward till now:  -128.0\n",
      "time step:  2\n",
      "episode number:  284\n",
      "reward till now:  -128.0\n",
      "time step:  3\n",
      "episode number:  284\n",
      "reward till now:  -129.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 285 reward -129.00, Last 30ep Avg. rewards -129.00.\n",
      "episode number:  285\n",
      "reward till now:  -129.0\n",
      "time step:  0\n",
      "episode number:  285\n",
      "reward till now:  -129.0\n",
      "time step:  1\n",
      "episode number:  285\n",
      "reward till now:  -129.0\n",
      "time step:  2\n",
      "episode number:  285\n",
      "reward till now:  -129.0\n",
      "time step:  3\n",
      "episode number:  285\n",
      "reward till now:  -130.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 286 reward -130.00, Last 30ep Avg. rewards -130.00.\n",
      "episode number:  286\n",
      "reward till now:  -130.0\n",
      "time step:  0\n",
      "episode number:  286\n",
      "reward till now:  -130.0\n",
      "time step:  1\n",
      "episode number:  286\n",
      "reward till now:  -130.0\n",
      "time step:  2\n",
      "episode number:  286\n",
      "reward till now:  -130.0\n",
      "time step:  3\n",
      "episode number:  286\n",
      "reward till now:  -131.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 287 reward -131.00, Last 30ep Avg. rewards -131.00.\n",
      "episode number:  287\n",
      "reward till now:  -131.0\n",
      "time step:  0\n",
      "episode number:  287\n",
      "reward till now:  -131.0\n",
      "time step:  1\n",
      "episode number:  287\n",
      "reward till now:  -131.0\n",
      "time step:  2\n",
      "episode number:  287\n",
      "reward till now:  -131.0\n",
      "time step:  3\n",
      "episode number:  287\n",
      "reward till now:  -132.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 288 reward -132.00, Last 30ep Avg. rewards -132.00.\n",
      "episode number:  288\n",
      "reward till now:  -132.0\n",
      "time step:  0\n",
      "episode number:  288\n",
      "reward till now:  -132.0\n",
      "time step:  1\n",
      "episode number:  288\n",
      "reward till now:  -132.0\n",
      "time step:  2\n",
      "episode number:  288\n",
      "reward till now:  -132.0\n",
      "time step:  3\n",
      "episode number:  288\n",
      "reward till now:  -133.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 289 reward -133.00, Last 30ep Avg. rewards -133.00.\n",
      "episode number:  289\n",
      "reward till now:  -133.0\n",
      "time step:  0\n",
      "episode number:  289\n",
      "reward till now:  -133.0\n",
      "time step:  1\n",
      "episode number:  289\n",
      "reward till now:  -133.0\n",
      "time step:  2\n",
      "episode number:  289\n",
      "reward till now:  -133.0\n",
      "time step:  3\n",
      "episode number:  289\n",
      "reward till now:  -134.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 290 reward -134.00, Last 30ep Avg. rewards -134.00.\n",
      "episode number:  290\n",
      "reward till now:  -134.0\n",
      "time step:  0\n",
      "episode number:  290\n",
      "reward till now:  -134.0\n",
      "time step:  1\n",
      "episode number:  290\n",
      "reward till now:  -134.0\n",
      "time step:  2\n",
      "episode number:  290\n",
      "reward till now:  -134.0\n",
      "time step:  3\n",
      "episode number:  290\n",
      "reward till now:  -135.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 291 reward -135.00, Last 30ep Avg. rewards -135.00.\n",
      "episode number:  291\n",
      "reward till now:  -135.0\n",
      "time step:  0\n",
      "episode number:  291\n",
      "reward till now:  -135.0\n",
      "time step:  1\n",
      "episode number:  291\n",
      "reward till now:  -135.0\n",
      "time step:  2\n",
      "episode number:  291\n",
      "reward till now:  -135.0\n",
      "time step:  3\n",
      "episode number:  291\n",
      "reward till now:  -136.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 292 reward -136.00, Last 30ep Avg. rewards -136.00.\n",
      "episode number:  292\n",
      "reward till now:  -136.0\n",
      "time step:  0\n",
      "episode number:  292\n",
      "reward till now:  -136.0\n",
      "time step:  1\n",
      "episode number:  292\n",
      "reward till now:  -136.0\n",
      "time step:  2\n",
      "episode number:  292\n",
      "reward till now:  -136.0\n",
      "time step:  3\n",
      "episode number:  292\n",
      "reward till now:  -137.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 293 reward -137.00, Last 30ep Avg. rewards -137.00.\n",
      "episode number:  293\n",
      "reward till now:  -137.0\n",
      "time step:  0\n",
      "episode number:  293\n",
      "reward till now:  -137.0\n",
      "time step:  1\n",
      "episode number:  293\n",
      "reward till now:  -137.0\n",
      "time step:  2\n",
      "episode number:  293\n",
      "reward till now:  -137.0\n",
      "time step:  3\n",
      "episode number:  293\n",
      "reward till now:  -138.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 294 reward -138.00, Last 30ep Avg. rewards -138.00.\n",
      "episode number:  294\n",
      "reward till now:  -138.0\n",
      "time step:  0\n",
      "episode number:  294\n",
      "reward till now:  -138.0\n",
      "time step:  1\n",
      "episode number:  294\n",
      "reward till now:  -138.0\n",
      "time step:  2\n",
      "episode number:  294\n",
      "reward till now:  -138.0\n",
      "time step:  3\n",
      "episode number:  294\n",
      "reward till now:  -139.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 295 reward -139.00, Last 30ep Avg. rewards -139.00.\n",
      "episode number:  295\n",
      "reward till now:  -139.0\n",
      "time step:  0\n",
      "episode number:  295\n",
      "reward till now:  -139.0\n",
      "time step:  1\n",
      "episode number:  295\n",
      "reward till now:  -139.0\n",
      "time step:  2\n",
      "episode number:  295\n",
      "reward till now:  -139.0\n",
      "time step:  3\n",
      "episode number:  295\n",
      "reward till now:  -140.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 296 reward -140.00, Last 30ep Avg. rewards -140.00.\n",
      "episode number:  296\n",
      "reward till now:  -140.0\n",
      "time step:  0\n",
      "episode number:  296\n",
      "reward till now:  -140.0\n",
      "time step:  1\n",
      "episode number:  296\n",
      "reward till now:  -140.0\n",
      "time step:  2\n",
      "episode number:  296\n",
      "reward till now:  -140.0\n",
      "time step:  3\n",
      "episode number:  296\n",
      "reward till now:  -141.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 297 reward -141.00, Last 30ep Avg. rewards -141.00.\n",
      "episode number:  297\n",
      "reward till now:  -141.0\n",
      "time step:  0\n",
      "episode number:  297\n",
      "reward till now:  -141.0\n",
      "time step:  1\n",
      "episode number:  297\n",
      "reward till now:  -141.0\n",
      "time step:  2\n",
      "episode number:  297\n",
      "reward till now:  -141.0\n",
      "time step:  3\n",
      "episode number:  297\n",
      "reward till now:  -142.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 298 reward -142.00, Last 30ep Avg. rewards -142.00.\n",
      "episode number:  298\n",
      "reward till now:  -142.0\n",
      "time step:  0\n",
      "episode number:  298\n",
      "reward till now:  -142.0\n",
      "time step:  1\n",
      "episode number:  298\n",
      "reward till now:  -142.0\n",
      "time step:  2\n",
      "episode number:  298\n",
      "reward till now:  -142.0\n",
      "time step:  3\n",
      "episode number:  298\n",
      "reward till now:  -143.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 299 reward -143.00, Last 30ep Avg. rewards -143.00.\n",
      "episode number:  299\n",
      "reward till now:  -143.0\n",
      "time step:  0\n",
      "episode number:  299\n",
      "reward till now:  -143.0\n",
      "time step:  1\n",
      "episode number:  299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -143.0\n",
      "time step:  2\n",
      "episode number:  299\n",
      "reward till now:  -143.0\n",
      "time step:  3\n",
      "episode number:  299\n",
      "reward till now:  -144.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 300 reward -144.00, Last 30ep Avg. rewards -144.00.\n",
      "episode number:  300\n",
      "reward till now:  -144.0\n",
      "time step:  0\n",
      "episode number:  300\n",
      "reward till now:  -144.0\n",
      "time step:  1\n",
      "episode number:  300\n",
      "reward till now:  -144.0\n",
      "time step:  2\n",
      "episode number:  300\n",
      "reward till now:  -144.0\n",
      "time step:  3\n",
      "episode number:  300\n",
      "reward till now:  -145.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 301 reward -145.00, Last 30ep Avg. rewards -145.00.\n",
      "episode number:  301\n",
      "reward till now:  -145.0\n",
      "time step:  0\n",
      "episode number:  301\n",
      "reward till now:  -145.0\n",
      "time step:  1\n",
      "episode number:  301\n",
      "reward till now:  -145.0\n",
      "time step:  2\n",
      "episode number:  301\n",
      "reward till now:  -145.0\n",
      "time step:  3\n",
      "episode number:  301\n",
      "reward till now:  -146.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 302 reward -146.00, Last 30ep Avg. rewards -146.00.\n",
      "episode number:  302\n",
      "reward till now:  -146.0\n",
      "time step:  0\n",
      "episode number:  302\n",
      "reward till now:  -146.0\n",
      "time step:  1\n",
      "episode number:  302\n",
      "reward till now:  -146.0\n",
      "time step:  2\n",
      "episode number:  302\n",
      "reward till now:  -146.0\n",
      "time step:  3\n",
      "episode number:  302\n",
      "reward till now:  -147.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 303 reward -147.00, Last 30ep Avg. rewards -147.00.\n",
      "episode number:  303\n",
      "reward till now:  -147.0\n",
      "time step:  0\n",
      "episode number:  303\n",
      "reward till now:  -147.0\n",
      "time step:  1\n",
      "episode number:  303\n",
      "reward till now:  -147.0\n",
      "time step:  2\n",
      "episode number:  303\n",
      "reward till now:  -147.0\n",
      "time step:  3\n",
      "episode number:  303\n",
      "reward till now:  -148.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 304 reward -148.00, Last 30ep Avg. rewards -148.00.\n",
      "episode number:  304\n",
      "reward till now:  -148.0\n",
      "time step:  0\n",
      "episode number:  304\n",
      "reward till now:  -148.0\n",
      "time step:  1\n",
      "episode number:  304\n",
      "reward till now:  -148.0\n",
      "time step:  2\n",
      "episode number:  304\n",
      "reward till now:  -148.0\n",
      "time step:  3\n",
      "episode number:  304\n",
      "reward till now:  -149.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 305 reward -149.00, Last 30ep Avg. rewards -149.00.\n",
      "episode number:  305\n",
      "reward till now:  -149.0\n",
      "time step:  0\n",
      "episode number:  305\n",
      "reward till now:  -149.0\n",
      "time step:  1\n",
      "episode number:  305\n",
      "reward till now:  -149.0\n",
      "time step:  2\n",
      "episode number:  305\n",
      "reward till now:  -149.0\n",
      "time step:  3\n",
      "episode number:  305\n",
      "reward till now:  -150.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 306 reward -150.00, Last 30ep Avg. rewards -150.00.\n",
      "episode number:  306\n",
      "reward till now:  -150.0\n",
      "time step:  0\n",
      "episode number:  306\n",
      "reward till now:  -150.0\n",
      "time step:  1\n",
      "episode number:  306\n",
      "reward till now:  -150.0\n",
      "time step:  2\n",
      "episode number:  306\n",
      "reward till now:  -150.0\n",
      "time step:  3\n",
      "episode number:  306\n",
      "reward till now:  -151.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 307 reward -151.00, Last 30ep Avg. rewards -151.00.\n",
      "episode number:  307\n",
      "reward till now:  -151.0\n",
      "time step:  0\n",
      "episode number:  307\n",
      "reward till now:  -151.0\n",
      "time step:  1\n",
      "episode number:  307\n",
      "reward till now:  -151.0\n",
      "time step:  2\n",
      "episode number:  307\n",
      "reward till now:  -151.0\n",
      "time step:  3\n",
      "episode number:  307\n",
      "reward till now:  -152.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 308 reward -152.00, Last 30ep Avg. rewards -152.00.\n",
      "episode number:  308\n",
      "reward till now:  -152.0\n",
      "time step:  0\n",
      "episode number:  308\n",
      "reward till now:  -152.0\n",
      "time step:  1\n",
      "episode number:  308\n",
      "reward till now:  -152.0\n",
      "time step:  2\n",
      "episode number:  308\n",
      "reward till now:  -152.0\n",
      "time step:  3\n",
      "episode number:  308\n",
      "reward till now:  -153.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 309 reward -153.00, Last 30ep Avg. rewards -153.00.\n",
      "episode number:  309\n",
      "reward till now:  -153.0\n",
      "time step:  0\n",
      "episode number:  309\n",
      "reward till now:  -153.0\n",
      "time step:  1\n",
      "episode number:  309\n",
      "reward till now:  -153.0\n",
      "time step:  2\n",
      "episode number:  309\n",
      "reward till now:  -153.0\n",
      "time step:  3\n",
      "episode number:  309\n",
      "reward till now:  -154.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 310 reward -154.00, Last 30ep Avg. rewards -154.00.\n",
      "episode number:  310\n",
      "reward till now:  -154.0\n",
      "time step:  0\n",
      "episode number:  310\n",
      "reward till now:  -154.0\n",
      "time step:  1\n",
      "episode number:  310\n",
      "reward till now:  -154.0\n",
      "time step:  2\n",
      "episode number:  310\n",
      "reward till now:  -154.0\n",
      "time step:  3\n",
      "episode number:  310\n",
      "reward till now:  -155.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 311 reward -155.00, Last 30ep Avg. rewards -155.00.\n",
      "episode number:  311\n",
      "reward till now:  -155.0\n",
      "time step:  0\n",
      "episode number:  311\n",
      "reward till now:  -155.0\n",
      "time step:  1\n",
      "episode number:  311\n",
      "reward till now:  -155.0\n",
      "time step:  2\n",
      "episode number:  311\n",
      "reward till now:  -155.0\n",
      "time step:  3\n",
      "episode number:  311\n",
      "reward till now:  -156.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 312 reward -156.00, Last 30ep Avg. rewards -156.00.\n",
      "episode number:  312\n",
      "reward till now:  -156.0\n",
      "time step:  0\n",
      "episode number:  312\n",
      "reward till now:  -156.0\n",
      "time step:  1\n",
      "episode number:  312\n",
      "reward till now:  -156.0\n",
      "time step:  2\n",
      "episode number:  312\n",
      "reward till now:  -156.0\n",
      "time step:  3\n",
      "episode number:  312\n",
      "reward till now:  -157.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 313 reward -157.00, Last 30ep Avg. rewards -157.00.\n",
      "episode number:  313\n",
      "reward till now:  -157.0\n",
      "time step:  0\n",
      "episode number:  313\n",
      "reward till now:  -157.0\n",
      "time step:  1\n",
      "episode number:  313\n",
      "reward till now:  -157.0\n",
      "time step:  2\n",
      "episode number:  313\n",
      "reward till now:  -157.0\n",
      "time step:  3\n",
      "episode number:  313\n",
      "reward till now:  -158.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 314 reward -158.00, Last 30ep Avg. rewards -158.00.\n",
      "episode number:  314\n",
      "reward till now:  -158.0\n",
      "time step:  0\n",
      "episode number:  314\n",
      "reward till now:  -158.0\n",
      "time step:  1\n",
      "episode number:  314\n",
      "reward till now:  -158.0\n",
      "time step:  2\n",
      "episode number:  314\n",
      "reward till now:  -158.0\n",
      "time step:  3\n",
      "episode number:  314\n",
      "reward till now:  -159.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 315 reward -159.00, Last 30ep Avg. rewards -159.00.\n",
      "episode number:  315\n",
      "reward till now:  -159.0\n",
      "time step:  0\n",
      "episode number:  315\n",
      "reward till now:  -159.0\n",
      "time step:  1\n",
      "episode number:  315\n",
      "reward till now:  -159.0\n",
      "time step:  2\n",
      "episode number:  315\n",
      "reward till now:  -159.0\n",
      "time step:  3\n",
      "episode number:  315\n",
      "reward till now:  -160.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 316 reward -160.00, Last 30ep Avg. rewards -160.00.\n",
      "episode number:  316\n",
      "reward till now:  -160.0\n",
      "time step:  0\n",
      "episode number:  316\n",
      "reward till now:  -160.0\n",
      "time step:  1\n",
      "episode number:  316\n",
      "reward till now:  -160.0\n",
      "time step:  2\n",
      "episode number:  316\n",
      "reward till now:  -160.0\n",
      "time step:  3\n",
      "episode number:  316\n",
      "reward till now:  -161.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 317 reward -161.00, Last 30ep Avg. rewards -161.00.\n",
      "episode number:  317\n",
      "reward till now:  -161.0\n",
      "time step:  0\n",
      "episode number:  317\n",
      "reward till now:  -161.0\n",
      "time step:  1\n",
      "episode number:  317\n",
      "reward till now:  -161.0\n",
      "time step:  2\n",
      "episode number:  317\n",
      "reward till now:  -161.0\n",
      "time step:  3\n",
      "episode number:  317\n",
      "reward till now:  -162.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 318 reward -162.00, Last 30ep Avg. rewards -162.00.\n",
      "episode number:  318\n",
      "reward till now:  -162.0\n",
      "time step:  0\n",
      "episode number:  318\n",
      "reward till now:  -162.0\n",
      "time step:  1\n",
      "episode number:  318\n",
      "reward till now:  -162.0\n",
      "time step:  2\n",
      "episode number:  318\n",
      "reward till now:  -162.0\n",
      "time step:  3\n",
      "episode number:  318\n",
      "reward till now:  -163.0\n",
      "time step:  4\n",
      "in discounted reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 319 reward -163.00, Last 30ep Avg. rewards -163.00.\n",
      "episode number:  319\n",
      "reward till now:  -163.0\n",
      "time step:  0\n",
      "episode number:  319\n",
      "reward till now:  -163.0\n",
      "time step:  1\n",
      "episode number:  319\n",
      "reward till now:  -163.0\n",
      "time step:  2\n",
      "episode number:  319\n",
      "reward till now:  -163.0\n",
      "time step:  3\n",
      "episode number:  319\n",
      "reward till now:  -164.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 320 reward -164.00, Last 30ep Avg. rewards -164.00.\n",
      "episode number:  320\n",
      "reward till now:  -164.0\n",
      "time step:  0\n",
      "episode number:  320\n",
      "reward till now:  -164.0\n",
      "time step:  1\n",
      "episode number:  320\n",
      "reward till now:  -164.0\n",
      "time step:  2\n",
      "episode number:  320\n",
      "reward till now:  -164.0\n",
      "time step:  3\n",
      "episode number:  320\n",
      "reward till now:  -165.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 321 reward -165.00, Last 30ep Avg. rewards -165.00.\n",
      "episode number:  321\n",
      "reward till now:  -165.0\n",
      "time step:  0\n",
      "episode number:  321\n",
      "reward till now:  -165.0\n",
      "time step:  1\n",
      "episode number:  321\n",
      "reward till now:  -165.0\n",
      "time step:  2\n",
      "episode number:  321\n",
      "reward till now:  -165.0\n",
      "time step:  3\n",
      "episode number:  321\n",
      "reward till now:  -166.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 322 reward -166.00, Last 30ep Avg. rewards -166.00.\n",
      "episode number:  322\n",
      "reward till now:  -166.0\n",
      "time step:  0\n",
      "episode number:  322\n",
      "reward till now:  -166.0\n",
      "time step:  1\n",
      "episode number:  322\n",
      "reward till now:  -166.0\n",
      "time step:  2\n",
      "episode number:  322\n",
      "reward till now:  -166.0\n",
      "time step:  3\n",
      "episode number:  322\n",
      "reward till now:  -167.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 323 reward -167.00, Last 30ep Avg. rewards -167.00.\n",
      "episode number:  323\n",
      "reward till now:  -167.0\n",
      "time step:  0\n",
      "episode number:  323\n",
      "reward till now:  -167.0\n",
      "time step:  1\n",
      "episode number:  323\n",
      "reward till now:  -167.0\n",
      "time step:  2\n",
      "episode number:  323\n",
      "reward till now:  -167.0\n",
      "time step:  3\n",
      "episode number:  323\n",
      "reward till now:  -168.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 324 reward -168.00, Last 30ep Avg. rewards -168.00.\n",
      "episode number:  324\n",
      "reward till now:  -168.0\n",
      "time step:  0\n",
      "episode number:  324\n",
      "reward till now:  -168.0\n",
      "time step:  1\n",
      "episode number:  324\n",
      "reward till now:  -168.0\n",
      "time step:  2\n",
      "episode number:  324\n",
      "reward till now:  -168.0\n",
      "time step:  3\n",
      "episode number:  324\n",
      "reward till now:  -169.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 325 reward -169.00, Last 30ep Avg. rewards -169.00.\n",
      "episode number:  325\n",
      "reward till now:  -169.0\n",
      "time step:  0\n",
      "episode number:  325\n",
      "reward till now:  -169.0\n",
      "time step:  1\n",
      "episode number:  325\n",
      "reward till now:  -169.0\n",
      "time step:  2\n",
      "episode number:  325\n",
      "reward till now:  -169.0\n",
      "time step:  3\n",
      "episode number:  325\n",
      "reward till now:  -170.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 326 reward -170.00, Last 30ep Avg. rewards -170.00.\n",
      "episode number:  326\n",
      "reward till now:  -170.0\n",
      "time step:  0\n",
      "episode number:  326\n",
      "reward till now:  -170.0\n",
      "time step:  1\n",
      "episode number:  326\n",
      "reward till now:  -170.0\n",
      "time step:  2\n",
      "episode number:  326\n",
      "reward till now:  -170.0\n",
      "time step:  3\n",
      "episode number:  326\n",
      "reward till now:  -171.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 327 reward -171.00, Last 30ep Avg. rewards -171.00.\n",
      "episode number:  327\n",
      "reward till now:  -171.0\n",
      "time step:  0\n",
      "episode number:  327\n",
      "reward till now:  -171.0\n",
      "time step:  1\n",
      "episode number:  327\n",
      "reward till now:  -171.0\n",
      "time step:  2\n",
      "episode number:  327\n",
      "reward till now:  -171.0\n",
      "time step:  3\n",
      "episode number:  327\n",
      "reward till now:  -172.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 328 reward -172.00, Last 30ep Avg. rewards -172.00.\n",
      "episode number:  328\n",
      "reward till now:  -172.0\n",
      "time step:  0\n",
      "episode number:  328\n",
      "reward till now:  -172.0\n",
      "time step:  1\n",
      "episode number:  328\n",
      "reward till now:  -172.0\n",
      "time step:  2\n",
      "episode number:  328\n",
      "reward till now:  -172.0\n",
      "time step:  3\n",
      "episode number:  328\n",
      "reward till now:  -173.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 329 reward -173.00, Last 30ep Avg. rewards -173.00.\n",
      "episode number:  329\n",
      "reward till now:  -173.0\n",
      "time step:  0\n",
      "episode number:  329\n",
      "reward till now:  -173.0\n",
      "time step:  1\n",
      "episode number:  329\n",
      "reward till now:  -173.0\n",
      "time step:  2\n",
      "episode number:  329\n",
      "reward till now:  -173.0\n",
      "time step:  3\n",
      "episode number:  329\n",
      "reward till now:  -174.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 330 reward -174.00, Last 30ep Avg. rewards -174.00.\n",
      "episode number:  330\n",
      "reward till now:  -174.0\n",
      "time step:  0\n",
      "episode number:  330\n",
      "reward till now:  -174.0\n",
      "time step:  1\n",
      "episode number:  330\n",
      "reward till now:  -174.0\n",
      "time step:  2\n",
      "episode number:  330\n",
      "reward till now:  -174.0\n",
      "time step:  3\n",
      "episode number:  330\n",
      "reward till now:  -175.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 331 reward -175.00, Last 30ep Avg. rewards -175.00.\n",
      "episode number:  331\n",
      "reward till now:  -175.0\n",
      "time step:  0\n",
      "episode number:  331\n",
      "reward till now:  -175.0\n",
      "time step:  1\n",
      "episode number:  331\n",
      "reward till now:  -175.0\n",
      "time step:  2\n",
      "episode number:  331\n",
      "reward till now:  -175.0\n",
      "time step:  3\n",
      "episode number:  331\n",
      "reward till now:  -176.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 332 reward -176.00, Last 30ep Avg. rewards -176.00.\n",
      "episode number:  332\n",
      "reward till now:  -176.0\n",
      "time step:  0\n",
      "episode number:  332\n",
      "reward till now:  -176.0\n",
      "time step:  1\n",
      "episode number:  332\n",
      "reward till now:  -176.0\n",
      "time step:  2\n",
      "episode number:  332\n",
      "reward till now:  -176.0\n",
      "time step:  3\n",
      "episode number:  332\n",
      "reward till now:  -177.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 333 reward -177.00, Last 30ep Avg. rewards -177.00.\n",
      "episode number:  333\n",
      "reward till now:  -177.0\n",
      "time step:  0\n",
      "episode number:  333\n",
      "reward till now:  -177.0\n",
      "time step:  1\n",
      "episode number:  333\n",
      "reward till now:  -177.0\n",
      "time step:  2\n",
      "episode number:  333\n",
      "reward till now:  -177.0\n",
      "time step:  3\n",
      "episode number:  333\n",
      "reward till now:  -178.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 334 reward -178.00, Last 30ep Avg. rewards -178.00.\n",
      "episode number:  334\n",
      "reward till now:  -178.0\n",
      "time step:  0\n",
      "episode number:  334\n",
      "reward till now:  -178.0\n",
      "time step:  1\n",
      "episode number:  334\n",
      "reward till now:  -178.0\n",
      "time step:  2\n",
      "episode number:  334\n",
      "reward till now:  -178.0\n",
      "time step:  3\n",
      "episode number:  334\n",
      "reward till now:  -179.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 335 reward -179.00, Last 30ep Avg. rewards -179.00.\n",
      "episode number:  335\n",
      "reward till now:  -179.0\n",
      "time step:  0\n",
      "episode number:  335\n",
      "reward till now:  -179.0\n",
      "time step:  1\n",
      "episode number:  335\n",
      "reward till now:  -179.0\n",
      "time step:  2\n",
      "episode number:  335\n",
      "reward till now:  -179.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time step:  3\n",
      "episode number:  335\n",
      "reward till now:  -180.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 336 reward -180.00, Last 30ep Avg. rewards -180.00.\n",
      "episode number:  336\n",
      "reward till now:  -179.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 337 reward -179.00, Last 30ep Avg. rewards -179.00.\n",
      "episode number:  337\n",
      "reward till now:  -178.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 338 reward -178.00, Last 30ep Avg. rewards -178.00.\n",
      "episode number:  338\n",
      "reward till now:  -177.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 339 reward -177.00, Last 30ep Avg. rewards -177.00.\n",
      "episode number:  339\n",
      "reward till now:  -176.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 340 reward -176.00, Last 30ep Avg. rewards -176.00.\n",
      "episode number:  340\n",
      "reward till now:  -175.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 341 reward -175.00, Last 30ep Avg. rewards -175.00.\n",
      "episode number:  341\n",
      "reward till now:  -174.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 342 reward -174.00, Last 30ep Avg. rewards -174.00.\n",
      "episode number:  342\n",
      "reward till now:  -173.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 343 reward -173.00, Last 30ep Avg. rewards -173.00.\n",
      "episode number:  343\n",
      "reward till now:  -172.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 344 reward -172.00, Last 30ep Avg. rewards -172.00.\n",
      "episode number:  344\n",
      "reward till now:  -172.0\n",
      "time step:  0\n",
      "episode number:  344\n",
      "reward till now:  -172.0\n",
      "time step:  1\n",
      "episode number:  344\n",
      "reward till now:  -172.0\n",
      "time step:  2\n",
      "episode number:  344\n",
      "reward till now:  -172.0\n",
      "time step:  3\n",
      "episode number:  344\n",
      "reward till now:  -173.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 345 reward -173.00, Last 30ep Avg. rewards -173.00.\n",
      "episode number:  345\n",
      "reward till now:  -173.0\n",
      "time step:  0\n",
      "episode number:  345\n",
      "reward till now:  -173.0\n",
      "time step:  1\n",
      "episode number:  345\n",
      "reward till now:  -173.0\n",
      "time step:  2\n",
      "episode number:  345\n",
      "reward till now:  -173.0\n",
      "time step:  3\n",
      "episode number:  345\n",
      "reward till now:  -174.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 346 reward -174.00, Last 30ep Avg. rewards -174.00.\n",
      "episode number:  346\n",
      "reward till now:  -174.0\n",
      "time step:  0\n",
      "episode number:  346\n",
      "reward till now:  -174.0\n",
      "time step:  1\n",
      "episode number:  346\n",
      "reward till now:  -174.0\n",
      "time step:  2\n",
      "episode number:  346\n",
      "reward till now:  -174.0\n",
      "time step:  3\n",
      "episode number:  346\n",
      "reward till now:  -175.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 347 reward -175.00, Last 30ep Avg. rewards -175.00.\n",
      "episode number:  347\n",
      "reward till now:  -175.0\n",
      "time step:  0\n",
      "episode number:  347\n",
      "reward till now:  -175.0\n",
      "time step:  1\n",
      "episode number:  347\n",
      "reward till now:  -175.0\n",
      "time step:  2\n",
      "episode number:  347\n",
      "reward till now:  -175.0\n",
      "time step:  3\n",
      "episode number:  347\n",
      "reward till now:  -176.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 348 reward -176.00, Last 30ep Avg. rewards -176.00.\n",
      "episode number:  348\n",
      "reward till now:  -176.0\n",
      "time step:  0\n",
      "episode number:  348\n",
      "reward till now:  -176.0\n",
      "time step:  1\n",
      "episode number:  348\n",
      "reward till now:  -176.0\n",
      "time step:  2\n",
      "episode number:  348\n",
      "reward till now:  -176.0\n",
      "time step:  3\n",
      "episode number:  348\n",
      "reward till now:  -177.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 349 reward -177.00, Last 30ep Avg. rewards -177.00.\n",
      "episode number:  349\n",
      "reward till now:  -177.0\n",
      "time step:  0\n",
      "episode number:  349\n",
      "reward till now:  -177.0\n",
      "time step:  1\n",
      "episode number:  349\n",
      "reward till now:  -177.0\n",
      "time step:  2\n",
      "episode number:  349\n",
      "reward till now:  -177.0\n",
      "time step:  3\n",
      "episode number:  349\n",
      "reward till now:  -178.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 350 reward -178.00, Last 30ep Avg. rewards -178.00.\n",
      "episode number:  350\n",
      "reward till now:  -178.0\n",
      "time step:  0\n",
      "episode number:  350\n",
      "reward till now:  -178.0\n",
      "time step:  1\n",
      "episode number:  350\n",
      "reward till now:  -178.0\n",
      "time step:  2\n",
      "episode number:  350\n",
      "reward till now:  -178.0\n",
      "time step:  3\n",
      "episode number:  350\n",
      "reward till now:  -179.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 351 reward -179.00, Last 30ep Avg. rewards -179.00.\n",
      "episode number:  351\n",
      "reward till now:  -179.0\n",
      "time step:  0\n",
      "episode number:  351\n",
      "reward till now:  -179.0\n",
      "time step:  1\n",
      "episode number:  351\n",
      "reward till now:  -179.0\n",
      "time step:  2\n",
      "episode number:  351\n",
      "reward till now:  -179.0\n",
      "time step:  3\n",
      "episode number:  351\n",
      "reward till now:  -180.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 352 reward -180.00, Last 30ep Avg. rewards -180.00.\n",
      "episode number:  352\n",
      "reward till now:  -180.0\n",
      "time step:  0\n",
      "episode number:  352\n",
      "reward till now:  -180.0\n",
      "time step:  1\n",
      "episode number:  352\n",
      "reward till now:  -180.0\n",
      "time step:  2\n",
      "episode number:  352\n",
      "reward till now:  -180.0\n",
      "time step:  3\n",
      "episode number:  352\n",
      "reward till now:  -181.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 353 reward -181.00, Last 30ep Avg. rewards -181.00.\n",
      "episode number:  353\n",
      "reward till now:  -181.0\n",
      "time step:  0\n",
      "episode number:  353\n",
      "reward till now:  -181.0\n",
      "time step:  1\n",
      "episode number:  353\n",
      "reward till now:  -181.0\n",
      "time step:  2\n",
      "episode number:  353\n",
      "reward till now:  -181.0\n",
      "time step:  3\n",
      "episode number:  353\n",
      "reward till now:  -182.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 354 reward -182.00, Last 30ep Avg. rewards -182.00.\n",
      "episode number:  354\n",
      "reward till now:  -182.0\n",
      "time step:  0\n",
      "episode number:  354\n",
      "reward till now:  -182.0\n",
      "time step:  1\n",
      "episode number:  354\n",
      "reward till now:  -182.0\n",
      "time step:  2\n",
      "episode number:  354\n",
      "reward till now:  -182.0\n",
      "time step:  3\n",
      "episode number:  354\n",
      "reward till now:  -183.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 355 reward -183.00, Last 30ep Avg. rewards -183.00.\n",
      "episode number:  355\n",
      "reward till now:  -183.0\n",
      "time step:  0\n",
      "episode number:  355\n",
      "reward till now:  -183.0\n",
      "time step:  1\n",
      "episode number:  355\n",
      "reward till now:  -183.0\n",
      "time step:  2\n",
      "episode number:  355\n",
      "reward till now:  -183.0\n",
      "time step:  3\n",
      "episode number:  355\n",
      "reward till now:  -184.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 356 reward -184.00, Last 30ep Avg. rewards -184.00.\n",
      "episode number:  356\n",
      "reward till now:  -184.0\n",
      "time step:  0\n",
      "episode number:  356\n",
      "reward till now:  -184.0\n",
      "time step:  1\n",
      "episode number:  356\n",
      "reward till now:  -184.0\n",
      "time step:  2\n",
      "episode number:  356\n",
      "reward till now:  -184.0\n",
      "time step:  3\n",
      "episode number:  356\n",
      "reward till now:  -185.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 357 reward -185.00, Last 30ep Avg. rewards -185.00.\n",
      "episode number:  357\n",
      "reward till now:  -185.0\n",
      "time step:  0\n",
      "episode number:  357\n",
      "reward till now:  -185.0\n",
      "time step:  1\n",
      "episode number:  357\n",
      "reward till now:  -185.0\n",
      "time step:  2\n",
      "episode number:  357\n",
      "reward till now:  -185.0\n",
      "time step:  3\n",
      "episode number:  357\n",
      "reward till now:  -186.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 358 reward -186.00, Last 30ep Avg. rewards -186.00.\n",
      "episode number:  358\n",
      "reward till now:  -186.0\n",
      "time step:  0\n",
      "episode number:  358\n",
      "reward till now:  -186.0\n",
      "time step:  1\n",
      "episode number:  358\n",
      "reward till now:  -186.0\n",
      "time step:  2\n",
      "episode number:  358\n",
      "reward till now:  -186.0\n",
      "time step:  3\n",
      "episode number:  358\n",
      "reward till now:  -187.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 359 reward -187.00, Last 30ep Avg. rewards -187.00.\n",
      "episode number:  359\n",
      "reward till now:  -187.0\n",
      "time step:  0\n",
      "episode number:  359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -187.0\n",
      "time step:  1\n",
      "episode number:  359\n",
      "reward till now:  -187.0\n",
      "time step:  2\n",
      "episode number:  359\n",
      "reward till now:  -187.0\n",
      "time step:  3\n",
      "episode number:  359\n",
      "reward till now:  -188.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 360 reward -188.00, Last 30ep Avg. rewards -188.00.\n",
      "episode number:  360\n",
      "reward till now:  -188.0\n",
      "time step:  0\n",
      "episode number:  360\n",
      "reward till now:  -188.0\n",
      "time step:  1\n",
      "episode number:  360\n",
      "reward till now:  -188.0\n",
      "time step:  2\n",
      "episode number:  360\n",
      "reward till now:  -188.0\n",
      "time step:  3\n",
      "episode number:  360\n",
      "reward till now:  -189.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 361 reward -189.00, Last 30ep Avg. rewards -189.00.\n",
      "episode number:  361\n",
      "reward till now:  -189.0\n",
      "time step:  0\n",
      "episode number:  361\n",
      "reward till now:  -189.0\n",
      "time step:  1\n",
      "episode number:  361\n",
      "reward till now:  -189.0\n",
      "time step:  2\n",
      "episode number:  361\n",
      "reward till now:  -189.0\n",
      "time step:  3\n",
      "episode number:  361\n",
      "reward till now:  -190.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 362 reward -190.00, Last 30ep Avg. rewards -190.00.\n",
      "episode number:  362\n",
      "reward till now:  -190.0\n",
      "time step:  0\n",
      "episode number:  362\n",
      "reward till now:  -190.0\n",
      "time step:  1\n",
      "episode number:  362\n",
      "reward till now:  -190.0\n",
      "time step:  2\n",
      "episode number:  362\n",
      "reward till now:  -190.0\n",
      "time step:  3\n",
      "episode number:  362\n",
      "reward till now:  -191.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 363 reward -191.00, Last 30ep Avg. rewards -191.00.\n",
      "episode number:  363\n",
      "reward till now:  -191.0\n",
      "time step:  0\n",
      "episode number:  363\n",
      "reward till now:  -191.0\n",
      "time step:  1\n",
      "episode number:  363\n",
      "reward till now:  -191.0\n",
      "time step:  2\n",
      "episode number:  363\n",
      "reward till now:  -191.0\n",
      "time step:  3\n",
      "episode number:  363\n",
      "reward till now:  -192.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 364 reward -192.00, Last 30ep Avg. rewards -192.00.\n",
      "episode number:  364\n",
      "reward till now:  -192.0\n",
      "time step:  0\n",
      "episode number:  364\n",
      "reward till now:  -192.0\n",
      "time step:  1\n",
      "episode number:  364\n",
      "reward till now:  -192.0\n",
      "time step:  2\n",
      "episode number:  364\n",
      "reward till now:  -192.0\n",
      "time step:  3\n",
      "episode number:  364\n",
      "reward till now:  -193.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 365 reward -193.00, Last 30ep Avg. rewards -193.00.\n",
      "episode number:  365\n",
      "reward till now:  -193.0\n",
      "time step:  0\n",
      "episode number:  365\n",
      "reward till now:  -193.0\n",
      "time step:  1\n",
      "episode number:  365\n",
      "reward till now:  -193.0\n",
      "time step:  2\n",
      "episode number:  365\n",
      "reward till now:  -193.0\n",
      "time step:  3\n",
      "episode number:  365\n",
      "reward till now:  -194.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 366 reward -194.00, Last 30ep Avg. rewards -194.00.\n",
      "episode number:  366\n",
      "reward till now:  -193.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 367 reward -193.00, Last 30ep Avg. rewards -193.00.\n",
      "episode number:  367\n",
      "reward till now:  -192.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 368 reward -192.00, Last 30ep Avg. rewards -192.00.\n",
      "episode number:  368\n",
      "reward till now:  -191.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 369 reward -191.00, Last 30ep Avg. rewards -191.00.\n",
      "episode number:  369\n",
      "reward till now:  -190.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 370 reward -190.00, Last 30ep Avg. rewards -190.00.\n",
      "episode number:  370\n",
      "reward till now:  -189.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 371 reward -189.00, Last 30ep Avg. rewards -189.00.\n",
      "episode number:  371\n",
      "reward till now:  -188.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 372 reward -188.00, Last 30ep Avg. rewards -188.00.\n",
      "episode number:  372\n",
      "reward till now:  -188.0\n",
      "time step:  0\n",
      "episode number:  372\n",
      "reward till now:  -188.0\n",
      "time step:  1\n",
      "episode number:  372\n",
      "reward till now:  -188.0\n",
      "time step:  2\n",
      "episode number:  372\n",
      "reward till now:  -188.0\n",
      "time step:  3\n",
      "episode number:  372\n",
      "reward till now:  -189.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 373 reward -189.00, Last 30ep Avg. rewards -189.00.\n",
      "episode number:  373\n",
      "reward till now:  -189.0\n",
      "time step:  0\n",
      "episode number:  373\n",
      "reward till now:  -189.0\n",
      "time step:  1\n",
      "episode number:  373\n",
      "reward till now:  -189.0\n",
      "time step:  2\n",
      "episode number:  373\n",
      "reward till now:  -189.0\n",
      "time step:  3\n",
      "episode number:  373\n",
      "reward till now:  -190.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 374 reward -190.00, Last 30ep Avg. rewards -190.00.\n",
      "episode number:  374\n",
      "reward till now:  -190.0\n",
      "time step:  0\n",
      "episode number:  374\n",
      "reward till now:  -190.0\n",
      "time step:  1\n",
      "episode number:  374\n",
      "reward till now:  -190.0\n",
      "time step:  2\n",
      "episode number:  374\n",
      "reward till now:  -190.0\n",
      "time step:  3\n",
      "episode number:  374\n",
      "reward till now:  -191.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 375 reward -191.00, Last 30ep Avg. rewards -191.00.\n",
      "episode number:  375\n",
      "reward till now:  -191.0\n",
      "time step:  0\n",
      "episode number:  375\n",
      "reward till now:  -191.0\n",
      "time step:  1\n",
      "episode number:  375\n",
      "reward till now:  -191.0\n",
      "time step:  2\n",
      "episode number:  375\n",
      "reward till now:  -191.0\n",
      "time step:  3\n",
      "episode number:  375\n",
      "reward till now:  -192.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 376 reward -192.00, Last 30ep Avg. rewards -192.00.\n",
      "episode number:  376\n",
      "reward till now:  -192.0\n",
      "time step:  0\n",
      "episode number:  376\n",
      "reward till now:  -192.0\n",
      "time step:  1\n",
      "episode number:  376\n",
      "reward till now:  -192.0\n",
      "time step:  2\n",
      "episode number:  376\n",
      "reward till now:  -192.0\n",
      "time step:  3\n",
      "episode number:  376\n",
      "reward till now:  -193.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 377 reward -193.00, Last 30ep Avg. rewards -193.00.\n",
      "episode number:  377\n",
      "reward till now:  -193.0\n",
      "time step:  0\n",
      "episode number:  377\n",
      "reward till now:  -193.0\n",
      "time step:  1\n",
      "episode number:  377\n",
      "reward till now:  -193.0\n",
      "time step:  2\n",
      "episode number:  377\n",
      "reward till now:  -193.0\n",
      "time step:  3\n",
      "episode number:  377\n",
      "reward till now:  -194.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 378 reward -194.00, Last 30ep Avg. rewards -194.00.\n",
      "episode number:  378\n",
      "reward till now:  -194.0\n",
      "time step:  0\n",
      "episode number:  378\n",
      "reward till now:  -194.0\n",
      "time step:  1\n",
      "episode number:  378\n",
      "reward till now:  -194.0\n",
      "time step:  2\n",
      "episode number:  378\n",
      "reward till now:  -194.0\n",
      "time step:  3\n",
      "episode number:  378\n",
      "reward till now:  -195.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 379 reward -195.00, Last 30ep Avg. rewards -195.00.\n",
      "episode number:  379\n",
      "reward till now:  -195.0\n",
      "time step:  0\n",
      "episode number:  379\n",
      "reward till now:  -195.0\n",
      "time step:  1\n",
      "episode number:  379\n",
      "reward till now:  -195.0\n",
      "time step:  2\n",
      "episode number:  379\n",
      "reward till now:  -195.0\n",
      "time step:  3\n",
      "episode number:  379\n",
      "reward till now:  -196.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 380 reward -196.00, Last 30ep Avg. rewards -196.00.\n",
      "episode number:  380\n",
      "reward till now:  -196.0\n",
      "time step:  0\n",
      "episode number:  380\n",
      "reward till now:  -196.0\n",
      "time step:  1\n",
      "episode number:  380\n",
      "reward till now:  -196.0\n",
      "time step:  2\n",
      "episode number:  380\n",
      "reward till now:  -196.0\n",
      "time step:  3\n",
      "episode number:  380\n",
      "reward till now:  -197.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 381 reward -197.00, Last 30ep Avg. rewards -197.00.\n",
      "episode number:  381\n",
      "reward till now:  -197.0\n",
      "time step:  0\n",
      "episode number:  381\n",
      "reward till now:  -197.0\n",
      "time step:  1\n",
      "episode number:  381\n",
      "reward till now:  -197.0\n",
      "time step:  2\n",
      "episode number:  381\n",
      "reward till now:  -197.0\n",
      "time step:  3\n",
      "episode number:  381\n",
      "reward till now:  -198.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 382 reward -198.00, Last 30ep Avg. rewards -198.00.\n",
      "episode number:  382\n",
      "reward till now:  -198.0\n",
      "time step:  0\n",
      "episode number:  382\n",
      "reward till now:  -198.0\n",
      "time step:  1\n",
      "episode number:  382\n",
      "reward till now:  -198.0\n",
      "time step:  2\n",
      "episode number:  382\n",
      "reward till now:  -198.0\n",
      "time step:  3\n",
      "episode number:  382\n",
      "reward till now:  -199.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 383 reward -199.00, Last 30ep Avg. rewards -199.00.\n",
      "episode number:  383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -199.0\n",
      "time step:  0\n",
      "episode number:  383\n",
      "reward till now:  -199.0\n",
      "time step:  1\n",
      "episode number:  383\n",
      "reward till now:  -199.0\n",
      "time step:  2\n",
      "episode number:  383\n",
      "reward till now:  -199.0\n",
      "time step:  3\n",
      "episode number:  383\n",
      "reward till now:  -200.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 384 reward -200.00, Last 30ep Avg. rewards -200.00.\n",
      "episode number:  384\n",
      "reward till now:  -200.0\n",
      "time step:  0\n",
      "episode number:  384\n",
      "reward till now:  -200.0\n",
      "time step:  1\n",
      "episode number:  384\n",
      "reward till now:  -200.0\n",
      "time step:  2\n",
      "episode number:  384\n",
      "reward till now:  -200.0\n",
      "time step:  3\n",
      "episode number:  384\n",
      "reward till now:  -201.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 385 reward -201.00, Last 30ep Avg. rewards -201.00.\n",
      "episode number:  385\n",
      "reward till now:  -201.0\n",
      "time step:  0\n",
      "episode number:  385\n",
      "reward till now:  -201.0\n",
      "time step:  1\n",
      "episode number:  385\n",
      "reward till now:  -201.0\n",
      "time step:  2\n",
      "episode number:  385\n",
      "reward till now:  -201.0\n",
      "time step:  3\n",
      "episode number:  385\n",
      "reward till now:  -202.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 386 reward -202.00, Last 30ep Avg. rewards -202.00.\n",
      "episode number:  386\n",
      "reward till now:  -202.0\n",
      "time step:  0\n",
      "episode number:  386\n",
      "reward till now:  -202.0\n",
      "time step:  1\n",
      "episode number:  386\n",
      "reward till now:  -202.0\n",
      "time step:  2\n",
      "episode number:  386\n",
      "reward till now:  -202.0\n",
      "time step:  3\n",
      "episode number:  386\n",
      "reward till now:  -203.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 387 reward -203.00, Last 30ep Avg. rewards -203.00.\n",
      "episode number:  387\n",
      "reward till now:  -203.0\n",
      "time step:  0\n",
      "episode number:  387\n",
      "reward till now:  -203.0\n",
      "time step:  1\n",
      "episode number:  387\n",
      "reward till now:  -203.0\n",
      "time step:  2\n",
      "episode number:  387\n",
      "reward till now:  -203.0\n",
      "time step:  3\n",
      "episode number:  387\n",
      "reward till now:  -204.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 388 reward -204.00, Last 30ep Avg. rewards -204.00.\n",
      "episode number:  388\n",
      "reward till now:  -204.0\n",
      "time step:  0\n",
      "episode number:  388\n",
      "reward till now:  -204.0\n",
      "time step:  1\n",
      "episode number:  388\n",
      "reward till now:  -204.0\n",
      "time step:  2\n",
      "episode number:  388\n",
      "reward till now:  -204.0\n",
      "time step:  3\n",
      "episode number:  388\n",
      "reward till now:  -205.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 389 reward -205.00, Last 30ep Avg. rewards -205.00.\n",
      "episode number:  389\n",
      "reward till now:  -205.0\n",
      "time step:  0\n",
      "episode number:  389\n",
      "reward till now:  -205.0\n",
      "time step:  1\n",
      "episode number:  389\n",
      "reward till now:  -205.0\n",
      "time step:  2\n",
      "episode number:  389\n",
      "reward till now:  -205.0\n",
      "time step:  3\n",
      "episode number:  389\n",
      "reward till now:  -206.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 390 reward -206.00, Last 30ep Avg. rewards -206.00.\n",
      "episode number:  390\n",
      "reward till now:  -206.0\n",
      "time step:  0\n",
      "episode number:  390\n",
      "reward till now:  -206.0\n",
      "time step:  1\n",
      "episode number:  390\n",
      "reward till now:  -206.0\n",
      "time step:  2\n",
      "episode number:  390\n",
      "reward till now:  -206.0\n",
      "time step:  3\n",
      "episode number:  390\n",
      "reward till now:  -207.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 391 reward -207.00, Last 30ep Avg. rewards -207.00.\n",
      "episode number:  391\n",
      "reward till now:  -207.0\n",
      "time step:  0\n",
      "episode number:  391\n",
      "reward till now:  -207.0\n",
      "time step:  1\n",
      "episode number:  391\n",
      "reward till now:  -207.0\n",
      "time step:  2\n",
      "episode number:  391\n",
      "reward till now:  -207.0\n",
      "time step:  3\n",
      "episode number:  391\n",
      "reward till now:  -208.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 392 reward -208.00, Last 30ep Avg. rewards -208.00.\n",
      "episode number:  392\n",
      "reward till now:  -208.0\n",
      "time step:  0\n",
      "episode number:  392\n",
      "reward till now:  -208.0\n",
      "time step:  1\n",
      "episode number:  392\n",
      "reward till now:  -208.0\n",
      "time step:  2\n",
      "episode number:  392\n",
      "reward till now:  -208.0\n",
      "time step:  3\n",
      "episode number:  392\n",
      "reward till now:  -209.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 393 reward -209.00, Last 30ep Avg. rewards -209.00.\n",
      "episode number:  393\n",
      "reward till now:  -209.0\n",
      "time step:  0\n",
      "episode number:  393\n",
      "reward till now:  -209.0\n",
      "time step:  1\n",
      "episode number:  393\n",
      "reward till now:  -209.0\n",
      "time step:  2\n",
      "episode number:  393\n",
      "reward till now:  -209.0\n",
      "time step:  3\n",
      "episode number:  393\n",
      "reward till now:  -210.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 394 reward -210.00, Last 30ep Avg. rewards -210.00.\n",
      "episode number:  394\n",
      "reward till now:  -210.0\n",
      "time step:  0\n",
      "episode number:  394\n",
      "reward till now:  -210.0\n",
      "time step:  1\n",
      "episode number:  394\n",
      "reward till now:  -210.0\n",
      "time step:  2\n",
      "episode number:  394\n",
      "reward till now:  -210.0\n",
      "time step:  3\n",
      "episode number:  394\n",
      "reward till now:  -211.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 395 reward -211.00, Last 30ep Avg. rewards -211.00.\n",
      "episode number:  395\n",
      "reward till now:  -211.0\n",
      "time step:  0\n",
      "episode number:  395\n",
      "reward till now:  -211.0\n",
      "time step:  1\n",
      "episode number:  395\n",
      "reward till now:  -211.0\n",
      "time step:  2\n",
      "episode number:  395\n",
      "reward till now:  -211.0\n",
      "time step:  3\n",
      "episode number:  395\n",
      "reward till now:  -212.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 396 reward -212.00, Last 30ep Avg. rewards -212.00.\n",
      "episode number:  396\n",
      "reward till now:  -212.0\n",
      "time step:  0\n",
      "episode number:  396\n",
      "reward till now:  -212.0\n",
      "time step:  1\n",
      "episode number:  396\n",
      "reward till now:  -212.0\n",
      "time step:  2\n",
      "episode number:  396\n",
      "reward till now:  -212.0\n",
      "time step:  3\n",
      "episode number:  396\n",
      "reward till now:  -213.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 397 reward -213.00, Last 30ep Avg. rewards -213.00.\n",
      "episode number:  397\n",
      "reward till now:  -213.0\n",
      "time step:  0\n",
      "episode number:  397\n",
      "reward till now:  -213.0\n",
      "time step:  1\n",
      "episode number:  397\n",
      "reward till now:  -213.0\n",
      "time step:  2\n",
      "episode number:  397\n",
      "reward till now:  -213.0\n",
      "time step:  3\n",
      "episode number:  397\n",
      "reward till now:  -214.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 398 reward -214.00, Last 30ep Avg. rewards -214.00.\n",
      "episode number:  398\n",
      "reward till now:  -214.0\n",
      "time step:  0\n",
      "episode number:  398\n",
      "reward till now:  -214.0\n",
      "time step:  1\n",
      "episode number:  398\n",
      "reward till now:  -214.0\n",
      "time step:  2\n",
      "episode number:  398\n",
      "reward till now:  -214.0\n",
      "time step:  3\n",
      "episode number:  398\n",
      "reward till now:  -215.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 399 reward -215.00, Last 30ep Avg. rewards -215.00.\n",
      "episode number:  399\n",
      "reward till now:  -215.0\n",
      "time step:  0\n",
      "episode number:  399\n",
      "reward till now:  -215.0\n",
      "time step:  1\n",
      "episode number:  399\n",
      "reward till now:  -215.0\n",
      "time step:  2\n",
      "episode number:  399\n",
      "reward till now:  -215.0\n",
      "time step:  3\n",
      "episode number:  399\n",
      "reward till now:  -216.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 400 reward -216.00, Last 30ep Avg. rewards -216.00.\n",
      "episode number:  400\n",
      "reward till now:  -216.0\n",
      "time step:  0\n",
      "episode number:  400\n",
      "reward till now:  -216.0\n",
      "time step:  1\n",
      "episode number:  400\n",
      "reward till now:  -216.0\n",
      "time step:  2\n",
      "episode number:  400\n",
      "reward till now:  -216.0\n",
      "time step:  3\n",
      "episode number:  400\n",
      "reward till now:  -217.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 401 reward -217.00, Last 30ep Avg. rewards -217.00.\n",
      "episode number:  401\n",
      "reward till now:  -217.0\n",
      "time step:  0\n",
      "episode number:  401\n",
      "reward till now:  -217.0\n",
      "time step:  1\n",
      "episode number:  401\n",
      "reward till now:  -217.0\n",
      "time step:  2\n",
      "episode number:  401\n",
      "reward till now:  -217.0\n",
      "time step:  3\n",
      "episode number:  401\n",
      "reward till now:  -218.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 402 reward -218.00, Last 30ep Avg. rewards -218.00.\n",
      "episode number:  402\n",
      "reward till now:  -218.0\n",
      "time step:  0\n",
      "episode number:  402\n",
      "reward till now:  -218.0\n",
      "time step:  1\n",
      "episode number:  402\n",
      "reward till now:  -218.0\n",
      "time step:  2\n",
      "episode number:  402\n",
      "reward till now:  -218.0\n",
      "time step:  3\n",
      "episode number:  402\n",
      "reward till now:  -219.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 403 reward -219.00, Last 30ep Avg. rewards -219.00.\n",
      "episode number:  403\n",
      "reward till now:  -219.0\n",
      "time step:  0\n",
      "episode number:  403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -219.0\n",
      "time step:  1\n",
      "episode number:  403\n",
      "reward till now:  -219.0\n",
      "time step:  2\n",
      "episode number:  403\n",
      "reward till now:  -219.0\n",
      "time step:  3\n",
      "episode number:  403\n",
      "reward till now:  -220.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 404 reward -220.00, Last 30ep Avg. rewards -220.00.\n",
      "episode number:  404\n",
      "reward till now:  -220.0\n",
      "time step:  0\n",
      "episode number:  404\n",
      "reward till now:  -220.0\n",
      "time step:  1\n",
      "episode number:  404\n",
      "reward till now:  -220.0\n",
      "time step:  2\n",
      "episode number:  404\n",
      "reward till now:  -220.0\n",
      "time step:  3\n",
      "episode number:  404\n",
      "reward till now:  -221.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 405 reward -221.00, Last 30ep Avg. rewards -221.00.\n",
      "episode number:  405\n",
      "reward till now:  -221.0\n",
      "time step:  0\n",
      "episode number:  405\n",
      "reward till now:  -221.0\n",
      "time step:  1\n",
      "episode number:  405\n",
      "reward till now:  -221.0\n",
      "time step:  2\n",
      "episode number:  405\n",
      "reward till now:  -221.0\n",
      "time step:  3\n",
      "episode number:  405\n",
      "reward till now:  -222.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 406 reward -222.00, Last 30ep Avg. rewards -222.00.\n",
      "episode number:  406\n",
      "reward till now:  -222.0\n",
      "time step:  0\n",
      "episode number:  406\n",
      "reward till now:  -222.0\n",
      "time step:  1\n",
      "episode number:  406\n",
      "reward till now:  -222.0\n",
      "time step:  2\n",
      "episode number:  406\n",
      "reward till now:  -222.0\n",
      "time step:  3\n",
      "episode number:  406\n",
      "reward till now:  -223.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 407 reward -223.00, Last 30ep Avg. rewards -223.00.\n",
      "episode number:  407\n",
      "reward till now:  -223.0\n",
      "time step:  0\n",
      "episode number:  407\n",
      "reward till now:  -223.0\n",
      "time step:  1\n",
      "episode number:  407\n",
      "reward till now:  -223.0\n",
      "time step:  2\n",
      "episode number:  407\n",
      "reward till now:  -223.0\n",
      "time step:  3\n",
      "episode number:  407\n",
      "reward till now:  -224.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 408 reward -224.00, Last 30ep Avg. rewards -224.00.\n",
      "episode number:  408\n",
      "reward till now:  -224.0\n",
      "time step:  0\n",
      "episode number:  408\n",
      "reward till now:  -224.0\n",
      "time step:  1\n",
      "episode number:  408\n",
      "reward till now:  -224.0\n",
      "time step:  2\n",
      "episode number:  408\n",
      "reward till now:  -224.0\n",
      "time step:  3\n",
      "episode number:  408\n",
      "reward till now:  -225.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 409 reward -225.00, Last 30ep Avg. rewards -225.00.\n",
      "episode number:  409\n",
      "reward till now:  -225.0\n",
      "time step:  0\n",
      "episode number:  409\n",
      "reward till now:  -225.0\n",
      "time step:  1\n",
      "episode number:  409\n",
      "reward till now:  -225.0\n",
      "time step:  2\n",
      "episode number:  409\n",
      "reward till now:  -225.0\n",
      "time step:  3\n",
      "episode number:  409\n",
      "reward till now:  -226.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 410 reward -226.00, Last 30ep Avg. rewards -226.00.\n",
      "episode number:  410\n",
      "reward till now:  -226.0\n",
      "time step:  0\n",
      "episode number:  410\n",
      "reward till now:  -226.0\n",
      "time step:  1\n",
      "episode number:  410\n",
      "reward till now:  -226.0\n",
      "time step:  2\n",
      "episode number:  410\n",
      "reward till now:  -226.0\n",
      "time step:  3\n",
      "episode number:  410\n",
      "reward till now:  -227.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 411 reward -227.00, Last 30ep Avg. rewards -227.00.\n",
      "episode number:  411\n",
      "reward till now:  -227.0\n",
      "time step:  0\n",
      "episode number:  411\n",
      "reward till now:  -227.0\n",
      "time step:  1\n",
      "episode number:  411\n",
      "reward till now:  -227.0\n",
      "time step:  2\n",
      "episode number:  411\n",
      "reward till now:  -227.0\n",
      "time step:  3\n",
      "episode number:  411\n",
      "reward till now:  -228.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 412 reward -228.00, Last 30ep Avg. rewards -228.00.\n",
      "episode number:  412\n",
      "reward till now:  -228.0\n",
      "time step:  0\n",
      "episode number:  412\n",
      "reward till now:  -228.0\n",
      "time step:  1\n",
      "episode number:  412\n",
      "reward till now:  -228.0\n",
      "time step:  2\n",
      "episode number:  412\n",
      "reward till now:  -228.0\n",
      "time step:  3\n",
      "episode number:  412\n",
      "reward till now:  -229.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 413 reward -229.00, Last 30ep Avg. rewards -229.00.\n",
      "episode number:  413\n",
      "reward till now:  -229.0\n",
      "time step:  0\n",
      "episode number:  413\n",
      "reward till now:  -229.0\n",
      "time step:  1\n",
      "episode number:  413\n",
      "reward till now:  -229.0\n",
      "time step:  2\n",
      "episode number:  413\n",
      "reward till now:  -229.0\n",
      "time step:  3\n",
      "episode number:  413\n",
      "reward till now:  -230.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 414 reward -230.00, Last 30ep Avg. rewards -230.00.\n",
      "episode number:  414\n",
      "reward till now:  -230.0\n",
      "time step:  0\n",
      "episode number:  414\n",
      "reward till now:  -230.0\n",
      "time step:  1\n",
      "episode number:  414\n",
      "reward till now:  -230.0\n",
      "time step:  2\n",
      "episode number:  414\n",
      "reward till now:  -230.0\n",
      "time step:  3\n",
      "episode number:  414\n",
      "reward till now:  -231.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 415 reward -231.00, Last 30ep Avg. rewards -231.00.\n",
      "episode number:  415\n",
      "reward till now:  -231.0\n",
      "time step:  0\n",
      "episode number:  415\n",
      "reward till now:  -231.0\n",
      "time step:  1\n",
      "episode number:  415\n",
      "reward till now:  -231.0\n",
      "time step:  2\n",
      "episode number:  415\n",
      "reward till now:  -231.0\n",
      "time step:  3\n",
      "episode number:  415\n",
      "reward till now:  -232.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 416 reward -232.00, Last 30ep Avg. rewards -232.00.\n",
      "episode number:  416\n",
      "reward till now:  -232.0\n",
      "time step:  0\n",
      "episode number:  416\n",
      "reward till now:  -232.0\n",
      "time step:  1\n",
      "episode number:  416\n",
      "reward till now:  -232.0\n",
      "time step:  2\n",
      "episode number:  416\n",
      "reward till now:  -232.0\n",
      "time step:  3\n",
      "episode number:  416\n",
      "reward till now:  -233.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 417 reward -233.00, Last 30ep Avg. rewards -233.00.\n",
      "episode number:  417\n",
      "reward till now:  -233.0\n",
      "time step:  0\n",
      "episode number:  417\n",
      "reward till now:  -233.0\n",
      "time step:  1\n",
      "episode number:  417\n",
      "reward till now:  -233.0\n",
      "time step:  2\n",
      "episode number:  417\n",
      "reward till now:  -233.0\n",
      "time step:  3\n",
      "episode number:  417\n",
      "reward till now:  -234.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 418 reward -234.00, Last 30ep Avg. rewards -234.00.\n",
      "episode number:  418\n",
      "reward till now:  -234.0\n",
      "time step:  0\n",
      "episode number:  418\n",
      "reward till now:  -234.0\n",
      "time step:  1\n",
      "episode number:  418\n",
      "reward till now:  -234.0\n",
      "time step:  2\n",
      "episode number:  418\n",
      "reward till now:  -234.0\n",
      "time step:  3\n",
      "episode number:  418\n",
      "reward till now:  -235.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 419 reward -235.00, Last 30ep Avg. rewards -235.00.\n",
      "episode number:  419\n",
      "reward till now:  -235.0\n",
      "time step:  0\n",
      "episode number:  419\n",
      "reward till now:  -235.0\n",
      "time step:  1\n",
      "episode number:  419\n",
      "reward till now:  -235.0\n",
      "time step:  2\n",
      "episode number:  419\n",
      "reward till now:  -235.0\n",
      "time step:  3\n",
      "episode number:  419\n",
      "reward till now:  -236.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 420 reward -236.00, Last 30ep Avg. rewards -236.00.\n",
      "episode number:  420\n",
      "reward till now:  -236.0\n",
      "time step:  0\n",
      "episode number:  420\n",
      "reward till now:  -236.0\n",
      "time step:  1\n",
      "episode number:  420\n",
      "reward till now:  -236.0\n",
      "time step:  2\n",
      "episode number:  420\n",
      "reward till now:  -236.0\n",
      "time step:  3\n",
      "episode number:  420\n",
      "reward till now:  -237.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 421 reward -237.00, Last 30ep Avg. rewards -237.00.\n",
      "episode number:  421\n",
      "reward till now:  -237.0\n",
      "time step:  0\n",
      "episode number:  421\n",
      "reward till now:  -237.0\n",
      "time step:  1\n",
      "episode number:  421\n",
      "reward till now:  -237.0\n",
      "time step:  2\n",
      "episode number:  421\n",
      "reward till now:  -237.0\n",
      "time step:  3\n",
      "episode number:  421\n",
      "reward till now:  -238.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 422 reward -238.00, Last 30ep Avg. rewards -238.00.\n",
      "episode number:  422\n",
      "reward till now:  -238.0\n",
      "time step:  0\n",
      "episode number:  422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -238.0\n",
      "time step:  1\n",
      "episode number:  422\n",
      "reward till now:  -238.0\n",
      "time step:  2\n",
      "episode number:  422\n",
      "reward till now:  -238.0\n",
      "time step:  3\n",
      "episode number:  422\n",
      "reward till now:  -239.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 423 reward -239.00, Last 30ep Avg. rewards -239.00.\n",
      "episode number:  423\n",
      "reward till now:  -239.0\n",
      "time step:  0\n",
      "episode number:  423\n",
      "reward till now:  -239.0\n",
      "time step:  1\n",
      "episode number:  423\n",
      "reward till now:  -239.0\n",
      "time step:  2\n",
      "episode number:  423\n",
      "reward till now:  -239.0\n",
      "time step:  3\n",
      "episode number:  423\n",
      "reward till now:  -240.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 424 reward -240.00, Last 30ep Avg. rewards -240.00.\n",
      "episode number:  424\n",
      "reward till now:  -240.0\n",
      "time step:  0\n",
      "episode number:  424\n",
      "reward till now:  -240.0\n",
      "time step:  1\n",
      "episode number:  424\n",
      "reward till now:  -240.0\n",
      "time step:  2\n",
      "episode number:  424\n",
      "reward till now:  -240.0\n",
      "time step:  3\n",
      "episode number:  424\n",
      "reward till now:  -241.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 425 reward -241.00, Last 30ep Avg. rewards -241.00.\n",
      "episode number:  425\n",
      "reward till now:  -241.0\n",
      "time step:  0\n",
      "episode number:  425\n",
      "reward till now:  -241.0\n",
      "time step:  1\n",
      "episode number:  425\n",
      "reward till now:  -241.0\n",
      "time step:  2\n",
      "episode number:  425\n",
      "reward till now:  -241.0\n",
      "time step:  3\n",
      "episode number:  425\n",
      "reward till now:  -242.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 426 reward -242.00, Last 30ep Avg. rewards -242.00.\n",
      "episode number:  426\n",
      "reward till now:  -242.0\n",
      "time step:  0\n",
      "episode number:  426\n",
      "reward till now:  -242.0\n",
      "time step:  1\n",
      "episode number:  426\n",
      "reward till now:  -242.0\n",
      "time step:  2\n",
      "episode number:  426\n",
      "reward till now:  -242.0\n",
      "time step:  3\n",
      "episode number:  426\n",
      "reward till now:  -243.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 427 reward -243.00, Last 30ep Avg. rewards -243.00.\n",
      "episode number:  427\n",
      "reward till now:  -243.0\n",
      "time step:  0\n",
      "episode number:  427\n",
      "reward till now:  -243.0\n",
      "time step:  1\n",
      "episode number:  427\n",
      "reward till now:  -243.0\n",
      "time step:  2\n",
      "episode number:  427\n",
      "reward till now:  -243.0\n",
      "time step:  3\n",
      "episode number:  427\n",
      "reward till now:  -244.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 428 reward -244.00, Last 30ep Avg. rewards -244.00.\n",
      "episode number:  428\n",
      "reward till now:  -244.0\n",
      "time step:  0\n",
      "episode number:  428\n",
      "reward till now:  -244.0\n",
      "time step:  1\n",
      "episode number:  428\n",
      "reward till now:  -244.0\n",
      "time step:  2\n",
      "episode number:  428\n",
      "reward till now:  -244.0\n",
      "time step:  3\n",
      "episode number:  428\n",
      "reward till now:  -245.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 429 reward -245.00, Last 30ep Avg. rewards -245.00.\n",
      "episode number:  429\n",
      "reward till now:  -245.0\n",
      "time step:  0\n",
      "episode number:  429\n",
      "reward till now:  -245.0\n",
      "time step:  1\n",
      "episode number:  429\n",
      "reward till now:  -245.0\n",
      "time step:  2\n",
      "episode number:  429\n",
      "reward till now:  -245.0\n",
      "time step:  3\n",
      "episode number:  429\n",
      "reward till now:  -246.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 430 reward -246.00, Last 30ep Avg. rewards -246.00.\n",
      "episode number:  430\n",
      "reward till now:  -246.0\n",
      "time step:  0\n",
      "episode number:  430\n",
      "reward till now:  -246.0\n",
      "time step:  1\n",
      "episode number:  430\n",
      "reward till now:  -246.0\n",
      "time step:  2\n",
      "episode number:  430\n",
      "reward till now:  -246.0\n",
      "time step:  3\n",
      "episode number:  430\n",
      "reward till now:  -247.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 431 reward -247.00, Last 30ep Avg. rewards -247.00.\n",
      "episode number:  431\n",
      "reward till now:  -247.0\n",
      "time step:  0\n",
      "episode number:  431\n",
      "reward till now:  -247.0\n",
      "time step:  1\n",
      "episode number:  431\n",
      "reward till now:  -247.0\n",
      "time step:  2\n",
      "episode number:  431\n",
      "reward till now:  -247.0\n",
      "time step:  3\n",
      "episode number:  431\n",
      "reward till now:  -248.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 432 reward -248.00, Last 30ep Avg. rewards -248.00.\n",
      "episode number:  432\n",
      "reward till now:  -248.0\n",
      "time step:  0\n",
      "episode number:  432\n",
      "reward till now:  -248.0\n",
      "time step:  1\n",
      "episode number:  432\n",
      "reward till now:  -248.0\n",
      "time step:  2\n",
      "episode number:  432\n",
      "reward till now:  -248.0\n",
      "time step:  3\n",
      "episode number:  432\n",
      "reward till now:  -249.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 433 reward -249.00, Last 30ep Avg. rewards -249.00.\n",
      "episode number:  433\n",
      "reward till now:  -249.0\n",
      "time step:  0\n",
      "episode number:  433\n",
      "reward till now:  -249.0\n",
      "time step:  1\n",
      "episode number:  433\n",
      "reward till now:  -249.0\n",
      "time step:  2\n",
      "episode number:  433\n",
      "reward till now:  -249.0\n",
      "time step:  3\n",
      "episode number:  433\n",
      "reward till now:  -250.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 434 reward -250.00, Last 30ep Avg. rewards -250.00.\n",
      "episode number:  434\n",
      "reward till now:  -250.0\n",
      "time step:  0\n",
      "episode number:  434\n",
      "reward till now:  -250.0\n",
      "time step:  1\n",
      "episode number:  434\n",
      "reward till now:  -250.0\n",
      "time step:  2\n",
      "episode number:  434\n",
      "reward till now:  -250.0\n",
      "time step:  3\n",
      "episode number:  434\n",
      "reward till now:  -251.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 435 reward -251.00, Last 30ep Avg. rewards -251.00.\n",
      "episode number:  435\n",
      "reward till now:  -251.0\n",
      "time step:  0\n",
      "episode number:  435\n",
      "reward till now:  -251.0\n",
      "time step:  1\n",
      "episode number:  435\n",
      "reward till now:  -251.0\n",
      "time step:  2\n",
      "episode number:  435\n",
      "reward till now:  -251.0\n",
      "time step:  3\n",
      "episode number:  435\n",
      "reward till now:  -252.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 436 reward -252.00, Last 30ep Avg. rewards -252.00.\n",
      "episode number:  436\n",
      "reward till now:  -252.0\n",
      "time step:  0\n",
      "episode number:  436\n",
      "reward till now:  -252.0\n",
      "time step:  1\n",
      "episode number:  436\n",
      "reward till now:  -252.0\n",
      "time step:  2\n",
      "episode number:  436\n",
      "reward till now:  -252.0\n",
      "time step:  3\n",
      "episode number:  436\n",
      "reward till now:  -253.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 437 reward -253.00, Last 30ep Avg. rewards -253.00.\n",
      "episode number:  437\n",
      "reward till now:  -253.0\n",
      "time step:  0\n",
      "episode number:  437\n",
      "reward till now:  -253.0\n",
      "time step:  1\n",
      "episode number:  437\n",
      "reward till now:  -253.0\n",
      "time step:  2\n",
      "episode number:  437\n",
      "reward till now:  -253.0\n",
      "time step:  3\n",
      "episode number:  437\n",
      "reward till now:  -254.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 438 reward -254.00, Last 30ep Avg. rewards -254.00.\n",
      "episode number:  438\n",
      "reward till now:  -254.0\n",
      "time step:  0\n",
      "episode number:  438\n",
      "reward till now:  -254.0\n",
      "time step:  1\n",
      "episode number:  438\n",
      "reward till now:  -254.0\n",
      "time step:  2\n",
      "episode number:  438\n",
      "reward till now:  -254.0\n",
      "time step:  3\n",
      "episode number:  438\n",
      "reward till now:  -255.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 439 reward -255.00, Last 30ep Avg. rewards -255.00.\n",
      "episode number:  439\n",
      "reward till now:  -255.0\n",
      "time step:  0\n",
      "episode number:  439\n",
      "reward till now:  -255.0\n",
      "time step:  1\n",
      "episode number:  439\n",
      "reward till now:  -255.0\n",
      "time step:  2\n",
      "episode number:  439\n",
      "reward till now:  -255.0\n",
      "time step:  3\n",
      "episode number:  439\n",
      "reward till now:  -256.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 440 reward -256.00, Last 30ep Avg. rewards -256.00.\n",
      "episode number:  440\n",
      "reward till now:  -255.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 441 reward -255.00, Last 30ep Avg. rewards -255.00.\n",
      "episode number:  441\n",
      "reward till now:  -254.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 442 reward -254.00, Last 30ep Avg. rewards -254.00.\n",
      "episode number:  442\n",
      "reward till now:  -253.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 443 reward -253.00, Last 30ep Avg. rewards -253.00.\n",
      "episode number:  443\n",
      "reward till now:  -252.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 444 reward -252.00, Last 30ep Avg. rewards -252.00.\n",
      "episode number:  444\n",
      "reward till now:  -251.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 445 reward -251.00, Last 30ep Avg. rewards -251.00.\n",
      "episode number:  445\n",
      "reward till now:  -250.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 446 reward -250.00, Last 30ep Avg. rewards -250.00.\n",
      "episode number:  446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -249.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 447 reward -249.00, Last 30ep Avg. rewards -249.00.\n",
      "episode number:  447\n",
      "reward till now:  -248.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 448 reward -248.00, Last 30ep Avg. rewards -248.00.\n",
      "episode number:  448\n",
      "reward till now:  -247.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 449 reward -247.00, Last 30ep Avg. rewards -247.00.\n",
      "episode number:  449\n",
      "reward till now:  -246.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 450 reward -246.00, Last 30ep Avg. rewards -246.00.\n",
      "episode number:  450\n",
      "reward till now:  -245.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 451 reward -245.00, Last 30ep Avg. rewards -245.00.\n",
      "episode number:  451\n",
      "reward till now:  -244.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 452 reward -244.00, Last 30ep Avg. rewards -244.00.\n",
      "episode number:  452\n",
      "reward till now:  -243.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 453 reward -243.00, Last 30ep Avg. rewards -243.00.\n",
      "episode number:  453\n",
      "reward till now:  -242.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 454 reward -242.00, Last 30ep Avg. rewards -242.00.\n",
      "episode number:  454\n",
      "reward till now:  -241.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 455 reward -241.00, Last 30ep Avg. rewards -241.00.\n",
      "episode number:  455\n",
      "reward till now:  -240.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 456 reward -240.00, Last 30ep Avg. rewards -240.00.\n",
      "episode number:  456\n",
      "reward till now:  -239.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 457 reward -239.00, Last 30ep Avg. rewards -239.00.\n",
      "episode number:  457\n",
      "reward till now:  -238.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 458 reward -238.00, Last 30ep Avg. rewards -238.00.\n",
      "episode number:  458\n",
      "reward till now:  -237.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 459 reward -237.00, Last 30ep Avg. rewards -237.00.\n",
      "episode number:  459\n",
      "reward till now:  -236.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 460 reward -236.00, Last 30ep Avg. rewards -236.00.\n",
      "episode number:  460\n",
      "reward till now:  -235.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 461 reward -235.00, Last 30ep Avg. rewards -235.00.\n",
      "episode number:  461\n",
      "reward till now:  -234.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 462 reward -234.00, Last 30ep Avg. rewards -234.00.\n",
      "episode number:  462\n",
      "reward till now:  -233.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 463 reward -233.00, Last 30ep Avg. rewards -233.00.\n",
      "episode number:  463\n",
      "reward till now:  -232.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 464 reward -232.00, Last 30ep Avg. rewards -232.00.\n",
      "episode number:  464\n",
      "reward till now:  -231.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 465 reward -231.00, Last 30ep Avg. rewards -231.00.\n",
      "episode number:  465\n",
      "reward till now:  -230.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 466 reward -230.00, Last 30ep Avg. rewards -230.00.\n",
      "episode number:  466\n",
      "reward till now:  -229.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 467 reward -229.00, Last 30ep Avg. rewards -229.00.\n",
      "episode number:  467\n",
      "reward till now:  -228.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 468 reward -228.00, Last 30ep Avg. rewards -228.00.\n",
      "episode number:  468\n",
      "reward till now:  -227.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 469 reward -227.00, Last 30ep Avg. rewards -227.00.\n",
      "episode number:  469\n",
      "reward till now:  -226.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 470 reward -226.00, Last 30ep Avg. rewards -226.00.\n",
      "episode number:  470\n",
      "reward till now:  -225.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 471 reward -225.00, Last 30ep Avg. rewards -225.00.\n",
      "episode number:  471\n",
      "reward till now:  -224.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 472 reward -224.00, Last 30ep Avg. rewards -224.00.\n",
      "episode number:  472\n",
      "reward till now:  -223.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 473 reward -223.00, Last 30ep Avg. rewards -223.00.\n",
      "episode number:  473\n",
      "reward till now:  -222.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 474 reward -222.00, Last 30ep Avg. rewards -222.00.\n",
      "episode number:  474\n",
      "reward till now:  -221.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 475 reward -221.00, Last 30ep Avg. rewards -221.00.\n",
      "episode number:  475\n",
      "reward till now:  -220.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 476 reward -220.00, Last 30ep Avg. rewards -220.00.\n",
      "episode number:  476\n",
      "reward till now:  -219.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 477 reward -219.00, Last 30ep Avg. rewards -219.00.\n",
      "episode number:  477\n",
      "reward till now:  -218.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 478 reward -218.00, Last 30ep Avg. rewards -218.00.\n",
      "episode number:  478\n",
      "reward till now:  -217.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 479 reward -217.00, Last 30ep Avg. rewards -217.00.\n",
      "episode number:  479\n",
      "reward till now:  -216.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 480 reward -216.00, Last 30ep Avg. rewards -216.00.\n",
      "episode number:  480\n",
      "reward till now:  -215.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 481 reward -215.00, Last 30ep Avg. rewards -215.00.\n",
      "episode number:  481\n",
      "reward till now:  -214.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 482 reward -214.00, Last 30ep Avg. rewards -214.00.\n",
      "episode number:  482\n",
      "reward till now:  -213.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 483 reward -213.00, Last 30ep Avg. rewards -213.00.\n",
      "episode number:  483\n",
      "reward till now:  -212.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 484 reward -212.00, Last 30ep Avg. rewards -212.00.\n",
      "episode number:  484\n",
      "reward till now:  -211.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 485 reward -211.00, Last 30ep Avg. rewards -211.00.\n",
      "episode number:  485\n",
      "reward till now:  -210.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 486 reward -210.00, Last 30ep Avg. rewards -210.00.\n",
      "episode number:  486\n",
      "reward till now:  -209.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 487 reward -209.00, Last 30ep Avg. rewards -209.00.\n",
      "episode number:  487\n",
      "reward till now:  -208.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 488 reward -208.00, Last 30ep Avg. rewards -208.00.\n",
      "episode number:  488\n",
      "reward till now:  -207.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 489 reward -207.00, Last 30ep Avg. rewards -207.00.\n",
      "episode number:  489\n",
      "reward till now:  -206.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 490 reward -206.00, Last 30ep Avg. rewards -206.00.\n",
      "episode number:  490\n",
      "reward till now:  -205.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 491 reward -205.00, Last 30ep Avg. rewards -205.00.\n",
      "episode number:  491\n",
      "reward till now:  -204.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 492 reward -204.00, Last 30ep Avg. rewards -204.00.\n",
      "episode number:  492\n",
      "reward till now:  -203.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 493 reward -203.00, Last 30ep Avg. rewards -203.00.\n",
      "episode number:  493\n",
      "reward till now:  -202.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 494 reward -202.00, Last 30ep Avg. rewards -202.00.\n",
      "episode number:  494\n",
      "reward till now:  -201.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 495 reward -201.00, Last 30ep Avg. rewards -201.00.\n",
      "episode number:  495\n",
      "reward till now:  -200.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 496 reward -200.00, Last 30ep Avg. rewards -200.00.\n",
      "episode number:  496\n",
      "reward till now:  -199.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 497 reward -199.00, Last 30ep Avg. rewards -199.00.\n",
      "episode number:  497\n",
      "reward till now:  -198.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 498 reward -198.00, Last 30ep Avg. rewards -198.00.\n",
      "episode number:  498\n",
      "reward till now:  -197.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 499 reward -197.00, Last 30ep Avg. rewards -197.00.\n",
      "episode number:  499\n",
      "reward till now:  -196.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 500 reward -196.00, Last 30ep Avg. rewards -196.00.\n",
      "episode number:  500\n",
      "reward till now:  -195.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 501 reward -195.00, Last 30ep Avg. rewards -195.00.\n",
      "episode number:  501\n",
      "reward till now:  -194.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 502 reward -194.00, Last 30ep Avg. rewards -194.00.\n",
      "episode number:  502\n",
      "reward till now:  -193.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 503 reward -193.00, Last 30ep Avg. rewards -193.00.\n",
      "episode number:  503\n",
      "reward till now:  -192.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 504 reward -192.00, Last 30ep Avg. rewards -192.00.\n",
      "episode number:  504\n",
      "reward till now:  -191.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 505 reward -191.00, Last 30ep Avg. rewards -191.00.\n",
      "episode number:  505\n",
      "reward till now:  -190.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 506 reward -190.00, Last 30ep Avg. rewards -190.00.\n",
      "episode number:  506\n",
      "reward till now:  -189.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 507 reward -189.00, Last 30ep Avg. rewards -189.00.\n",
      "episode number:  507\n",
      "reward till now:  -188.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 508 reward -188.00, Last 30ep Avg. rewards -188.00.\n",
      "episode number:  508\n",
      "reward till now:  -187.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 509 reward -187.00, Last 30ep Avg. rewards -187.00.\n",
      "episode number:  509\n",
      "reward till now:  -186.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 510 reward -186.00, Last 30ep Avg. rewards -186.00.\n",
      "episode number:  510\n",
      "reward till now:  -185.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 511 reward -185.00, Last 30ep Avg. rewards -185.00.\n",
      "episode number:  511\n",
      "reward till now:  -184.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 512 reward -184.00, Last 30ep Avg. rewards -184.00.\n",
      "episode number:  512\n",
      "reward till now:  -183.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 513 reward -183.00, Last 30ep Avg. rewards -183.00.\n",
      "episode number:  513\n",
      "reward till now:  -182.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 514 reward -182.00, Last 30ep Avg. rewards -182.00.\n",
      "episode number:  514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -181.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 515 reward -181.00, Last 30ep Avg. rewards -181.00.\n",
      "episode number:  515\n",
      "reward till now:  -180.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 516 reward -180.00, Last 30ep Avg. rewards -180.00.\n",
      "episode number:  516\n",
      "reward till now:  -179.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 517 reward -179.00, Last 30ep Avg. rewards -179.00.\n",
      "episode number:  517\n",
      "reward till now:  -178.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 518 reward -178.00, Last 30ep Avg. rewards -178.00.\n",
      "episode number:  518\n",
      "reward till now:  -177.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 519 reward -177.00, Last 30ep Avg. rewards -177.00.\n",
      "episode number:  519\n",
      "reward till now:  -176.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 520 reward -176.00, Last 30ep Avg. rewards -176.00.\n",
      "episode number:  520\n",
      "reward till now:  -176.0\n",
      "time step:  0\n",
      "episode number:  520\n",
      "reward till now:  -176.0\n",
      "time step:  1\n",
      "episode number:  520\n",
      "reward till now:  -176.0\n",
      "time step:  2\n",
      "episode number:  520\n",
      "reward till now:  -176.0\n",
      "time step:  3\n",
      "episode number:  520\n",
      "reward till now:  -177.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 521 reward -177.00, Last 30ep Avg. rewards -177.00.\n",
      "episode number:  521\n",
      "reward till now:  -177.0\n",
      "time step:  0\n",
      "episode number:  521\n",
      "reward till now:  -177.0\n",
      "time step:  1\n",
      "episode number:  521\n",
      "reward till now:  -177.0\n",
      "time step:  2\n",
      "episode number:  521\n",
      "reward till now:  -177.0\n",
      "time step:  3\n",
      "episode number:  521\n",
      "reward till now:  -178.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 522 reward -178.00, Last 30ep Avg. rewards -178.00.\n",
      "episode number:  522\n",
      "reward till now:  -178.0\n",
      "time step:  0\n",
      "episode number:  522\n",
      "reward till now:  -178.0\n",
      "time step:  1\n",
      "episode number:  522\n",
      "reward till now:  -178.0\n",
      "time step:  2\n",
      "episode number:  522\n",
      "reward till now:  -178.0\n",
      "time step:  3\n",
      "episode number:  522\n",
      "reward till now:  -179.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 523 reward -179.00, Last 30ep Avg. rewards -179.00.\n",
      "episode number:  523\n",
      "reward till now:  -179.0\n",
      "time step:  0\n",
      "episode number:  523\n",
      "reward till now:  -179.0\n",
      "time step:  1\n",
      "episode number:  523\n",
      "reward till now:  -179.0\n",
      "time step:  2\n",
      "episode number:  523\n",
      "reward till now:  -179.0\n",
      "time step:  3\n",
      "episode number:  523\n",
      "reward till now:  -180.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 524 reward -180.00, Last 30ep Avg. rewards -180.00.\n",
      "episode number:  524\n",
      "reward till now:  -180.0\n",
      "time step:  0\n",
      "episode number:  524\n",
      "reward till now:  -180.0\n",
      "time step:  1\n",
      "episode number:  524\n",
      "reward till now:  -180.0\n",
      "time step:  2\n",
      "episode number:  524\n",
      "reward till now:  -180.0\n",
      "time step:  3\n",
      "episode number:  524\n",
      "reward till now:  -181.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 525 reward -181.00, Last 30ep Avg. rewards -181.00.\n",
      "episode number:  525\n",
      "reward till now:  -181.0\n",
      "time step:  0\n",
      "episode number:  525\n",
      "reward till now:  -181.0\n",
      "time step:  1\n",
      "episode number:  525\n",
      "reward till now:  -181.0\n",
      "time step:  2\n",
      "episode number:  525\n",
      "reward till now:  -181.0\n",
      "time step:  3\n",
      "episode number:  525\n",
      "reward till now:  -182.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 526 reward -182.00, Last 30ep Avg. rewards -182.00.\n",
      "episode number:  526\n",
      "reward till now:  -182.0\n",
      "time step:  0\n",
      "episode number:  526\n",
      "reward till now:  -182.0\n",
      "time step:  1\n",
      "episode number:  526\n",
      "reward till now:  -182.0\n",
      "time step:  2\n",
      "episode number:  526\n",
      "reward till now:  -182.0\n",
      "time step:  3\n",
      "episode number:  526\n",
      "reward till now:  -183.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 527 reward -183.00, Last 30ep Avg. rewards -183.00.\n",
      "episode number:  527\n",
      "reward till now:  -183.0\n",
      "time step:  0\n",
      "episode number:  527\n",
      "reward till now:  -183.0\n",
      "time step:  1\n",
      "episode number:  527\n",
      "reward till now:  -183.0\n",
      "time step:  2\n",
      "episode number:  527\n",
      "reward till now:  -183.0\n",
      "time step:  3\n",
      "episode number:  527\n",
      "reward till now:  -184.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 528 reward -184.00, Last 30ep Avg. rewards -184.00.\n",
      "episode number:  528\n",
      "reward till now:  -184.0\n",
      "time step:  0\n",
      "episode number:  528\n",
      "reward till now:  -184.0\n",
      "time step:  1\n",
      "episode number:  528\n",
      "reward till now:  -184.0\n",
      "time step:  2\n",
      "episode number:  528\n",
      "reward till now:  -184.0\n",
      "time step:  3\n",
      "episode number:  528\n",
      "reward till now:  -185.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 529 reward -185.00, Last 30ep Avg. rewards -185.00.\n",
      "episode number:  529\n",
      "reward till now:  -185.0\n",
      "time step:  0\n",
      "episode number:  529\n",
      "reward till now:  -185.0\n",
      "time step:  1\n",
      "episode number:  529\n",
      "reward till now:  -185.0\n",
      "time step:  2\n",
      "episode number:  529\n",
      "reward till now:  -185.0\n",
      "time step:  3\n",
      "episode number:  529\n",
      "reward till now:  -186.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 530 reward -186.00, Last 30ep Avg. rewards -186.00.\n",
      "episode number:  530\n",
      "reward till now:  -186.0\n",
      "time step:  0\n",
      "episode number:  530\n",
      "reward till now:  -186.0\n",
      "time step:  1\n",
      "episode number:  530\n",
      "reward till now:  -186.0\n",
      "time step:  2\n",
      "episode number:  530\n",
      "reward till now:  -186.0\n",
      "time step:  3\n",
      "episode number:  530\n",
      "reward till now:  -187.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 531 reward -187.00, Last 30ep Avg. rewards -187.00.\n",
      "episode number:  531\n",
      "reward till now:  -187.0\n",
      "time step:  0\n",
      "episode number:  531\n",
      "reward till now:  -187.0\n",
      "time step:  1\n",
      "episode number:  531\n",
      "reward till now:  -187.0\n",
      "time step:  2\n",
      "episode number:  531\n",
      "reward till now:  -187.0\n",
      "time step:  3\n",
      "episode number:  531\n",
      "reward till now:  -188.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 532 reward -188.00, Last 30ep Avg. rewards -188.00.\n",
      "episode number:  532\n",
      "reward till now:  -188.0\n",
      "time step:  0\n",
      "episode number:  532\n",
      "reward till now:  -188.0\n",
      "time step:  1\n",
      "episode number:  532\n",
      "reward till now:  -188.0\n",
      "time step:  2\n",
      "episode number:  532\n",
      "reward till now:  -188.0\n",
      "time step:  3\n",
      "episode number:  532\n",
      "reward till now:  -189.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 533 reward -189.00, Last 30ep Avg. rewards -189.00.\n",
      "episode number:  533\n",
      "reward till now:  -189.0\n",
      "time step:  0\n",
      "episode number:  533\n",
      "reward till now:  -189.0\n",
      "time step:  1\n",
      "episode number:  533\n",
      "reward till now:  -189.0\n",
      "time step:  2\n",
      "episode number:  533\n",
      "reward till now:  -189.0\n",
      "time step:  3\n",
      "episode number:  533\n",
      "reward till now:  -190.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 534 reward -190.00, Last 30ep Avg. rewards -190.00.\n",
      "episode number:  534\n",
      "reward till now:  -190.0\n",
      "time step:  0\n",
      "episode number:  534\n",
      "reward till now:  -190.0\n",
      "time step:  1\n",
      "episode number:  534\n",
      "reward till now:  -190.0\n",
      "time step:  2\n",
      "episode number:  534\n",
      "reward till now:  -190.0\n",
      "time step:  3\n",
      "episode number:  534\n",
      "reward till now:  -191.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 535 reward -191.00, Last 30ep Avg. rewards -191.00.\n",
      "episode number:  535\n",
      "reward till now:  -191.0\n",
      "time step:  0\n",
      "episode number:  535\n",
      "reward till now:  -191.0\n",
      "time step:  1\n",
      "episode number:  535\n",
      "reward till now:  -191.0\n",
      "time step:  2\n",
      "episode number:  535\n",
      "reward till now:  -191.0\n",
      "time step:  3\n",
      "episode number:  535\n",
      "reward till now:  -192.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 536 reward -192.00, Last 30ep Avg. rewards -192.00.\n",
      "episode number:  536\n",
      "reward till now:  -192.0\n",
      "time step:  0\n",
      "episode number:  536\n",
      "reward till now:  -192.0\n",
      "time step:  1\n",
      "episode number:  536\n",
      "reward till now:  -192.0\n",
      "time step:  2\n",
      "episode number:  536\n",
      "reward till now:  -192.0\n",
      "time step:  3\n",
      "episode number:  536\n",
      "reward till now:  -193.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 537 reward -193.00, Last 30ep Avg. rewards -193.00.\n",
      "episode number:  537\n",
      "reward till now:  -193.0\n",
      "time step:  0\n",
      "episode number:  537\n",
      "reward till now:  -193.0\n",
      "time step:  1\n",
      "episode number:  537\n",
      "reward till now:  -193.0\n",
      "time step:  2\n",
      "episode number:  537\n",
      "reward till now:  -193.0\n",
      "time step:  3\n",
      "episode number:  537\n",
      "reward till now:  -194.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 538 reward -194.00, Last 30ep Avg. rewards -194.00.\n",
      "episode number:  538\n",
      "reward till now:  -194.0\n",
      "time step:  0\n",
      "episode number:  538\n",
      "reward till now:  -194.0\n",
      "time step:  1\n",
      "episode number:  538\n",
      "reward till now:  -194.0\n",
      "time step:  2\n",
      "episode number:  538\n",
      "reward till now:  -194.0\n",
      "time step:  3\n",
      "episode number:  538\n",
      "reward till now:  -195.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 539 reward -195.00, Last 30ep Avg. rewards -195.00.\n",
      "episode number:  539\n",
      "reward till now:  -195.0\n",
      "time step:  0\n",
      "episode number:  539\n",
      "reward till now:  -195.0\n",
      "time step:  1\n",
      "episode number:  539\n",
      "reward till now:  -195.0\n",
      "time step:  2\n",
      "episode number:  539\n",
      "reward till now:  -195.0\n",
      "time step:  3\n",
      "episode number:  539\n",
      "reward till now:  -196.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 540 reward -196.00, Last 30ep Avg. rewards -196.00.\n",
      "episode number:  540\n",
      "reward till now:  -196.0\n",
      "time step:  0\n",
      "episode number:  540\n",
      "reward till now:  -196.0\n",
      "time step:  1\n",
      "episode number:  540\n",
      "reward till now:  -196.0\n",
      "time step:  2\n",
      "episode number:  540\n",
      "reward till now:  -196.0\n",
      "time step:  3\n",
      "episode number:  540\n",
      "reward till now:  -197.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 541 reward -197.00, Last 30ep Avg. rewards -197.00.\n",
      "episode number:  541\n",
      "reward till now:  -197.0\n",
      "time step:  0\n",
      "episode number:  541\n",
      "reward till now:  -197.0\n",
      "time step:  1\n",
      "episode number:  541\n",
      "reward till now:  -197.0\n",
      "time step:  2\n",
      "episode number:  541\n",
      "reward till now:  -197.0\n",
      "time step:  3\n",
      "episode number:  541\n",
      "reward till now:  -198.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 542 reward -198.00, Last 30ep Avg. rewards -198.00.\n",
      "episode number:  542\n",
      "reward till now:  -198.0\n",
      "time step:  0\n",
      "episode number:  542\n",
      "reward till now:  -198.0\n",
      "time step:  1\n",
      "episode number:  542\n",
      "reward till now:  -198.0\n",
      "time step:  2\n",
      "episode number:  542\n",
      "reward till now:  -198.0\n",
      "time step:  3\n",
      "episode number:  542\n",
      "reward till now:  -199.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 543 reward -199.00, Last 30ep Avg. rewards -199.00.\n",
      "episode number:  543\n",
      "reward till now:  -199.0\n",
      "time step:  0\n",
      "episode number:  543\n",
      "reward till now:  -199.0\n",
      "time step:  1\n",
      "episode number:  543\n",
      "reward till now:  -199.0\n",
      "time step:  2\n",
      "episode number:  543\n",
      "reward till now:  -199.0\n",
      "time step:  3\n",
      "episode number:  543\n",
      "reward till now:  -200.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 544 reward -200.00, Last 30ep Avg. rewards -200.00.\n",
      "episode number:  544\n",
      "reward till now:  -200.0\n",
      "time step:  0\n",
      "episode number:  544\n",
      "reward till now:  -200.0\n",
      "time step:  1\n",
      "episode number:  544\n",
      "reward till now:  -200.0\n",
      "time step:  2\n",
      "episode number:  544\n",
      "reward till now:  -200.0\n",
      "time step:  3\n",
      "episode number:  544\n",
      "reward till now:  -201.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 545 reward -201.00, Last 30ep Avg. rewards -201.00.\n",
      "episode number:  545\n",
      "reward till now:  -201.0\n",
      "time step:  0\n",
      "episode number:  545\n",
      "reward till now:  -201.0\n",
      "time step:  1\n",
      "episode number:  545\n",
      "reward till now:  -201.0\n",
      "time step:  2\n",
      "episode number:  545\n",
      "reward till now:  -201.0\n",
      "time step:  3\n",
      "episode number:  545\n",
      "reward till now:  -202.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 546 reward -202.00, Last 30ep Avg. rewards -202.00.\n",
      "episode number:  546\n",
      "reward till now:  -202.0\n",
      "time step:  0\n",
      "episode number:  546\n",
      "reward till now:  -202.0\n",
      "time step:  1\n",
      "episode number:  546\n",
      "reward till now:  -202.0\n",
      "time step:  2\n",
      "episode number:  546\n",
      "reward till now:  -202.0\n",
      "time step:  3\n",
      "episode number:  546\n",
      "reward till now:  -203.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 547 reward -203.00, Last 30ep Avg. rewards -203.00.\n",
      "episode number:  547\n",
      "reward till now:  -203.0\n",
      "time step:  0\n",
      "episode number:  547\n",
      "reward till now:  -203.0\n",
      "time step:  1\n",
      "episode number:  547\n",
      "reward till now:  -203.0\n",
      "time step:  2\n",
      "episode number:  547\n",
      "reward till now:  -203.0\n",
      "time step:  3\n",
      "episode number:  547\n",
      "reward till now:  -204.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 548 reward -204.00, Last 30ep Avg. rewards -204.00.\n",
      "episode number:  548\n",
      "reward till now:  -204.0\n",
      "time step:  0\n",
      "episode number:  548\n",
      "reward till now:  -204.0\n",
      "time step:  1\n",
      "episode number:  548\n",
      "reward till now:  -204.0\n",
      "time step:  2\n",
      "episode number:  548\n",
      "reward till now:  -204.0\n",
      "time step:  3\n",
      "episode number:  548\n",
      "reward till now:  -205.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 549 reward -205.00, Last 30ep Avg. rewards -205.00.\n",
      "episode number:  549\n",
      "reward till now:  -205.0\n",
      "time step:  0\n",
      "episode number:  549\n",
      "reward till now:  -205.0\n",
      "time step:  1\n",
      "episode number:  549\n",
      "reward till now:  -205.0\n",
      "time step:  2\n",
      "episode number:  549\n",
      "reward till now:  -205.0\n",
      "time step:  3\n",
      "episode number:  549\n",
      "reward till now:  -206.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 550 reward -206.00, Last 30ep Avg. rewards -206.00.\n",
      "episode number:  550\n",
      "reward till now:  -206.0\n",
      "time step:  0\n",
      "episode number:  550\n",
      "reward till now:  -206.0\n",
      "time step:  1\n",
      "episode number:  550\n",
      "reward till now:  -206.0\n",
      "time step:  2\n",
      "episode number:  550\n",
      "reward till now:  -206.0\n",
      "time step:  3\n",
      "episode number:  550\n",
      "reward till now:  -207.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 551 reward -207.00, Last 30ep Avg. rewards -207.00.\n",
      "episode number:  551\n",
      "reward till now:  -207.0\n",
      "time step:  0\n",
      "episode number:  551\n",
      "reward till now:  -207.0\n",
      "time step:  1\n",
      "episode number:  551\n",
      "reward till now:  -207.0\n",
      "time step:  2\n",
      "episode number:  551\n",
      "reward till now:  -207.0\n",
      "time step:  3\n",
      "episode number:  551\n",
      "reward till now:  -208.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 552 reward -208.00, Last 30ep Avg. rewards -208.00.\n",
      "episode number:  552\n",
      "reward till now:  -208.0\n",
      "time step:  0\n",
      "episode number:  552\n",
      "reward till now:  -208.0\n",
      "time step:  1\n",
      "episode number:  552\n",
      "reward till now:  -208.0\n",
      "time step:  2\n",
      "episode number:  552\n",
      "reward till now:  -208.0\n",
      "time step:  3\n",
      "episode number:  552\n",
      "reward till now:  -209.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 553 reward -209.00, Last 30ep Avg. rewards -209.00.\n",
      "episode number:  553\n",
      "reward till now:  -209.0\n",
      "time step:  0\n",
      "episode number:  553\n",
      "reward till now:  -209.0\n",
      "time step:  1\n",
      "episode number:  553\n",
      "reward till now:  -209.0\n",
      "time step:  2\n",
      "episode number:  553\n",
      "reward till now:  -209.0\n",
      "time step:  3\n",
      "episode number:  553\n",
      "reward till now:  -210.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 554 reward -210.00, Last 30ep Avg. rewards -210.00.\n",
      "episode number:  554\n",
      "reward till now:  -210.0\n",
      "time step:  0\n",
      "episode number:  554\n",
      "reward till now:  -210.0\n",
      "time step:  1\n",
      "episode number:  554\n",
      "reward till now:  -210.0\n",
      "time step:  2\n",
      "episode number:  554\n",
      "reward till now:  -210.0\n",
      "time step:  3\n",
      "episode number:  554\n",
      "reward till now:  -211.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 555 reward -211.00, Last 30ep Avg. rewards -211.00.\n",
      "episode number:  555\n",
      "reward till now:  -211.0\n",
      "time step:  0\n",
      "episode number:  555\n",
      "reward till now:  -211.0\n",
      "time step:  1\n",
      "episode number:  555\n",
      "reward till now:  -211.0\n",
      "time step:  2\n",
      "episode number:  555\n",
      "reward till now:  -211.0\n",
      "time step:  3\n",
      "episode number:  555\n",
      "reward till now:  -212.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 556 reward -212.00, Last 30ep Avg. rewards -212.00.\n",
      "episode number:  556\n",
      "reward till now:  -212.0\n",
      "time step:  0\n",
      "episode number:  556\n",
      "reward till now:  -212.0\n",
      "time step:  1\n",
      "episode number:  556\n",
      "reward till now:  -212.0\n",
      "time step:  2\n",
      "episode number:  556\n",
      "reward till now:  -212.0\n",
      "time step:  3\n",
      "episode number:  556\n",
      "reward till now:  -213.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 557 reward -213.00, Last 30ep Avg. rewards -213.00.\n",
      "episode number:  557\n",
      "reward till now:  -213.0\n",
      "time step:  0\n",
      "episode number:  557\n",
      "reward till now:  -213.0\n",
      "time step:  1\n",
      "episode number:  557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -213.0\n",
      "time step:  2\n",
      "episode number:  557\n",
      "reward till now:  -213.0\n",
      "time step:  3\n",
      "episode number:  557\n",
      "reward till now:  -214.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 558 reward -214.00, Last 30ep Avg. rewards -214.00.\n",
      "episode number:  558\n",
      "reward till now:  -214.0\n",
      "time step:  0\n",
      "episode number:  558\n",
      "reward till now:  -214.0\n",
      "time step:  1\n",
      "episode number:  558\n",
      "reward till now:  -214.0\n",
      "time step:  2\n",
      "episode number:  558\n",
      "reward till now:  -214.0\n",
      "time step:  3\n",
      "episode number:  558\n",
      "reward till now:  -215.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 559 reward -215.00, Last 30ep Avg. rewards -215.00.\n",
      "episode number:  559\n",
      "reward till now:  -215.0\n",
      "time step:  0\n",
      "episode number:  559\n",
      "reward till now:  -215.0\n",
      "time step:  1\n",
      "episode number:  559\n",
      "reward till now:  -215.0\n",
      "time step:  2\n",
      "episode number:  559\n",
      "reward till now:  -215.0\n",
      "time step:  3\n",
      "episode number:  559\n",
      "reward till now:  -216.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 560 reward -216.00, Last 30ep Avg. rewards -216.00.\n",
      "episode number:  560\n",
      "reward till now:  -216.0\n",
      "time step:  0\n",
      "episode number:  560\n",
      "reward till now:  -216.0\n",
      "time step:  1\n",
      "episode number:  560\n",
      "reward till now:  -216.0\n",
      "time step:  2\n",
      "episode number:  560\n",
      "reward till now:  -216.0\n",
      "time step:  3\n",
      "episode number:  560\n",
      "reward till now:  -217.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 561 reward -217.00, Last 30ep Avg. rewards -217.00.\n",
      "episode number:  561\n",
      "reward till now:  -217.0\n",
      "time step:  0\n",
      "episode number:  561\n",
      "reward till now:  -217.0\n",
      "time step:  1\n",
      "episode number:  561\n",
      "reward till now:  -217.0\n",
      "time step:  2\n",
      "episode number:  561\n",
      "reward till now:  -217.0\n",
      "time step:  3\n",
      "episode number:  561\n",
      "reward till now:  -218.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 562 reward -218.00, Last 30ep Avg. rewards -218.00.\n",
      "episode number:  562\n",
      "reward till now:  -218.0\n",
      "time step:  0\n",
      "episode number:  562\n",
      "reward till now:  -218.0\n",
      "time step:  1\n",
      "episode number:  562\n",
      "reward till now:  -218.0\n",
      "time step:  2\n",
      "episode number:  562\n",
      "reward till now:  -218.0\n",
      "time step:  3\n",
      "episode number:  562\n",
      "reward till now:  -219.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 563 reward -219.00, Last 30ep Avg. rewards -219.00.\n",
      "episode number:  563\n",
      "reward till now:  -219.0\n",
      "time step:  0\n",
      "episode number:  563\n",
      "reward till now:  -219.0\n",
      "time step:  1\n",
      "episode number:  563\n",
      "reward till now:  -219.0\n",
      "time step:  2\n",
      "episode number:  563\n",
      "reward till now:  -219.0\n",
      "time step:  3\n",
      "episode number:  563\n",
      "reward till now:  -220.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 564 reward -220.00, Last 30ep Avg. rewards -220.00.\n",
      "episode number:  564\n",
      "reward till now:  -220.0\n",
      "time step:  0\n",
      "episode number:  564\n",
      "reward till now:  -220.0\n",
      "time step:  1\n",
      "episode number:  564\n",
      "reward till now:  -220.0\n",
      "time step:  2\n",
      "episode number:  564\n",
      "reward till now:  -220.0\n",
      "time step:  3\n",
      "episode number:  564\n",
      "reward till now:  -221.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 565 reward -221.00, Last 30ep Avg. rewards -221.00.\n",
      "episode number:  565\n",
      "reward till now:  -221.0\n",
      "time step:  0\n",
      "episode number:  565\n",
      "reward till now:  -221.0\n",
      "time step:  1\n",
      "episode number:  565\n",
      "reward till now:  -221.0\n",
      "time step:  2\n",
      "episode number:  565\n",
      "reward till now:  -221.0\n",
      "time step:  3\n",
      "episode number:  565\n",
      "reward till now:  -222.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 566 reward -222.00, Last 30ep Avg. rewards -222.00.\n",
      "episode number:  566\n",
      "reward till now:  -222.0\n",
      "time step:  0\n",
      "episode number:  566\n",
      "reward till now:  -222.0\n",
      "time step:  1\n",
      "episode number:  566\n",
      "reward till now:  -222.0\n",
      "time step:  2\n",
      "episode number:  566\n",
      "reward till now:  -222.0\n",
      "time step:  3\n",
      "episode number:  566\n",
      "reward till now:  -223.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 567 reward -223.00, Last 30ep Avg. rewards -223.00.\n",
      "episode number:  567\n",
      "reward till now:  -223.0\n",
      "time step:  0\n",
      "episode number:  567\n",
      "reward till now:  -223.0\n",
      "time step:  1\n",
      "episode number:  567\n",
      "reward till now:  -223.0\n",
      "time step:  2\n",
      "episode number:  567\n",
      "reward till now:  -223.0\n",
      "time step:  3\n",
      "episode number:  567\n",
      "reward till now:  -224.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 568 reward -224.00, Last 30ep Avg. rewards -224.00.\n",
      "episode number:  568\n",
      "reward till now:  -224.0\n",
      "time step:  0\n",
      "episode number:  568\n",
      "reward till now:  -224.0\n",
      "time step:  1\n",
      "episode number:  568\n",
      "reward till now:  -224.0\n",
      "time step:  2\n",
      "episode number:  568\n",
      "reward till now:  -224.0\n",
      "time step:  3\n",
      "episode number:  568\n",
      "reward till now:  -225.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 569 reward -225.00, Last 30ep Avg. rewards -225.00.\n",
      "episode number:  569\n",
      "reward till now:  -225.0\n",
      "time step:  0\n",
      "episode number:  569\n",
      "reward till now:  -225.0\n",
      "time step:  1\n",
      "episode number:  569\n",
      "reward till now:  -225.0\n",
      "time step:  2\n",
      "episode number:  569\n",
      "reward till now:  -225.0\n",
      "time step:  3\n",
      "episode number:  569\n",
      "reward till now:  -226.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 570 reward -226.00, Last 30ep Avg. rewards -226.00.\n",
      "episode number:  570\n",
      "reward till now:  -226.0\n",
      "time step:  0\n",
      "episode number:  570\n",
      "reward till now:  -226.0\n",
      "time step:  1\n",
      "episode number:  570\n",
      "reward till now:  -226.0\n",
      "time step:  2\n",
      "episode number:  570\n",
      "reward till now:  -226.0\n",
      "time step:  3\n",
      "episode number:  570\n",
      "reward till now:  -227.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 571 reward -227.00, Last 30ep Avg. rewards -227.00.\n",
      "episode number:  571\n",
      "reward till now:  -227.0\n",
      "time step:  0\n",
      "episode number:  571\n",
      "reward till now:  -227.0\n",
      "time step:  1\n",
      "episode number:  571\n",
      "reward till now:  -227.0\n",
      "time step:  2\n",
      "episode number:  571\n",
      "reward till now:  -227.0\n",
      "time step:  3\n",
      "episode number:  571\n",
      "reward till now:  -228.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 572 reward -228.00, Last 30ep Avg. rewards -228.00.\n",
      "episode number:  572\n",
      "reward till now:  -228.0\n",
      "time step:  0\n",
      "episode number:  572\n",
      "reward till now:  -228.0\n",
      "time step:  1\n",
      "episode number:  572\n",
      "reward till now:  -228.0\n",
      "time step:  2\n",
      "episode number:  572\n",
      "reward till now:  -228.0\n",
      "time step:  3\n",
      "episode number:  572\n",
      "reward till now:  -229.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 573 reward -229.00, Last 30ep Avg. rewards -229.00.\n",
      "episode number:  573\n",
      "reward till now:  -229.0\n",
      "time step:  0\n",
      "episode number:  573\n",
      "reward till now:  -229.0\n",
      "time step:  1\n",
      "episode number:  573\n",
      "reward till now:  -229.0\n",
      "time step:  2\n",
      "episode number:  573\n",
      "reward till now:  -229.0\n",
      "time step:  3\n",
      "episode number:  573\n",
      "reward till now:  -230.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 574 reward -230.00, Last 30ep Avg. rewards -230.00.\n",
      "episode number:  574\n",
      "reward till now:  -230.0\n",
      "time step:  0\n",
      "episode number:  574\n",
      "reward till now:  -230.0\n",
      "time step:  1\n",
      "episode number:  574\n",
      "reward till now:  -230.0\n",
      "time step:  2\n",
      "episode number:  574\n",
      "reward till now:  -230.0\n",
      "time step:  3\n",
      "episode number:  574\n",
      "reward till now:  -231.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 575 reward -231.00, Last 30ep Avg. rewards -231.00.\n",
      "episode number:  575\n",
      "reward till now:  -231.0\n",
      "time step:  0\n",
      "episode number:  575\n",
      "reward till now:  -231.0\n",
      "time step:  1\n",
      "episode number:  575\n",
      "reward till now:  -231.0\n",
      "time step:  2\n",
      "episode number:  575\n",
      "reward till now:  -231.0\n",
      "time step:  3\n",
      "episode number:  575\n",
      "reward till now:  -232.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 576 reward -232.00, Last 30ep Avg. rewards -232.00.\n",
      "episode number:  576\n",
      "reward till now:  -232.0\n",
      "time step:  0\n",
      "episode number:  576\n",
      "reward till now:  -232.0\n",
      "time step:  1\n",
      "episode number:  576\n",
      "reward till now:  -232.0\n",
      "time step:  2\n",
      "episode number:  576\n",
      "reward till now:  -232.0\n",
      "time step:  3\n",
      "episode number:  576\n",
      "reward till now:  -233.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 577 reward -233.00, Last 30ep Avg. rewards -233.00.\n",
      "episode number:  577\n",
      "reward till now:  -233.0\n",
      "time step:  0\n",
      "episode number:  577\n",
      "reward till now:  -233.0\n",
      "time step:  1\n",
      "episode number:  577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -233.0\n",
      "time step:  2\n",
      "episode number:  577\n",
      "reward till now:  -233.0\n",
      "time step:  3\n",
      "episode number:  577\n",
      "reward till now:  -234.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 578 reward -234.00, Last 30ep Avg. rewards -234.00.\n",
      "episode number:  578\n",
      "reward till now:  -234.0\n",
      "time step:  0\n",
      "episode number:  578\n",
      "reward till now:  -234.0\n",
      "time step:  1\n",
      "episode number:  578\n",
      "reward till now:  -234.0\n",
      "time step:  2\n",
      "episode number:  578\n",
      "reward till now:  -234.0\n",
      "time step:  3\n",
      "episode number:  578\n",
      "reward till now:  -235.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 579 reward -235.00, Last 30ep Avg. rewards -235.00.\n",
      "episode number:  579\n",
      "reward till now:  -235.0\n",
      "time step:  0\n",
      "episode number:  579\n",
      "reward till now:  -235.0\n",
      "time step:  1\n",
      "episode number:  579\n",
      "reward till now:  -235.0\n",
      "time step:  2\n",
      "episode number:  579\n",
      "reward till now:  -235.0\n",
      "time step:  3\n",
      "episode number:  579\n",
      "reward till now:  -236.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 580 reward -236.00, Last 30ep Avg. rewards -236.00.\n",
      "episode number:  580\n",
      "reward till now:  -236.0\n",
      "time step:  0\n",
      "episode number:  580\n",
      "reward till now:  -236.0\n",
      "time step:  1\n",
      "episode number:  580\n",
      "reward till now:  -236.0\n",
      "time step:  2\n",
      "episode number:  580\n",
      "reward till now:  -236.0\n",
      "time step:  3\n",
      "episode number:  580\n",
      "reward till now:  -237.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 581 reward -237.00, Last 30ep Avg. rewards -237.00.\n",
      "episode number:  581\n",
      "reward till now:  -237.0\n",
      "time step:  0\n",
      "episode number:  581\n",
      "reward till now:  -237.0\n",
      "time step:  1\n",
      "episode number:  581\n",
      "reward till now:  -237.0\n",
      "time step:  2\n",
      "episode number:  581\n",
      "reward till now:  -237.0\n",
      "time step:  3\n",
      "episode number:  581\n",
      "reward till now:  -238.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 582 reward -238.00, Last 30ep Avg. rewards -238.00.\n",
      "episode number:  582\n",
      "reward till now:  -238.0\n",
      "time step:  0\n",
      "episode number:  582\n",
      "reward till now:  -238.0\n",
      "time step:  1\n",
      "episode number:  582\n",
      "reward till now:  -238.0\n",
      "time step:  2\n",
      "episode number:  582\n",
      "reward till now:  -238.0\n",
      "time step:  3\n",
      "episode number:  582\n",
      "reward till now:  -239.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 583 reward -239.00, Last 30ep Avg. rewards -239.00.\n",
      "episode number:  583\n",
      "reward till now:  -239.0\n",
      "time step:  0\n",
      "episode number:  583\n",
      "reward till now:  -239.0\n",
      "time step:  1\n",
      "episode number:  583\n",
      "reward till now:  -239.0\n",
      "time step:  2\n",
      "episode number:  583\n",
      "reward till now:  -239.0\n",
      "time step:  3\n",
      "episode number:  583\n",
      "reward till now:  -240.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 584 reward -240.00, Last 30ep Avg. rewards -240.00.\n",
      "episode number:  584\n",
      "reward till now:  -240.0\n",
      "time step:  0\n",
      "episode number:  584\n",
      "reward till now:  -240.0\n",
      "time step:  1\n",
      "episode number:  584\n",
      "reward till now:  -240.0\n",
      "time step:  2\n",
      "episode number:  584\n",
      "reward till now:  -240.0\n",
      "time step:  3\n",
      "episode number:  584\n",
      "reward till now:  -241.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 585 reward -241.00, Last 30ep Avg. rewards -241.00.\n",
      "episode number:  585\n",
      "reward till now:  -241.0\n",
      "time step:  0\n",
      "episode number:  585\n",
      "reward till now:  -241.0\n",
      "time step:  1\n",
      "episode number:  585\n",
      "reward till now:  -241.0\n",
      "time step:  2\n",
      "episode number:  585\n",
      "reward till now:  -241.0\n",
      "time step:  3\n",
      "episode number:  585\n",
      "reward till now:  -242.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 586 reward -242.00, Last 30ep Avg. rewards -242.00.\n",
      "episode number:  586\n",
      "reward till now:  -242.0\n",
      "time step:  0\n",
      "episode number:  586\n",
      "reward till now:  -242.0\n",
      "time step:  1\n",
      "episode number:  586\n",
      "reward till now:  -242.0\n",
      "time step:  2\n",
      "episode number:  586\n",
      "reward till now:  -242.0\n",
      "time step:  3\n",
      "episode number:  586\n",
      "reward till now:  -243.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 587 reward -243.00, Last 30ep Avg. rewards -243.00.\n",
      "episode number:  587\n",
      "reward till now:  -243.0\n",
      "time step:  0\n",
      "episode number:  587\n",
      "reward till now:  -243.0\n",
      "time step:  1\n",
      "episode number:  587\n",
      "reward till now:  -243.0\n",
      "time step:  2\n",
      "episode number:  587\n",
      "reward till now:  -243.0\n",
      "time step:  3\n",
      "episode number:  587\n",
      "reward till now:  -244.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 588 reward -244.00, Last 30ep Avg. rewards -244.00.\n",
      "episode number:  588\n",
      "reward till now:  -244.0\n",
      "time step:  0\n",
      "episode number:  588\n",
      "reward till now:  -244.0\n",
      "time step:  1\n",
      "episode number:  588\n",
      "reward till now:  -244.0\n",
      "time step:  2\n",
      "episode number:  588\n",
      "reward till now:  -244.0\n",
      "time step:  3\n",
      "episode number:  588\n",
      "reward till now:  -245.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 589 reward -245.00, Last 30ep Avg. rewards -245.00.\n",
      "episode number:  589\n",
      "reward till now:  -245.0\n",
      "time step:  0\n",
      "episode number:  589\n",
      "reward till now:  -245.0\n",
      "time step:  1\n",
      "episode number:  589\n",
      "reward till now:  -245.0\n",
      "time step:  2\n",
      "episode number:  589\n",
      "reward till now:  -245.0\n",
      "time step:  3\n",
      "episode number:  589\n",
      "reward till now:  -246.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 590 reward -246.00, Last 30ep Avg. rewards -246.00.\n",
      "episode number:  590\n",
      "reward till now:  -246.0\n",
      "time step:  0\n",
      "episode number:  590\n",
      "reward till now:  -246.0\n",
      "time step:  1\n",
      "episode number:  590\n",
      "reward till now:  -246.0\n",
      "time step:  2\n",
      "episode number:  590\n",
      "reward till now:  -246.0\n",
      "time step:  3\n",
      "episode number:  590\n",
      "reward till now:  -247.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 591 reward -247.00, Last 30ep Avg. rewards -247.00.\n",
      "episode number:  591\n",
      "reward till now:  -247.0\n",
      "time step:  0\n",
      "episode number:  591\n",
      "reward till now:  -247.0\n",
      "time step:  1\n",
      "episode number:  591\n",
      "reward till now:  -247.0\n",
      "time step:  2\n",
      "episode number:  591\n",
      "reward till now:  -247.0\n",
      "time step:  3\n",
      "episode number:  591\n",
      "reward till now:  -248.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 592 reward -248.00, Last 30ep Avg. rewards -248.00.\n",
      "episode number:  592\n",
      "reward till now:  -248.0\n",
      "time step:  0\n",
      "episode number:  592\n",
      "reward till now:  -248.0\n",
      "time step:  1\n",
      "episode number:  592\n",
      "reward till now:  -248.0\n",
      "time step:  2\n",
      "episode number:  592\n",
      "reward till now:  -248.0\n",
      "time step:  3\n",
      "episode number:  592\n",
      "reward till now:  -249.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 593 reward -249.00, Last 30ep Avg. rewards -249.00.\n",
      "episode number:  593\n",
      "reward till now:  -249.0\n",
      "time step:  0\n",
      "episode number:  593\n",
      "reward till now:  -249.0\n",
      "time step:  1\n",
      "episode number:  593\n",
      "reward till now:  -249.0\n",
      "time step:  2\n",
      "episode number:  593\n",
      "reward till now:  -249.0\n",
      "time step:  3\n",
      "episode number:  593\n",
      "reward till now:  -250.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 594 reward -250.00, Last 30ep Avg. rewards -250.00.\n",
      "episode number:  594\n",
      "reward till now:  -250.0\n",
      "time step:  0\n",
      "episode number:  594\n",
      "reward till now:  -250.0\n",
      "time step:  1\n",
      "episode number:  594\n",
      "reward till now:  -250.0\n",
      "time step:  2\n",
      "episode number:  594\n",
      "reward till now:  -250.0\n",
      "time step:  3\n",
      "episode number:  594\n",
      "reward till now:  -251.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 595 reward -251.00, Last 30ep Avg. rewards -251.00.\n",
      "episode number:  595\n",
      "reward till now:  -251.0\n",
      "time step:  0\n",
      "episode number:  595\n",
      "reward till now:  -251.0\n",
      "time step:  1\n",
      "episode number:  595\n",
      "reward till now:  -251.0\n",
      "time step:  2\n",
      "episode number:  595\n",
      "reward till now:  -251.0\n",
      "time step:  3\n",
      "episode number:  595\n",
      "reward till now:  -252.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 596 reward -252.00, Last 30ep Avg. rewards -252.00.\n",
      "episode number:  596\n",
      "reward till now:  -252.0\n",
      "time step:  0\n",
      "episode number:  596\n",
      "reward till now:  -252.0\n",
      "time step:  1\n",
      "episode number:  596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -252.0\n",
      "time step:  2\n",
      "episode number:  596\n",
      "reward till now:  -252.0\n",
      "time step:  3\n",
      "episode number:  596\n",
      "reward till now:  -253.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 597 reward -253.00, Last 30ep Avg. rewards -253.00.\n",
      "episode number:  597\n",
      "reward till now:  -253.0\n",
      "time step:  0\n",
      "episode number:  597\n",
      "reward till now:  -253.0\n",
      "time step:  1\n",
      "episode number:  597\n",
      "reward till now:  -253.0\n",
      "time step:  2\n",
      "episode number:  597\n",
      "reward till now:  -253.0\n",
      "time step:  3\n",
      "episode number:  597\n",
      "reward till now:  -254.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 598 reward -254.00, Last 30ep Avg. rewards -254.00.\n",
      "episode number:  598\n",
      "reward till now:  -254.0\n",
      "time step:  0\n",
      "episode number:  598\n",
      "reward till now:  -254.0\n",
      "time step:  1\n",
      "episode number:  598\n",
      "reward till now:  -254.0\n",
      "time step:  2\n",
      "episode number:  598\n",
      "reward till now:  -254.0\n",
      "time step:  3\n",
      "episode number:  598\n",
      "reward till now:  -255.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 599 reward -255.00, Last 30ep Avg. rewards -255.00.\n",
      "episode number:  599\n",
      "reward till now:  -255.0\n",
      "time step:  0\n",
      "episode number:  599\n",
      "reward till now:  -255.0\n",
      "time step:  1\n",
      "episode number:  599\n",
      "reward till now:  -255.0\n",
      "time step:  2\n",
      "episode number:  599\n",
      "reward till now:  -255.0\n",
      "time step:  3\n",
      "episode number:  599\n",
      "reward till now:  -256.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 600 reward -256.00, Last 30ep Avg. rewards -256.00.\n",
      "episode number:  600\n",
      "reward till now:  -256.0\n",
      "time step:  0\n",
      "episode number:  600\n",
      "reward till now:  -256.0\n",
      "time step:  1\n",
      "episode number:  600\n",
      "reward till now:  -256.0\n",
      "time step:  2\n",
      "episode number:  600\n",
      "reward till now:  -256.0\n",
      "time step:  3\n",
      "episode number:  600\n",
      "reward till now:  -257.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 601 reward -257.00, Last 30ep Avg. rewards -257.00.\n",
      "episode number:  601\n",
      "reward till now:  -257.0\n",
      "time step:  0\n",
      "episode number:  601\n",
      "reward till now:  -257.0\n",
      "time step:  1\n",
      "episode number:  601\n",
      "reward till now:  -257.0\n",
      "time step:  2\n",
      "episode number:  601\n",
      "reward till now:  -257.0\n",
      "time step:  3\n",
      "episode number:  601\n",
      "reward till now:  -258.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 602 reward -258.00, Last 30ep Avg. rewards -258.00.\n",
      "episode number:  602\n",
      "reward till now:  -258.0\n",
      "time step:  0\n",
      "episode number:  602\n",
      "reward till now:  -258.0\n",
      "time step:  1\n",
      "episode number:  602\n",
      "reward till now:  -258.0\n",
      "time step:  2\n",
      "episode number:  602\n",
      "reward till now:  -258.0\n",
      "time step:  3\n",
      "episode number:  602\n",
      "reward till now:  -259.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 603 reward -259.00, Last 30ep Avg. rewards -259.00.\n",
      "episode number:  603\n",
      "reward till now:  -259.0\n",
      "time step:  0\n",
      "episode number:  603\n",
      "reward till now:  -259.0\n",
      "time step:  1\n",
      "episode number:  603\n",
      "reward till now:  -259.0\n",
      "time step:  2\n",
      "episode number:  603\n",
      "reward till now:  -259.0\n",
      "time step:  3\n",
      "episode number:  603\n",
      "reward till now:  -260.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 604 reward -260.00, Last 30ep Avg. rewards -260.00.\n",
      "episode number:  604\n",
      "reward till now:  -260.0\n",
      "time step:  0\n",
      "episode number:  604\n",
      "reward till now:  -260.0\n",
      "time step:  1\n",
      "episode number:  604\n",
      "reward till now:  -260.0\n",
      "time step:  2\n",
      "episode number:  604\n",
      "reward till now:  -260.0\n",
      "time step:  3\n",
      "episode number:  604\n",
      "reward till now:  -261.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 605 reward -261.00, Last 30ep Avg. rewards -261.00.\n",
      "episode number:  605\n",
      "reward till now:  -261.0\n",
      "time step:  0\n",
      "episode number:  605\n",
      "reward till now:  -261.0\n",
      "time step:  1\n",
      "episode number:  605\n",
      "reward till now:  -261.0\n",
      "time step:  2\n",
      "episode number:  605\n",
      "reward till now:  -261.0\n",
      "time step:  3\n",
      "episode number:  605\n",
      "reward till now:  -262.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 606 reward -262.00, Last 30ep Avg. rewards -262.00.\n",
      "episode number:  606\n",
      "reward till now:  -262.0\n",
      "time step:  0\n",
      "episode number:  606\n",
      "reward till now:  -262.0\n",
      "time step:  1\n",
      "episode number:  606\n",
      "reward till now:  -262.0\n",
      "time step:  2\n",
      "episode number:  606\n",
      "reward till now:  -262.0\n",
      "time step:  3\n",
      "episode number:  606\n",
      "reward till now:  -263.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 607 reward -263.00, Last 30ep Avg. rewards -263.00.\n",
      "episode number:  607\n",
      "reward till now:  -263.0\n",
      "time step:  0\n",
      "episode number:  607\n",
      "reward till now:  -263.0\n",
      "time step:  1\n",
      "episode number:  607\n",
      "reward till now:  -263.0\n",
      "time step:  2\n",
      "episode number:  607\n",
      "reward till now:  -263.0\n",
      "time step:  3\n",
      "episode number:  607\n",
      "reward till now:  -264.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 608 reward -264.00, Last 30ep Avg. rewards -264.00.\n",
      "episode number:  608\n",
      "reward till now:  -264.0\n",
      "time step:  0\n",
      "episode number:  608\n",
      "reward till now:  -264.0\n",
      "time step:  1\n",
      "episode number:  608\n",
      "reward till now:  -264.0\n",
      "time step:  2\n",
      "episode number:  608\n",
      "reward till now:  -264.0\n",
      "time step:  3\n",
      "episode number:  608\n",
      "reward till now:  -265.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 609 reward -265.00, Last 30ep Avg. rewards -265.00.\n",
      "episode number:  609\n",
      "reward till now:  -265.0\n",
      "time step:  0\n",
      "episode number:  609\n",
      "reward till now:  -265.0\n",
      "time step:  1\n",
      "episode number:  609\n",
      "reward till now:  -265.0\n",
      "time step:  2\n",
      "episode number:  609\n",
      "reward till now:  -265.0\n",
      "time step:  3\n",
      "episode number:  609\n",
      "reward till now:  -266.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 610 reward -266.00, Last 30ep Avg. rewards -266.00.\n",
      "episode number:  610\n",
      "reward till now:  -266.0\n",
      "time step:  0\n",
      "episode number:  610\n",
      "reward till now:  -266.0\n",
      "time step:  1\n",
      "episode number:  610\n",
      "reward till now:  -266.0\n",
      "time step:  2\n",
      "episode number:  610\n",
      "reward till now:  -266.0\n",
      "time step:  3\n",
      "episode number:  610\n",
      "reward till now:  -267.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 611 reward -267.00, Last 30ep Avg. rewards -267.00.\n",
      "episode number:  611\n",
      "reward till now:  -267.0\n",
      "time step:  0\n",
      "episode number:  611\n",
      "reward till now:  -267.0\n",
      "time step:  1\n",
      "episode number:  611\n",
      "reward till now:  -267.0\n",
      "time step:  2\n",
      "episode number:  611\n",
      "reward till now:  -267.0\n",
      "time step:  3\n",
      "episode number:  611\n",
      "reward till now:  -268.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 612 reward -268.00, Last 30ep Avg. rewards -268.00.\n",
      "episode number:  612\n",
      "reward till now:  -268.0\n",
      "time step:  0\n",
      "episode number:  612\n",
      "reward till now:  -268.0\n",
      "time step:  1\n",
      "episode number:  612\n",
      "reward till now:  -268.0\n",
      "time step:  2\n",
      "episode number:  612\n",
      "reward till now:  -268.0\n",
      "time step:  3\n",
      "episode number:  612\n",
      "reward till now:  -269.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 613 reward -269.00, Last 30ep Avg. rewards -269.00.\n",
      "episode number:  613\n",
      "reward till now:  -269.0\n",
      "time step:  0\n",
      "episode number:  613\n",
      "reward till now:  -269.0\n",
      "time step:  1\n",
      "episode number:  613\n",
      "reward till now:  -269.0\n",
      "time step:  2\n",
      "episode number:  613\n",
      "reward till now:  -269.0\n",
      "time step:  3\n",
      "episode number:  613\n",
      "reward till now:  -270.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 614 reward -270.00, Last 30ep Avg. rewards -270.00.\n",
      "episode number:  614\n",
      "reward till now:  -270.0\n",
      "time step:  0\n",
      "episode number:  614\n",
      "reward till now:  -270.0\n",
      "time step:  1\n",
      "episode number:  614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -270.0\n",
      "time step:  2\n",
      "episode number:  614\n",
      "reward till now:  -270.0\n",
      "time step:  3\n",
      "episode number:  614\n",
      "reward till now:  -271.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 615 reward -271.00, Last 30ep Avg. rewards -271.00.\n",
      "episode number:  615\n",
      "reward till now:  -271.0\n",
      "time step:  0\n",
      "episode number:  615\n",
      "reward till now:  -271.0\n",
      "time step:  1\n",
      "episode number:  615\n",
      "reward till now:  -271.0\n",
      "time step:  2\n",
      "episode number:  615\n",
      "reward till now:  -271.0\n",
      "time step:  3\n",
      "episode number:  615\n",
      "reward till now:  -272.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 616 reward -272.00, Last 30ep Avg. rewards -272.00.\n",
      "episode number:  616\n",
      "reward till now:  -272.0\n",
      "time step:  0\n",
      "episode number:  616\n",
      "reward till now:  -272.0\n",
      "time step:  1\n",
      "episode number:  616\n",
      "reward till now:  -272.0\n",
      "time step:  2\n",
      "episode number:  616\n",
      "reward till now:  -272.0\n",
      "time step:  3\n",
      "episode number:  616\n",
      "reward till now:  -273.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 617 reward -273.00, Last 30ep Avg. rewards -273.00.\n",
      "episode number:  617\n",
      "reward till now:  -273.0\n",
      "time step:  0\n",
      "episode number:  617\n",
      "reward till now:  -273.0\n",
      "time step:  1\n",
      "episode number:  617\n",
      "reward till now:  -273.0\n",
      "time step:  2\n",
      "episode number:  617\n",
      "reward till now:  -273.0\n",
      "time step:  3\n",
      "episode number:  617\n",
      "reward till now:  -274.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 618 reward -274.00, Last 30ep Avg. rewards -274.00.\n",
      "episode number:  618\n",
      "reward till now:  -274.0\n",
      "time step:  0\n",
      "episode number:  618\n",
      "reward till now:  -274.0\n",
      "time step:  1\n",
      "episode number:  618\n",
      "reward till now:  -274.0\n",
      "time step:  2\n",
      "episode number:  618\n",
      "reward till now:  -274.0\n",
      "time step:  3\n",
      "episode number:  618\n",
      "reward till now:  -275.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 619 reward -275.00, Last 30ep Avg. rewards -275.00.\n",
      "episode number:  619\n",
      "reward till now:  -275.0\n",
      "time step:  0\n",
      "episode number:  619\n",
      "reward till now:  -275.0\n",
      "time step:  1\n",
      "episode number:  619\n",
      "reward till now:  -275.0\n",
      "time step:  2\n",
      "episode number:  619\n",
      "reward till now:  -275.0\n",
      "time step:  3\n",
      "episode number:  619\n",
      "reward till now:  -276.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 620 reward -276.00, Last 30ep Avg. rewards -276.00.\n",
      "episode number:  620\n",
      "reward till now:  -276.0\n",
      "time step:  0\n",
      "episode number:  620\n",
      "reward till now:  -276.0\n",
      "time step:  1\n",
      "episode number:  620\n",
      "reward till now:  -276.0\n",
      "time step:  2\n",
      "episode number:  620\n",
      "reward till now:  -276.0\n",
      "time step:  3\n",
      "episode number:  620\n",
      "reward till now:  -277.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 621 reward -277.00, Last 30ep Avg. rewards -277.00.\n",
      "episode number:  621\n",
      "reward till now:  -277.0\n",
      "time step:  0\n",
      "episode number:  621\n",
      "reward till now:  -277.0\n",
      "time step:  1\n",
      "episode number:  621\n",
      "reward till now:  -277.0\n",
      "time step:  2\n",
      "episode number:  621\n",
      "reward till now:  -277.0\n",
      "time step:  3\n",
      "episode number:  621\n",
      "reward till now:  -278.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 622 reward -278.00, Last 30ep Avg. rewards -278.00.\n",
      "episode number:  622\n",
      "reward till now:  -278.0\n",
      "time step:  0\n",
      "episode number:  622\n",
      "reward till now:  -278.0\n",
      "time step:  1\n",
      "episode number:  622\n",
      "reward till now:  -278.0\n",
      "time step:  2\n",
      "episode number:  622\n",
      "reward till now:  -278.0\n",
      "time step:  3\n",
      "episode number:  622\n",
      "reward till now:  -279.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 623 reward -279.00, Last 30ep Avg. rewards -279.00.\n",
      "episode number:  623\n",
      "reward till now:  -279.0\n",
      "time step:  0\n",
      "episode number:  623\n",
      "reward till now:  -279.0\n",
      "time step:  1\n",
      "episode number:  623\n",
      "reward till now:  -279.0\n",
      "time step:  2\n",
      "episode number:  623\n",
      "reward till now:  -279.0\n",
      "time step:  3\n",
      "episode number:  623\n",
      "reward till now:  -280.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 624 reward -280.00, Last 30ep Avg. rewards -280.00.\n",
      "episode number:  624\n",
      "reward till now:  -280.0\n",
      "time step:  0\n",
      "episode number:  624\n",
      "reward till now:  -280.0\n",
      "time step:  1\n",
      "episode number:  624\n",
      "reward till now:  -280.0\n",
      "time step:  2\n",
      "episode number:  624\n",
      "reward till now:  -280.0\n",
      "time step:  3\n",
      "episode number:  624\n",
      "reward till now:  -281.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 625 reward -281.00, Last 30ep Avg. rewards -281.00.\n",
      "episode number:  625\n",
      "reward till now:  -281.0\n",
      "time step:  0\n",
      "episode number:  625\n",
      "reward till now:  -281.0\n",
      "time step:  1\n",
      "episode number:  625\n",
      "reward till now:  -281.0\n",
      "time step:  2\n",
      "episode number:  625\n",
      "reward till now:  -281.0\n",
      "time step:  3\n",
      "episode number:  625\n",
      "reward till now:  -282.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 626 reward -282.00, Last 30ep Avg. rewards -282.00.\n",
      "episode number:  626\n",
      "reward till now:  -282.0\n",
      "time step:  0\n",
      "episode number:  626\n",
      "reward till now:  -282.0\n",
      "time step:  1\n",
      "episode number:  626\n",
      "reward till now:  -282.0\n",
      "time step:  2\n",
      "episode number:  626\n",
      "reward till now:  -282.0\n",
      "time step:  3\n",
      "episode number:  626\n",
      "reward till now:  -283.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 627 reward -283.00, Last 30ep Avg. rewards -283.00.\n",
      "episode number:  627\n",
      "reward till now:  -283.0\n",
      "time step:  0\n",
      "episode number:  627\n",
      "reward till now:  -283.0\n",
      "time step:  1\n",
      "episode number:  627\n",
      "reward till now:  -283.0\n",
      "time step:  2\n",
      "episode number:  627\n",
      "reward till now:  -283.0\n",
      "time step:  3\n",
      "episode number:  627\n",
      "reward till now:  -284.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 628 reward -284.00, Last 30ep Avg. rewards -284.00.\n",
      "episode number:  628\n",
      "reward till now:  -284.0\n",
      "time step:  0\n",
      "episode number:  628\n",
      "reward till now:  -284.0\n",
      "time step:  1\n",
      "episode number:  628\n",
      "reward till now:  -284.0\n",
      "time step:  2\n",
      "episode number:  628\n",
      "reward till now:  -284.0\n",
      "time step:  3\n",
      "episode number:  628\n",
      "reward till now:  -285.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 629 reward -285.00, Last 30ep Avg. rewards -285.00.\n",
      "episode number:  629\n",
      "reward till now:  -285.0\n",
      "time step:  0\n",
      "episode number:  629\n",
      "reward till now:  -285.0\n",
      "time step:  1\n",
      "episode number:  629\n",
      "reward till now:  -285.0\n",
      "time step:  2\n",
      "episode number:  629\n",
      "reward till now:  -285.0\n",
      "time step:  3\n",
      "episode number:  629\n",
      "reward till now:  -286.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 630 reward -286.00, Last 30ep Avg. rewards -286.00.\n",
      "episode number:  630\n",
      "reward till now:  -286.0\n",
      "time step:  0\n",
      "episode number:  630\n",
      "reward till now:  -286.0\n",
      "time step:  1\n",
      "episode number:  630\n",
      "reward till now:  -286.0\n",
      "time step:  2\n",
      "episode number:  630\n",
      "reward till now:  -286.0\n",
      "time step:  3\n",
      "episode number:  630\n",
      "reward till now:  -287.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 631 reward -287.00, Last 30ep Avg. rewards -287.00.\n",
      "episode number:  631\n",
      "reward till now:  -287.0\n",
      "time step:  0\n",
      "episode number:  631\n",
      "reward till now:  -287.0\n",
      "time step:  1\n",
      "episode number:  631\n",
      "reward till now:  -287.0\n",
      "time step:  2\n",
      "episode number:  631\n",
      "reward till now:  -287.0\n",
      "time step:  3\n",
      "episode number:  631\n",
      "reward till now:  -288.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 632 reward -288.00, Last 30ep Avg. rewards -288.00.\n",
      "episode number:  632\n",
      "reward till now:  -288.0\n",
      "time step:  0\n",
      "episode number:  632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -288.0\n",
      "time step:  1\n",
      "episode number:  632\n",
      "reward till now:  -288.0\n",
      "time step:  2\n",
      "episode number:  632\n",
      "reward till now:  -288.0\n",
      "time step:  3\n",
      "episode number:  632\n",
      "reward till now:  -289.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 633 reward -289.00, Last 30ep Avg. rewards -289.00.\n",
      "episode number:  633\n",
      "reward till now:  -289.0\n",
      "time step:  0\n",
      "episode number:  633\n",
      "reward till now:  -289.0\n",
      "time step:  1\n",
      "episode number:  633\n",
      "reward till now:  -289.0\n",
      "time step:  2\n",
      "episode number:  633\n",
      "reward till now:  -289.0\n",
      "time step:  3\n",
      "episode number:  633\n",
      "reward till now:  -290.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 634 reward -290.00, Last 30ep Avg. rewards -290.00.\n",
      "episode number:  634\n",
      "reward till now:  -290.0\n",
      "time step:  0\n",
      "episode number:  634\n",
      "reward till now:  -290.0\n",
      "time step:  1\n",
      "episode number:  634\n",
      "reward till now:  -290.0\n",
      "time step:  2\n",
      "episode number:  634\n",
      "reward till now:  -290.0\n",
      "time step:  3\n",
      "episode number:  634\n",
      "reward till now:  -291.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 635 reward -291.00, Last 30ep Avg. rewards -291.00.\n",
      "episode number:  635\n",
      "reward till now:  -291.0\n",
      "time step:  0\n",
      "episode number:  635\n",
      "reward till now:  -291.0\n",
      "time step:  1\n",
      "episode number:  635\n",
      "reward till now:  -291.0\n",
      "time step:  2\n",
      "episode number:  635\n",
      "reward till now:  -291.0\n",
      "time step:  3\n",
      "episode number:  635\n",
      "reward till now:  -292.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 636 reward -292.00, Last 30ep Avg. rewards -292.00.\n",
      "episode number:  636\n",
      "reward till now:  -292.0\n",
      "time step:  0\n",
      "episode number:  636\n",
      "reward till now:  -292.0\n",
      "time step:  1\n",
      "episode number:  636\n",
      "reward till now:  -292.0\n",
      "time step:  2\n",
      "episode number:  636\n",
      "reward till now:  -292.0\n",
      "time step:  3\n",
      "episode number:  636\n",
      "reward till now:  -293.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 637 reward -293.00, Last 30ep Avg. rewards -293.00.\n",
      "episode number:  637\n",
      "reward till now:  -293.0\n",
      "time step:  0\n",
      "episode number:  637\n",
      "reward till now:  -293.0\n",
      "time step:  1\n",
      "episode number:  637\n",
      "reward till now:  -293.0\n",
      "time step:  2\n",
      "episode number:  637\n",
      "reward till now:  -293.0\n",
      "time step:  3\n",
      "episode number:  637\n",
      "reward till now:  -294.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 638 reward -294.00, Last 30ep Avg. rewards -294.00.\n",
      "episode number:  638\n",
      "reward till now:  -294.0\n",
      "time step:  0\n",
      "episode number:  638\n",
      "reward till now:  -294.0\n",
      "time step:  1\n",
      "episode number:  638\n",
      "reward till now:  -294.0\n",
      "time step:  2\n",
      "episode number:  638\n",
      "reward till now:  -294.0\n",
      "time step:  3\n",
      "episode number:  638\n",
      "reward till now:  -295.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 639 reward -295.00, Last 30ep Avg. rewards -295.00.\n",
      "episode number:  639\n",
      "reward till now:  -295.0\n",
      "time step:  0\n",
      "episode number:  639\n",
      "reward till now:  -295.0\n",
      "time step:  1\n",
      "episode number:  639\n",
      "reward till now:  -295.0\n",
      "time step:  2\n",
      "episode number:  639\n",
      "reward till now:  -295.0\n",
      "time step:  3\n",
      "episode number:  639\n",
      "reward till now:  -296.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 640 reward -296.00, Last 30ep Avg. rewards -296.00.\n",
      "episode number:  640\n",
      "reward till now:  -296.0\n",
      "time step:  0\n",
      "episode number:  640\n",
      "reward till now:  -296.0\n",
      "time step:  1\n",
      "episode number:  640\n",
      "reward till now:  -296.0\n",
      "time step:  2\n",
      "episode number:  640\n",
      "reward till now:  -296.0\n",
      "time step:  3\n",
      "episode number:  640\n",
      "reward till now:  -297.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 641 reward -297.00, Last 30ep Avg. rewards -297.00.\n",
      "episode number:  641\n",
      "reward till now:  -297.0\n",
      "time step:  0\n",
      "episode number:  641\n",
      "reward till now:  -297.0\n",
      "time step:  1\n",
      "episode number:  641\n",
      "reward till now:  -297.0\n",
      "time step:  2\n",
      "episode number:  641\n",
      "reward till now:  -297.0\n",
      "time step:  3\n",
      "episode number:  641\n",
      "reward till now:  -298.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 642 reward -298.00, Last 30ep Avg. rewards -298.00.\n",
      "episode number:  642\n",
      "reward till now:  -298.0\n",
      "time step:  0\n",
      "episode number:  642\n",
      "reward till now:  -298.0\n",
      "time step:  1\n",
      "episode number:  642\n",
      "reward till now:  -298.0\n",
      "time step:  2\n",
      "episode number:  642\n",
      "reward till now:  -298.0\n",
      "time step:  3\n",
      "episode number:  642\n",
      "reward till now:  -299.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 643 reward -299.00, Last 30ep Avg. rewards -299.00.\n",
      "episode number:  643\n",
      "reward till now:  -299.0\n",
      "time step:  0\n",
      "episode number:  643\n",
      "reward till now:  -299.0\n",
      "time step:  1\n",
      "episode number:  643\n",
      "reward till now:  -299.0\n",
      "time step:  2\n",
      "episode number:  643\n",
      "reward till now:  -299.0\n",
      "time step:  3\n",
      "episode number:  643\n",
      "reward till now:  -300.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 644 reward -300.00, Last 30ep Avg. rewards -300.00.\n",
      "episode number:  644\n",
      "reward till now:  -300.0\n",
      "time step:  0\n",
      "episode number:  644\n",
      "reward till now:  -300.0\n",
      "time step:  1\n",
      "episode number:  644\n",
      "reward till now:  -300.0\n",
      "time step:  2\n",
      "episode number:  644\n",
      "reward till now:  -300.0\n",
      "time step:  3\n",
      "episode number:  644\n",
      "reward till now:  -301.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 645 reward -301.00, Last 30ep Avg. rewards -301.00.\n",
      "episode number:  645\n",
      "reward till now:  -301.0\n",
      "time step:  0\n",
      "episode number:  645\n",
      "reward till now:  -301.0\n",
      "time step:  1\n",
      "episode number:  645\n",
      "reward till now:  -301.0\n",
      "time step:  2\n",
      "episode number:  645\n",
      "reward till now:  -301.0\n",
      "time step:  3\n",
      "episode number:  645\n",
      "reward till now:  -302.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 646 reward -302.00, Last 30ep Avg. rewards -302.00.\n",
      "episode number:  646\n",
      "reward till now:  -302.0\n",
      "time step:  0\n",
      "episode number:  646\n",
      "reward till now:  -302.0\n",
      "time step:  1\n",
      "episode number:  646\n",
      "reward till now:  -302.0\n",
      "time step:  2\n",
      "episode number:  646\n",
      "reward till now:  -302.0\n",
      "time step:  3\n",
      "episode number:  646\n",
      "reward till now:  -303.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 647 reward -303.00, Last 30ep Avg. rewards -303.00.\n",
      "episode number:  647\n",
      "reward till now:  -303.0\n",
      "time step:  0\n",
      "episode number:  647\n",
      "reward till now:  -303.0\n",
      "time step:  1\n",
      "episode number:  647\n",
      "reward till now:  -303.0\n",
      "time step:  2\n",
      "episode number:  647\n",
      "reward till now:  -303.0\n",
      "time step:  3\n",
      "episode number:  647\n",
      "reward till now:  -304.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 648 reward -304.00, Last 30ep Avg. rewards -304.00.\n",
      "episode number:  648\n",
      "reward till now:  -304.0\n",
      "time step:  0\n",
      "episode number:  648\n",
      "reward till now:  -304.0\n",
      "time step:  1\n",
      "episode number:  648\n",
      "reward till now:  -304.0\n",
      "time step:  2\n",
      "episode number:  648\n",
      "reward till now:  -304.0\n",
      "time step:  3\n",
      "episode number:  648\n",
      "reward till now:  -305.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 649 reward -305.00, Last 30ep Avg. rewards -305.00.\n",
      "episode number:  649\n",
      "reward till now:  -305.0\n",
      "time step:  0\n",
      "episode number:  649\n",
      "reward till now:  -305.0\n",
      "time step:  1\n",
      "episode number:  649\n",
      "reward till now:  -305.0\n",
      "time step:  2\n",
      "episode number:  649\n",
      "reward till now:  -305.0\n",
      "time step:  3\n",
      "episode number:  649\n",
      "reward till now:  -306.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 650 reward -306.00, Last 30ep Avg. rewards -306.00.\n",
      "episode number:  650\n",
      "reward till now:  -306.0\n",
      "time step:  0\n",
      "episode number:  650\n",
      "reward till now:  -306.0\n",
      "time step:  1\n",
      "episode number:  650\n",
      "reward till now:  -306.0\n",
      "time step:  2\n",
      "episode number:  650\n",
      "reward till now:  -306.0\n",
      "time step:  3\n",
      "episode number:  650\n",
      "reward till now:  -307.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 651 reward -307.00, Last 30ep Avg. rewards -307.00.\n",
      "episode number:  651\n",
      "reward till now:  -307.0\n",
      "time step:  0\n",
      "episode number:  651\n",
      "reward till now:  -307.0\n",
      "time step:  1\n",
      "episode number:  651\n",
      "reward till now:  -307.0\n",
      "time step:  2\n",
      "episode number:  651\n",
      "reward till now:  -307.0\n",
      "time step:  3\n",
      "episode number:  651\n",
      "reward till now:  -308.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 652 reward -308.00, Last 30ep Avg. rewards -308.00.\n",
      "episode number:  652\n",
      "reward till now:  -308.0\n",
      "time step:  0\n",
      "episode number:  652\n",
      "reward till now:  -308.0\n",
      "time step:  1\n",
      "episode number:  652\n",
      "reward till now:  -308.0\n",
      "time step:  2\n",
      "episode number:  652\n",
      "reward till now:  -308.0\n",
      "time step:  3\n",
      "episode number:  652\n",
      "reward till now:  -309.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 653 reward -309.00, Last 30ep Avg. rewards -309.00.\n",
      "episode number:  653\n",
      "reward till now:  -309.0\n",
      "time step:  0\n",
      "episode number:  653\n",
      "reward till now:  -309.0\n",
      "time step:  1\n",
      "episode number:  653\n",
      "reward till now:  -309.0\n",
      "time step:  2\n",
      "episode number:  653\n",
      "reward till now:  -309.0\n",
      "time step:  3\n",
      "episode number:  653\n",
      "reward till now:  -310.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 654 reward -310.00, Last 30ep Avg. rewards -310.00.\n",
      "episode number:  654\n",
      "reward till now:  -310.0\n",
      "time step:  0\n",
      "episode number:  654\n",
      "reward till now:  -310.0\n",
      "time step:  1\n",
      "episode number:  654\n",
      "reward till now:  -310.0\n",
      "time step:  2\n",
      "episode number:  654\n",
      "reward till now:  -310.0\n",
      "time step:  3\n",
      "episode number:  654\n",
      "reward till now:  -311.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 655 reward -311.00, Last 30ep Avg. rewards -311.00.\n",
      "episode number:  655\n",
      "reward till now:  -311.0\n",
      "time step:  0\n",
      "episode number:  655\n",
      "reward till now:  -311.0\n",
      "time step:  1\n",
      "episode number:  655\n",
      "reward till now:  -311.0\n",
      "time step:  2\n",
      "episode number:  655\n",
      "reward till now:  -311.0\n",
      "time step:  3\n",
      "episode number:  655\n",
      "reward till now:  -312.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 656 reward -312.00, Last 30ep Avg. rewards -312.00.\n",
      "episode number:  656\n",
      "reward till now:  -312.0\n",
      "time step:  0\n",
      "episode number:  656\n",
      "reward till now:  -312.0\n",
      "time step:  1\n",
      "episode number:  656\n",
      "reward till now:  -312.0\n",
      "time step:  2\n",
      "episode number:  656\n",
      "reward till now:  -312.0\n",
      "time step:  3\n",
      "episode number:  656\n",
      "reward till now:  -313.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 657 reward -313.00, Last 30ep Avg. rewards -313.00.\n",
      "episode number:  657\n",
      "reward till now:  -313.0\n",
      "time step:  0\n",
      "episode number:  657\n",
      "reward till now:  -313.0\n",
      "time step:  1\n",
      "episode number:  657\n",
      "reward till now:  -313.0\n",
      "time step:  2\n",
      "episode number:  657\n",
      "reward till now:  -313.0\n",
      "time step:  3\n",
      "episode number:  657\n",
      "reward till now:  -314.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 658 reward -314.00, Last 30ep Avg. rewards -314.00.\n",
      "episode number:  658\n",
      "reward till now:  -314.0\n",
      "time step:  0\n",
      "episode number:  658\n",
      "reward till now:  -314.0\n",
      "time step:  1\n",
      "episode number:  658\n",
      "reward till now:  -314.0\n",
      "time step:  2\n",
      "episode number:  658\n",
      "reward till now:  -314.0\n",
      "time step:  3\n",
      "episode number:  658\n",
      "reward till now:  -315.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 659 reward -315.00, Last 30ep Avg. rewards -315.00.\n",
      "episode number:  659\n",
      "reward till now:  -315.0\n",
      "time step:  0\n",
      "episode number:  659\n",
      "reward till now:  -315.0\n",
      "time step:  1\n",
      "episode number:  659\n",
      "reward till now:  -315.0\n",
      "time step:  2\n",
      "episode number:  659\n",
      "reward till now:  -315.0\n",
      "time step:  3\n",
      "episode number:  659\n",
      "reward till now:  -316.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 660 reward -316.00, Last 30ep Avg. rewards -316.00.\n",
      "episode number:  660\n",
      "reward till now:  -316.0\n",
      "time step:  0\n",
      "episode number:  660\n",
      "reward till now:  -316.0\n",
      "time step:  1\n",
      "episode number:  660\n",
      "reward till now:  -316.0\n",
      "time step:  2\n",
      "episode number:  660\n",
      "reward till now:  -316.0\n",
      "time step:  3\n",
      "episode number:  660\n",
      "reward till now:  -317.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 661 reward -317.00, Last 30ep Avg. rewards -317.00.\n",
      "episode number:  661\n",
      "reward till now:  -317.0\n",
      "time step:  0\n",
      "episode number:  661\n",
      "reward till now:  -317.0\n",
      "time step:  1\n",
      "episode number:  661\n",
      "reward till now:  -317.0\n",
      "time step:  2\n",
      "episode number:  661\n",
      "reward till now:  -317.0\n",
      "time step:  3\n",
      "episode number:  661\n",
      "reward till now:  -318.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 662 reward -318.00, Last 30ep Avg. rewards -318.00.\n",
      "episode number:  662\n",
      "reward till now:  -318.0\n",
      "time step:  0\n",
      "episode number:  662\n",
      "reward till now:  -318.0\n",
      "time step:  1\n",
      "episode number:  662\n",
      "reward till now:  -318.0\n",
      "time step:  2\n",
      "episode number:  662\n",
      "reward till now:  -318.0\n",
      "time step:  3\n",
      "episode number:  662\n",
      "reward till now:  -319.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 663 reward -319.00, Last 30ep Avg. rewards -319.00.\n",
      "episode number:  663\n",
      "reward till now:  -319.0\n",
      "time step:  0\n",
      "episode number:  663\n",
      "reward till now:  -319.0\n",
      "time step:  1\n",
      "episode number:  663\n",
      "reward till now:  -319.0\n",
      "time step:  2\n",
      "episode number:  663\n",
      "reward till now:  -319.0\n",
      "time step:  3\n",
      "episode number:  663\n",
      "reward till now:  -320.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 664 reward -320.00, Last 30ep Avg. rewards -320.00.\n",
      "episode number:  664\n",
      "reward till now:  -320.0\n",
      "time step:  0\n",
      "episode number:  664\n",
      "reward till now:  -320.0\n",
      "time step:  1\n",
      "episode number:  664\n",
      "reward till now:  -320.0\n",
      "time step:  2\n",
      "episode number:  664\n",
      "reward till now:  -320.0\n",
      "time step:  3\n",
      "episode number:  664\n",
      "reward till now:  -321.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 665 reward -321.00, Last 30ep Avg. rewards -321.00.\n",
      "episode number:  665\n",
      "reward till now:  -321.0\n",
      "time step:  0\n",
      "episode number:  665\n",
      "reward till now:  -321.0\n",
      "time step:  1\n",
      "episode number:  665\n",
      "reward till now:  -321.0\n",
      "time step:  2\n",
      "episode number:  665\n",
      "reward till now:  -321.0\n",
      "time step:  3\n",
      "episode number:  665\n",
      "reward till now:  -322.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 666 reward -322.00, Last 30ep Avg. rewards -322.00.\n",
      "episode number:  666\n",
      "reward till now:  -322.0\n",
      "time step:  0\n",
      "episode number:  666\n",
      "reward till now:  -322.0\n",
      "time step:  1\n",
      "episode number:  666\n",
      "reward till now:  -322.0\n",
      "time step:  2\n",
      "episode number:  666\n",
      "reward till now:  -322.0\n",
      "time step:  3\n",
      "episode number:  666\n",
      "reward till now:  -323.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 667 reward -323.00, Last 30ep Avg. rewards -323.00.\n",
      "episode number:  667\n",
      "reward till now:  -323.0\n",
      "time step:  0\n",
      "episode number:  667\n",
      "reward till now:  -323.0\n",
      "time step:  1\n",
      "episode number:  667\n",
      "reward till now:  -323.0\n",
      "time step:  2\n",
      "episode number:  667\n",
      "reward till now:  -323.0\n",
      "time step:  3\n",
      "episode number:  667\n",
      "reward till now:  -324.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 668 reward -324.00, Last 30ep Avg. rewards -324.00.\n",
      "episode number:  668\n",
      "reward till now:  -324.0\n",
      "time step:  0\n",
      "episode number:  668\n",
      "reward till now:  -324.0\n",
      "time step:  1\n",
      "episode number:  668\n",
      "reward till now:  -324.0\n",
      "time step:  2\n",
      "episode number:  668\n",
      "reward till now:  -324.0\n",
      "time step:  3\n",
      "episode number:  668\n",
      "reward till now:  -325.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 669 reward -325.00, Last 30ep Avg. rewards -325.00.\n",
      "episode number:  669\n",
      "reward till now:  -325.0\n",
      "time step:  0\n",
      "episode number:  669\n",
      "reward till now:  -325.0\n",
      "time step:  1\n",
      "episode number:  669\n",
      "reward till now:  -325.0\n",
      "time step:  2\n",
      "episode number:  669\n",
      "reward till now:  -325.0\n",
      "time step:  3\n",
      "episode number:  669\n",
      "reward till now:  -326.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 670 reward -326.00, Last 30ep Avg. rewards -326.00.\n",
      "episode number:  670\n",
      "reward till now:  -326.0\n",
      "time step:  0\n",
      "episode number:  670\n",
      "reward till now:  -326.0\n",
      "time step:  1\n",
      "episode number:  670\n",
      "reward till now:  -326.0\n",
      "time step:  2\n",
      "episode number:  670\n",
      "reward till now:  -326.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time step:  3\n",
      "episode number:  670\n",
      "reward till now:  -327.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 671 reward -327.00, Last 30ep Avg. rewards -327.00.\n",
      "episode number:  671\n",
      "reward till now:  -327.0\n",
      "time step:  0\n",
      "episode number:  671\n",
      "reward till now:  -327.0\n",
      "time step:  1\n",
      "episode number:  671\n",
      "reward till now:  -327.0\n",
      "time step:  2\n",
      "episode number:  671\n",
      "reward till now:  -327.0\n",
      "time step:  3\n",
      "episode number:  671\n",
      "reward till now:  -328.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 672 reward -328.00, Last 30ep Avg. rewards -328.00.\n",
      "episode number:  672\n",
      "reward till now:  -328.0\n",
      "time step:  0\n",
      "episode number:  672\n",
      "reward till now:  -328.0\n",
      "time step:  1\n",
      "episode number:  672\n",
      "reward till now:  -328.0\n",
      "time step:  2\n",
      "episode number:  672\n",
      "reward till now:  -328.0\n",
      "time step:  3\n",
      "episode number:  672\n",
      "reward till now:  -329.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 673 reward -329.00, Last 30ep Avg. rewards -329.00.\n",
      "episode number:  673\n",
      "reward till now:  -329.0\n",
      "time step:  0\n",
      "episode number:  673\n",
      "reward till now:  -329.0\n",
      "time step:  1\n",
      "episode number:  673\n",
      "reward till now:  -329.0\n",
      "time step:  2\n",
      "episode number:  673\n",
      "reward till now:  -329.0\n",
      "time step:  3\n",
      "episode number:  673\n",
      "reward till now:  -330.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 674 reward -330.00, Last 30ep Avg. rewards -330.00.\n",
      "episode number:  674\n",
      "reward till now:  -330.0\n",
      "time step:  0\n",
      "episode number:  674\n",
      "reward till now:  -330.0\n",
      "time step:  1\n",
      "episode number:  674\n",
      "reward till now:  -330.0\n",
      "time step:  2\n",
      "episode number:  674\n",
      "reward till now:  -330.0\n",
      "time step:  3\n",
      "episode number:  674\n",
      "reward till now:  -331.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 675 reward -331.00, Last 30ep Avg. rewards -331.00.\n",
      "episode number:  675\n",
      "reward till now:  -331.0\n",
      "time step:  0\n",
      "episode number:  675\n",
      "reward till now:  -331.0\n",
      "time step:  1\n",
      "episode number:  675\n",
      "reward till now:  -331.0\n",
      "time step:  2\n",
      "episode number:  675\n",
      "reward till now:  -331.0\n",
      "time step:  3\n",
      "episode number:  675\n",
      "reward till now:  -332.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 676 reward -332.00, Last 30ep Avg. rewards -332.00.\n",
      "episode number:  676\n",
      "reward till now:  -332.0\n",
      "time step:  0\n",
      "episode number:  676\n",
      "reward till now:  -332.0\n",
      "time step:  1\n",
      "episode number:  676\n",
      "reward till now:  -332.0\n",
      "time step:  2\n",
      "episode number:  676\n",
      "reward till now:  -332.0\n",
      "time step:  3\n",
      "episode number:  676\n",
      "reward till now:  -333.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 677 reward -333.00, Last 30ep Avg. rewards -333.00.\n",
      "episode number:  677\n",
      "reward till now:  -333.0\n",
      "time step:  0\n",
      "episode number:  677\n",
      "reward till now:  -333.0\n",
      "time step:  1\n",
      "episode number:  677\n",
      "reward till now:  -333.0\n",
      "time step:  2\n",
      "episode number:  677\n",
      "reward till now:  -333.0\n",
      "time step:  3\n",
      "episode number:  677\n",
      "reward till now:  -334.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 678 reward -334.00, Last 30ep Avg. rewards -334.00.\n",
      "episode number:  678\n",
      "reward till now:  -334.0\n",
      "time step:  0\n",
      "episode number:  678\n",
      "reward till now:  -334.0\n",
      "time step:  1\n",
      "episode number:  678\n",
      "reward till now:  -334.0\n",
      "time step:  2\n",
      "episode number:  678\n",
      "reward till now:  -334.0\n",
      "time step:  3\n",
      "episode number:  678\n",
      "reward till now:  -335.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 679 reward -335.00, Last 30ep Avg. rewards -335.00.\n",
      "episode number:  679\n",
      "reward till now:  -335.0\n",
      "time step:  0\n",
      "episode number:  679\n",
      "reward till now:  -335.0\n",
      "time step:  1\n",
      "episode number:  679\n",
      "reward till now:  -335.0\n",
      "time step:  2\n",
      "episode number:  679\n",
      "reward till now:  -335.0\n",
      "time step:  3\n",
      "episode number:  679\n",
      "reward till now:  -336.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 680 reward -336.00, Last 30ep Avg. rewards -336.00.\n",
      "episode number:  680\n",
      "reward till now:  -336.0\n",
      "time step:  0\n",
      "episode number:  680\n",
      "reward till now:  -336.0\n",
      "time step:  1\n",
      "episode number:  680\n",
      "reward till now:  -336.0\n",
      "time step:  2\n",
      "episode number:  680\n",
      "reward till now:  -336.0\n",
      "time step:  3\n",
      "episode number:  680\n",
      "reward till now:  -337.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 681 reward -337.00, Last 30ep Avg. rewards -337.00.\n",
      "episode number:  681\n",
      "reward till now:  -337.0\n",
      "time step:  0\n",
      "episode number:  681\n",
      "reward till now:  -337.0\n",
      "time step:  1\n",
      "episode number:  681\n",
      "reward till now:  -337.0\n",
      "time step:  2\n",
      "episode number:  681\n",
      "reward till now:  -337.0\n",
      "time step:  3\n",
      "episode number:  681\n",
      "reward till now:  -338.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 682 reward -338.00, Last 30ep Avg. rewards -338.00.\n",
      "episode number:  682\n",
      "reward till now:  -338.0\n",
      "time step:  0\n",
      "episode number:  682\n",
      "reward till now:  -338.0\n",
      "time step:  1\n",
      "episode number:  682\n",
      "reward till now:  -338.0\n",
      "time step:  2\n",
      "episode number:  682\n",
      "reward till now:  -338.0\n",
      "time step:  3\n",
      "episode number:  682\n",
      "reward till now:  -339.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 683 reward -339.00, Last 30ep Avg. rewards -339.00.\n",
      "episode number:  683\n",
      "reward till now:  -339.0\n",
      "time step:  0\n",
      "episode number:  683\n",
      "reward till now:  -339.0\n",
      "time step:  1\n",
      "episode number:  683\n",
      "reward till now:  -339.0\n",
      "time step:  2\n",
      "episode number:  683\n",
      "reward till now:  -339.0\n",
      "time step:  3\n",
      "episode number:  683\n",
      "reward till now:  -340.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 684 reward -340.00, Last 30ep Avg. rewards -340.00.\n",
      "episode number:  684\n",
      "reward till now:  -340.0\n",
      "time step:  0\n",
      "episode number:  684\n",
      "reward till now:  -340.0\n",
      "time step:  1\n",
      "episode number:  684\n",
      "reward till now:  -340.0\n",
      "time step:  2\n",
      "episode number:  684\n",
      "reward till now:  -340.0\n",
      "time step:  3\n",
      "episode number:  684\n",
      "reward till now:  -341.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 685 reward -341.00, Last 30ep Avg. rewards -341.00.\n",
      "episode number:  685\n",
      "reward till now:  -341.0\n",
      "time step:  0\n",
      "episode number:  685\n",
      "reward till now:  -341.0\n",
      "time step:  1\n",
      "episode number:  685\n",
      "reward till now:  -341.0\n",
      "time step:  2\n",
      "episode number:  685\n",
      "reward till now:  -341.0\n",
      "time step:  3\n",
      "episode number:  685\n",
      "reward till now:  -342.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 686 reward -342.00, Last 30ep Avg. rewards -342.00.\n",
      "episode number:  686\n",
      "reward till now:  -342.0\n",
      "time step:  0\n",
      "episode number:  686\n",
      "reward till now:  -342.0\n",
      "time step:  1\n",
      "episode number:  686\n",
      "reward till now:  -342.0\n",
      "time step:  2\n",
      "episode number:  686\n",
      "reward till now:  -342.0\n",
      "time step:  3\n",
      "episode number:  686\n",
      "reward till now:  -343.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 687 reward -343.00, Last 30ep Avg. rewards -343.00.\n",
      "episode number:  687\n",
      "reward till now:  -343.0\n",
      "time step:  0\n",
      "episode number:  687\n",
      "reward till now:  -343.0\n",
      "time step:  1\n",
      "episode number:  687\n",
      "reward till now:  -343.0\n",
      "time step:  2\n",
      "episode number:  687\n",
      "reward till now:  -343.0\n",
      "time step:  3\n",
      "episode number:  687\n",
      "reward till now:  -344.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 688 reward -344.00, Last 30ep Avg. rewards -344.00.\n",
      "episode number:  688\n",
      "reward till now:  -344.0\n",
      "time step:  0\n",
      "episode number:  688\n",
      "reward till now:  -344.0\n",
      "time step:  1\n",
      "episode number:  688\n",
      "reward till now:  -344.0\n",
      "time step:  2\n",
      "episode number:  688\n",
      "reward till now:  -344.0\n",
      "time step:  3\n",
      "episode number:  688\n",
      "reward till now:  -345.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 689 reward -345.00, Last 30ep Avg. rewards -345.00.\n",
      "episode number:  689\n",
      "reward till now:  -345.0\n",
      "time step:  0\n",
      "episode number:  689\n",
      "reward till now:  -345.0\n",
      "time step:  1\n",
      "episode number:  689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward till now:  -345.0\n",
      "time step:  2\n",
      "episode number:  689\n",
      "reward till now:  -345.0\n",
      "time step:  3\n",
      "episode number:  689\n",
      "reward till now:  -346.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 690 reward -346.00, Last 30ep Avg. rewards -346.00.\n",
      "episode number:  690\n",
      "reward till now:  -346.0\n",
      "time step:  0\n",
      "episode number:  690\n",
      "reward till now:  -346.0\n",
      "time step:  1\n",
      "episode number:  690\n",
      "reward till now:  -346.0\n",
      "time step:  2\n",
      "episode number:  690\n",
      "reward till now:  -346.0\n",
      "time step:  3\n",
      "episode number:  690\n",
      "reward till now:  -347.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 691 reward -347.00, Last 30ep Avg. rewards -347.00.\n",
      "episode number:  691\n",
      "reward till now:  -347.0\n",
      "time step:  0\n",
      "episode number:  691\n",
      "reward till now:  -347.0\n",
      "time step:  1\n",
      "episode number:  691\n",
      "reward till now:  -347.0\n",
      "time step:  2\n",
      "episode number:  691\n",
      "reward till now:  -347.0\n",
      "time step:  3\n",
      "episode number:  691\n",
      "reward till now:  -348.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 692 reward -348.00, Last 30ep Avg. rewards -348.00.\n",
      "episode number:  692\n",
      "reward till now:  -348.0\n",
      "time step:  0\n",
      "episode number:  692\n",
      "reward till now:  -348.0\n",
      "time step:  1\n",
      "episode number:  692\n",
      "reward till now:  -348.0\n",
      "time step:  2\n",
      "episode number:  692\n",
      "reward till now:  -348.0\n",
      "time step:  3\n",
      "episode number:  692\n",
      "reward till now:  -349.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 693 reward -349.00, Last 30ep Avg. rewards -349.00.\n",
      "episode number:  693\n",
      "reward till now:  -349.0\n",
      "time step:  0\n",
      "episode number:  693\n",
      "reward till now:  -349.0\n",
      "time step:  1\n",
      "episode number:  693\n",
      "reward till now:  -349.0\n",
      "time step:  2\n",
      "episode number:  693\n",
      "reward till now:  -349.0\n",
      "time step:  3\n",
      "episode number:  693\n",
      "reward till now:  -350.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 694 reward -350.00, Last 30ep Avg. rewards -350.00.\n",
      "episode number:  694\n",
      "reward till now:  -350.0\n",
      "time step:  0\n",
      "episode number:  694\n",
      "reward till now:  -350.0\n",
      "time step:  1\n",
      "episode number:  694\n",
      "reward till now:  -350.0\n",
      "time step:  2\n",
      "episode number:  694\n",
      "reward till now:  -350.0\n",
      "time step:  3\n",
      "episode number:  694\n",
      "reward till now:  -351.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 695 reward -351.00, Last 30ep Avg. rewards -351.00.\n",
      "episode number:  695\n",
      "reward till now:  -351.0\n",
      "time step:  0\n",
      "episode number:  695\n",
      "reward till now:  -351.0\n",
      "time step:  1\n",
      "episode number:  695\n",
      "reward till now:  -351.0\n",
      "time step:  2\n",
      "episode number:  695\n",
      "reward till now:  -351.0\n",
      "time step:  3\n",
      "episode number:  695\n",
      "reward till now:  -352.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 696 reward -352.00, Last 30ep Avg. rewards -352.00.\n",
      "episode number:  696\n",
      "reward till now:  -352.0\n",
      "time step:  0\n",
      "episode number:  696\n",
      "reward till now:  -352.0\n",
      "time step:  1\n",
      "episode number:  696\n",
      "reward till now:  -352.0\n",
      "time step:  2\n",
      "episode number:  696\n",
      "reward till now:  -352.0\n",
      "time step:  3\n",
      "episode number:  696\n",
      "reward till now:  -353.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 697 reward -353.00, Last 30ep Avg. rewards -353.00.\n",
      "episode number:  697\n",
      "reward till now:  -353.0\n",
      "time step:  0\n",
      "episode number:  697\n",
      "reward till now:  -353.0\n",
      "time step:  1\n",
      "episode number:  697\n",
      "reward till now:  -353.0\n",
      "time step:  2\n",
      "episode number:  697\n",
      "reward till now:  -353.0\n",
      "time step:  3\n",
      "episode number:  697\n",
      "reward till now:  -354.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 698 reward -354.00, Last 30ep Avg. rewards -354.00.\n",
      "episode number:  698\n",
      "reward till now:  -354.0\n",
      "time step:  0\n",
      "episode number:  698\n",
      "reward till now:  -354.0\n",
      "time step:  1\n",
      "episode number:  698\n",
      "reward till now:  -354.0\n",
      "time step:  2\n",
      "episode number:  698\n",
      "reward till now:  -354.0\n",
      "time step:  3\n",
      "episode number:  698\n",
      "reward till now:  -355.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 699 reward -355.00, Last 30ep Avg. rewards -355.00.\n",
      "episode number:  699\n",
      "reward till now:  -355.0\n",
      "time step:  0\n",
      "episode number:  699\n",
      "reward till now:  -355.0\n",
      "time step:  1\n",
      "episode number:  699\n",
      "reward till now:  -355.0\n",
      "time step:  2\n",
      "episode number:  699\n",
      "reward till now:  -355.0\n",
      "time step:  3\n",
      "episode number:  699\n",
      "reward till now:  -356.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 700 reward -356.00, Last 30ep Avg. rewards -356.00.\n",
      "episode number:  700\n",
      "reward till now:  -355.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 701 reward -355.00, Last 30ep Avg. rewards -355.00.\n",
      "episode number:  701\n",
      "reward till now:  -354.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 702 reward -354.00, Last 30ep Avg. rewards -354.00.\n",
      "episode number:  702\n",
      "reward till now:  -353.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 703 reward -353.00, Last 30ep Avg. rewards -353.00.\n",
      "episode number:  703\n",
      "reward till now:  -353.0\n",
      "time step:  0\n",
      "episode number:  703\n",
      "reward till now:  -353.0\n",
      "time step:  1\n",
      "episode number:  703\n",
      "reward till now:  -353.0\n",
      "time step:  2\n",
      "episode number:  703\n",
      "reward till now:  -353.0\n",
      "time step:  3\n",
      "episode number:  703\n",
      "reward till now:  -354.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 704 reward -354.00, Last 30ep Avg. rewards -354.00.\n",
      "episode number:  704\n",
      "reward till now:  -354.0\n",
      "time step:  0\n",
      "episode number:  704\n",
      "reward till now:  -354.0\n",
      "time step:  1\n",
      "episode number:  704\n",
      "reward till now:  -354.0\n",
      "time step:  2\n",
      "episode number:  704\n",
      "reward till now:  -354.0\n",
      "time step:  3\n",
      "episode number:  704\n",
      "reward till now:  -355.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 705 reward -355.00, Last 30ep Avg. rewards -355.00.\n",
      "episode number:  705\n",
      "reward till now:  -355.0\n",
      "time step:  0\n",
      "episode number:  705\n",
      "reward till now:  -355.0\n",
      "time step:  1\n",
      "episode number:  705\n",
      "reward till now:  -355.0\n",
      "time step:  2\n",
      "episode number:  705\n",
      "reward till now:  -355.0\n",
      "time step:  3\n",
      "episode number:  705\n",
      "reward till now:  -356.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 706 reward -356.00, Last 30ep Avg. rewards -356.00.\n",
      "episode number:  706\n",
      "reward till now:  -356.0\n",
      "time step:  0\n",
      "episode number:  706\n",
      "reward till now:  -356.0\n",
      "time step:  1\n",
      "episode number:  706\n",
      "reward till now:  -356.0\n",
      "time step:  2\n",
      "episode number:  706\n",
      "reward till now:  -356.0\n",
      "time step:  3\n",
      "episode number:  706\n",
      "reward till now:  -357.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 707 reward -357.00, Last 30ep Avg. rewards -357.00.\n",
      "episode number:  707\n",
      "reward till now:  -357.0\n",
      "time step:  0\n",
      "episode number:  707\n",
      "reward till now:  -357.0\n",
      "time step:  1\n",
      "episode number:  707\n",
      "reward till now:  -357.0\n",
      "time step:  2\n",
      "episode number:  707\n",
      "reward till now:  -357.0\n",
      "time step:  3\n",
      "episode number:  707\n",
      "reward till now:  -358.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 708 reward -358.00, Last 30ep Avg. rewards -358.00.\n",
      "episode number:  708\n",
      "reward till now:  -358.0\n",
      "time step:  0\n",
      "episode number:  708\n",
      "reward till now:  -358.0\n",
      "time step:  1\n",
      "episode number:  708\n",
      "reward till now:  -358.0\n",
      "time step:  2\n",
      "episode number:  708\n",
      "reward till now:  -358.0\n",
      "time step:  3\n",
      "episode number:  708\n",
      "reward till now:  -359.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 709 reward -359.00, Last 30ep Avg. rewards -359.00.\n",
      "episode number:  709\n",
      "reward till now:  -359.0\n",
      "time step:  0\n",
      "episode number:  709\n",
      "reward till now:  -359.0\n",
      "time step:  1\n",
      "episode number:  709\n",
      "reward till now:  -359.0\n",
      "time step:  2\n",
      "episode number:  709\n",
      "reward till now:  -359.0\n",
      "time step:  3\n",
      "episode number:  709\n",
      "reward till now:  -360.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 710 reward -360.00, Last 30ep Avg. rewards -360.00.\n",
      "episode number:  710\n",
      "reward till now:  -360.0\n",
      "time step:  0\n",
      "episode number:  710\n",
      "reward till now:  -360.0\n",
      "time step:  1\n",
      "episode number:  710\n",
      "reward till now:  -360.0\n",
      "time step:  2\n",
      "episode number:  710\n",
      "reward till now:  -360.0\n",
      "time step:  3\n",
      "episode number:  710\n",
      "reward till now:  -361.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 711 reward -361.00, Last 30ep Avg. rewards -361.00.\n",
      "episode number:  711\n",
      "reward till now:  -361.0\n",
      "time step:  0\n",
      "episode number:  711\n",
      "reward till now:  -361.0\n",
      "time step:  1\n",
      "episode number:  711\n",
      "reward till now:  -361.0\n",
      "time step:  2\n",
      "episode number:  711\n",
      "reward till now:  -361.0\n",
      "time step:  3\n",
      "episode number:  711\n",
      "reward till now:  -362.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 712 reward -362.00, Last 30ep Avg. rewards -362.00.\n",
      "episode number:  712\n",
      "reward till now:  -362.0\n",
      "time step:  0\n",
      "episode number:  712\n",
      "reward till now:  -362.0\n",
      "time step:  1\n",
      "episode number:  712\n",
      "reward till now:  -362.0\n",
      "time step:  2\n",
      "episode number:  712\n",
      "reward till now:  -362.0\n",
      "time step:  3\n",
      "episode number:  712\n",
      "reward till now:  -363.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 713 reward -363.00, Last 30ep Avg. rewards -363.00.\n",
      "episode number:  713\n",
      "reward till now:  -363.0\n",
      "time step:  0\n",
      "episode number:  713\n",
      "reward till now:  -363.0\n",
      "time step:  1\n",
      "episode number:  713\n",
      "reward till now:  -363.0\n",
      "time step:  2\n",
      "episode number:  713\n",
      "reward till now:  -363.0\n",
      "time step:  3\n",
      "episode number:  713\n",
      "reward till now:  -364.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 714 reward -364.00, Last 30ep Avg. rewards -364.00.\n",
      "episode number:  714\n",
      "reward till now:  -364.0\n",
      "time step:  0\n",
      "episode number:  714\n",
      "reward till now:  -364.0\n",
      "time step:  1\n",
      "episode number:  714\n",
      "reward till now:  -364.0\n",
      "time step:  2\n",
      "episode number:  714\n",
      "reward till now:  -364.0\n",
      "time step:  3\n",
      "episode number:  714\n",
      "reward till now:  -365.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 715 reward -365.00, Last 30ep Avg. rewards -365.00.\n",
      "episode number:  715\n",
      "reward till now:  -365.0\n",
      "time step:  0\n",
      "episode number:  715\n",
      "reward till now:  -365.0\n",
      "time step:  1\n",
      "episode number:  715\n",
      "reward till now:  -365.0\n",
      "time step:  2\n",
      "episode number:  715\n",
      "reward till now:  -365.0\n",
      "time step:  3\n",
      "episode number:  715\n",
      "reward till now:  -366.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 716 reward -366.00, Last 30ep Avg. rewards -366.00.\n",
      "episode number:  716\n",
      "reward till now:  -366.0\n",
      "time step:  0\n",
      "episode number:  716\n",
      "reward till now:  -366.0\n",
      "time step:  1\n",
      "episode number:  716\n",
      "reward till now:  -365.0\n",
      "time step:  2\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 717 reward -365.00, Last 30ep Avg. rewards -365.00.\n",
      "episode number:  717\n",
      "reward till now:  -364.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 718 reward -364.00, Last 30ep Avg. rewards -364.00.\n",
      "episode number:  718\n",
      "reward till now:  -363.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 719 reward -363.00, Last 30ep Avg. rewards -363.00.\n",
      "episode number:  719\n",
      "reward till now:  -362.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.9025    ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 720 reward -362.00, Last 30ep Avg. rewards -362.00.\n",
      "episode number:  720\n",
      "reward till now:  -361.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 721 reward -361.00, Last 30ep Avg. rewards -361.00.\n",
      "episode number:  721\n",
      "reward till now:  -360.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 722 reward -360.00, Last 30ep Avg. rewards -360.00.\n",
      "episode number:  722\n",
      "reward till now:  -359.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 723 reward -359.00, Last 30ep Avg. rewards -359.00.\n",
      "episode number:  723\n",
      "reward till now:  -358.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 724 reward -358.00, Last 30ep Avg. rewards -358.00.\n",
      "episode number:  724\n",
      "reward till now:  -357.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 725 reward -357.00, Last 30ep Avg. rewards -357.00.\n",
      "episode number:  725\n",
      "reward till now:  -356.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 726 reward -356.00, Last 30ep Avg. rewards -356.00.\n",
      "episode number:  726\n",
      "reward till now:  -355.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 727 reward -355.00, Last 30ep Avg. rewards -355.00.\n",
      "episode number:  727\n",
      "reward till now:  -354.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 728 reward -354.00, Last 30ep Avg. rewards -354.00.\n",
      "episode number:  728\n",
      "reward till now:  -353.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 729 reward -353.00, Last 30ep Avg. rewards -353.00.\n",
      "episode number:  729\n",
      "reward till now:  -352.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 730 reward -352.00, Last 30ep Avg. rewards -352.00.\n",
      "episode number:  730\n",
      "reward till now:  -351.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 731 reward -351.00, Last 30ep Avg. rewards -351.00.\n",
      "episode number:  731\n",
      "reward till now:  -350.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 732 reward -350.00, Last 30ep Avg. rewards -350.00.\n",
      "episode number:  732\n",
      "reward till now:  -349.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 733 reward -349.00, Last 30ep Avg. rewards -349.00.\n",
      "episode number:  733\n",
      "reward till now:  -348.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 734 reward -348.00, Last 30ep Avg. rewards -348.00.\n",
      "episode number:  734\n",
      "reward till now:  -347.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 735 reward -347.00, Last 30ep Avg. rewards -347.00.\n",
      "episode number:  735\n",
      "reward till now:  -346.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 736 reward -346.00, Last 30ep Avg. rewards -346.00.\n",
      "episode number:  736\n",
      "reward till now:  -345.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 737 reward -345.00, Last 30ep Avg. rewards -345.00.\n",
      "episode number:  737\n",
      "reward till now:  -344.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 738 reward -344.00, Last 30ep Avg. rewards -344.00.\n",
      "episode number:  738\n",
      "reward till now:  -343.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 739 reward -343.00, Last 30ep Avg. rewards -343.00.\n",
      "episode number:  739\n",
      "reward till now:  -342.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 740 reward -342.00, Last 30ep Avg. rewards -342.00.\n",
      "episode number:  740\n",
      "reward till now:  -341.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 741 reward -341.00, Last 30ep Avg. rewards -341.00.\n",
      "episode number:  741\n",
      "reward till now:  -340.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 742 reward -340.00, Last 30ep Avg. rewards -340.00.\n",
      "episode number:  742\n",
      "reward till now:  -339.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 743 reward -339.00, Last 30ep Avg. rewards -339.00.\n",
      "episode number:  743\n",
      "reward till now:  -338.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 744 reward -338.00, Last 30ep Avg. rewards -338.00.\n",
      "episode number:  744\n",
      "reward till now:  -337.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 745 reward -337.00, Last 30ep Avg. rewards -337.00.\n",
      "episode number:  745\n",
      "reward till now:  -336.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 746 reward -336.00, Last 30ep Avg. rewards -336.00.\n",
      "episode number:  746\n",
      "reward till now:  -335.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 747 reward -335.00, Last 30ep Avg. rewards -335.00.\n",
      "episode number:  747\n",
      "reward till now:  -334.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 748 reward -334.00, Last 30ep Avg. rewards -334.00.\n",
      "episode number:  748\n",
      "reward till now:  -333.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 749 reward -333.00, Last 30ep Avg. rewards -333.00.\n",
      "episode number:  749\n",
      "reward till now:  -332.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 750 reward -332.00, Last 30ep Avg. rewards -332.00.\n",
      "episode number:  750\n",
      "reward till now:  -331.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 751 reward -331.00, Last 30ep Avg. rewards -331.00.\n",
      "episode number:  751\n",
      "reward till now:  -330.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 752 reward -330.00, Last 30ep Avg. rewards -330.00.\n",
      "episode number:  752\n",
      "reward till now:  -329.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 753 reward -329.00, Last 30ep Avg. rewards -329.00.\n",
      "episode number:  753\n",
      "reward till now:  -328.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 754 reward -328.00, Last 30ep Avg. rewards -328.00.\n",
      "episode number:  754\n",
      "reward till now:  -327.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 755 reward -327.00, Last 30ep Avg. rewards -327.00.\n",
      "episode number:  755\n",
      "reward till now:  -326.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 756 reward -326.00, Last 30ep Avg. rewards -326.00.\n",
      "episode number:  756\n",
      "reward till now:  -325.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 757 reward -325.00, Last 30ep Avg. rewards -325.00.\n",
      "episode number:  757\n",
      "reward till now:  -324.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 758 reward -324.00, Last 30ep Avg. rewards -324.00.\n",
      "episode number:  758\n",
      "reward till now:  -323.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 759 reward -323.00, Last 30ep Avg. rewards -323.00.\n",
      "episode number:  759\n",
      "reward till now:  -322.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 760 reward -322.00, Last 30ep Avg. rewards -322.00.\n",
      "episode number:  760\n",
      "reward till now:  -321.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 761 reward -321.00, Last 30ep Avg. rewards -321.00.\n",
      "episode number:  761\n",
      "reward till now:  -320.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 762 reward -320.00, Last 30ep Avg. rewards -320.00.\n",
      "episode number:  762\n",
      "reward till now:  -319.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 763 reward -319.00, Last 30ep Avg. rewards -319.00.\n",
      "episode number:  763\n",
      "reward till now:  -318.0\n",
      "time step:  0\n",
      "in discounted reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 764 reward -318.00, Last 30ep Avg. rewards -318.00.\n",
      "episode number:  764\n",
      "reward till now:  -317.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 765 reward -317.00, Last 30ep Avg. rewards -317.00.\n",
      "episode number:  765\n",
      "reward till now:  -316.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 766 reward -316.00, Last 30ep Avg. rewards -316.00.\n",
      "episode number:  766\n",
      "reward till now:  -315.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 767 reward -315.00, Last 30ep Avg. rewards -315.00.\n",
      "episode number:  767\n",
      "reward till now:  -314.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 768 reward -314.00, Last 30ep Avg. rewards -314.00.\n",
      "episode number:  768\n",
      "reward till now:  -313.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 769 reward -313.00, Last 30ep Avg. rewards -313.00.\n",
      "episode number:  769\n",
      "reward till now:  -312.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 770 reward -312.00, Last 30ep Avg. rewards -312.00.\n",
      "episode number:  770\n",
      "reward till now:  -311.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 771 reward -311.00, Last 30ep Avg. rewards -311.00.\n",
      "episode number:  771\n",
      "reward till now:  -310.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 772 reward -310.00, Last 30ep Avg. rewards -310.00.\n",
      "episode number:  772\n",
      "reward till now:  -309.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 773 reward -309.00, Last 30ep Avg. rewards -309.00.\n",
      "episode number:  773\n",
      "reward till now:  -308.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 774 reward -308.00, Last 30ep Avg. rewards -308.00.\n",
      "episode number:  774\n",
      "reward till now:  -307.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 775 reward -307.00, Last 30ep Avg. rewards -307.00.\n",
      "episode number:  775\n",
      "reward till now:  -306.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 776 reward -306.00, Last 30ep Avg. rewards -306.00.\n",
      "episode number:  776\n",
      "reward till now:  -305.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 777 reward -305.00, Last 30ep Avg. rewards -305.00.\n",
      "episode number:  777\n",
      "reward till now:  -304.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 778 reward -304.00, Last 30ep Avg. rewards -304.00.\n",
      "episode number:  778\n",
      "reward till now:  -303.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 779 reward -303.00, Last 30ep Avg. rewards -303.00.\n",
      "episode number:  779\n",
      "reward till now:  -302.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 780 reward -302.00, Last 30ep Avg. rewards -302.00.\n",
      "episode number:  780\n",
      "reward till now:  -301.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 781 reward -301.00, Last 30ep Avg. rewards -301.00.\n",
      "episode number:  781\n",
      "reward till now:  -300.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 782 reward -300.00, Last 30ep Avg. rewards -300.00.\n",
      "episode number:  782\n",
      "reward till now:  -299.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 783 reward -299.00, Last 30ep Avg. rewards -299.00.\n",
      "episode number:  783\n",
      "reward till now:  -298.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 784 reward -298.00, Last 30ep Avg. rewards -298.00.\n",
      "episode number:  784\n",
      "reward till now:  -297.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 785 reward -297.00, Last 30ep Avg. rewards -297.00.\n",
      "episode number:  785\n",
      "reward till now:  -296.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 786 reward -296.00, Last 30ep Avg. rewards -296.00.\n",
      "episode number:  786\n",
      "reward till now:  -295.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 787 reward -295.00, Last 30ep Avg. rewards -295.00.\n",
      "episode number:  787\n",
      "reward till now:  -294.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 788 reward -294.00, Last 30ep Avg. rewards -294.00.\n",
      "episode number:  788\n",
      "reward till now:  -293.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 789 reward -293.00, Last 30ep Avg. rewards -293.00.\n",
      "episode number:  789\n",
      "reward till now:  -292.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 790 reward -292.00, Last 30ep Avg. rewards -292.00.\n",
      "episode number:  790\n",
      "reward till now:  -291.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 791 reward -291.00, Last 30ep Avg. rewards -291.00.\n",
      "episode number:  791\n",
      "reward till now:  -290.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 792 reward -290.00, Last 30ep Avg. rewards -290.00.\n",
      "episode number:  792\n",
      "reward till now:  -289.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 793 reward -289.00, Last 30ep Avg. rewards -289.00.\n",
      "episode number:  793\n",
      "reward till now:  -288.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 794 reward -288.00, Last 30ep Avg. rewards -288.00.\n",
      "episode number:  794\n",
      "reward till now:  -287.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 795 reward -287.00, Last 30ep Avg. rewards -287.00.\n",
      "episode number:  795\n",
      "reward till now:  -286.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 796 reward -286.00, Last 30ep Avg. rewards -286.00.\n",
      "episode number:  796\n",
      "reward till now:  -285.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 797 reward -285.00, Last 30ep Avg. rewards -285.00.\n",
      "episode number:  797\n",
      "reward till now:  -284.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 798 reward -284.00, Last 30ep Avg. rewards -284.00.\n",
      "episode number:  798\n",
      "reward till now:  -283.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 799 reward -283.00, Last 30ep Avg. rewards -283.00.\n",
      "episode number:  799\n",
      "reward till now:  -282.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 800 reward -282.00, Last 30ep Avg. rewards -282.00.\n",
      "episode number:  800\n",
      "reward till now:  -281.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 801 reward -281.00, Last 30ep Avg. rewards -281.00.\n",
      "episode number:  801\n",
      "reward till now:  -280.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 802 reward -280.00, Last 30ep Avg. rewards -280.00.\n",
      "episode number:  802\n",
      "reward till now:  -279.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 803 reward -279.00, Last 30ep Avg. rewards -279.00.\n",
      "episode number:  803\n",
      "reward till now:  -278.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 804 reward -278.00, Last 30ep Avg. rewards -278.00.\n",
      "episode number:  804\n",
      "reward till now:  -277.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 805 reward -277.00, Last 30ep Avg. rewards -277.00.\n",
      "episode number:  805\n",
      "reward till now:  -276.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 806 reward -276.00, Last 30ep Avg. rewards -276.00.\n",
      "episode number:  806\n",
      "reward till now:  -275.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 807 reward -275.00, Last 30ep Avg. rewards -275.00.\n",
      "episode number:  807\n",
      "reward till now:  -274.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 808 reward -274.00, Last 30ep Avg. rewards -274.00.\n",
      "episode number:  808\n",
      "reward till now:  -273.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 809 reward -273.00, Last 30ep Avg. rewards -273.00.\n",
      "episode number:  809\n",
      "reward till now:  -272.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 810 reward -272.00, Last 30ep Avg. rewards -272.00.\n",
      "episode number:  810\n",
      "reward till now:  -271.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 811 reward -271.00, Last 30ep Avg. rewards -271.00.\n",
      "episode number:  811\n",
      "reward till now:  -270.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 812 reward -270.00, Last 30ep Avg. rewards -270.00.\n",
      "episode number:  812\n",
      "reward till now:  -270.0\n",
      "time step:  0\n",
      "episode number:  812\n",
      "reward till now:  -270.0\n",
      "time step:  1\n",
      "episode number:  812\n",
      "reward till now:  -270.0\n",
      "time step:  2\n",
      "episode number:  812\n",
      "reward till now:  -270.0\n",
      "time step:  3\n",
      "episode number:  812\n",
      "reward till now:  -271.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 813 reward -271.00, Last 30ep Avg. rewards -271.00.\n",
      "episode number:  813\n",
      "reward till now:  -271.0\n",
      "time step:  0\n",
      "episode number:  813\n",
      "reward till now:  -271.0\n",
      "time step:  1\n",
      "episode number:  813\n",
      "reward till now:  -271.0\n",
      "time step:  2\n",
      "episode number:  813\n",
      "reward till now:  -271.0\n",
      "time step:  3\n",
      "episode number:  813\n",
      "reward till now:  -272.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 814 reward -272.00, Last 30ep Avg. rewards -272.00.\n",
      "episode number:  814\n",
      "reward till now:  -272.0\n",
      "time step:  0\n",
      "episode number:  814\n",
      "reward till now:  -272.0\n",
      "time step:  1\n",
      "episode number:  814\n",
      "reward till now:  -272.0\n",
      "time step:  2\n",
      "episode number:  814\n",
      "reward till now:  -272.0\n",
      "time step:  3\n",
      "episode number:  814\n",
      "reward till now:  -273.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 815 reward -273.00, Last 30ep Avg. rewards -273.00.\n",
      "episode number:  815\n",
      "reward till now:  -273.0\n",
      "time step:  0\n",
      "episode number:  815\n",
      "reward till now:  -273.0\n",
      "time step:  1\n",
      "episode number:  815\n",
      "reward till now:  -273.0\n",
      "time step:  2\n",
      "episode number:  815\n",
      "reward till now:  -273.0\n",
      "time step:  3\n",
      "episode number:  815\n",
      "reward till now:  -274.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 816 reward -274.00, Last 30ep Avg. rewards -274.00.\n",
      "episode number:  816\n",
      "reward till now:  -274.0\n",
      "time step:  0\n",
      "episode number:  816\n",
      "reward till now:  -274.0\n",
      "time step:  1\n",
      "episode number:  816\n",
      "reward till now:  -274.0\n",
      "time step:  2\n",
      "episode number:  816\n",
      "reward till now:  -274.0\n",
      "time step:  3\n",
      "episode number:  816\n",
      "reward till now:  -275.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 817 reward -275.00, Last 30ep Avg. rewards -275.00.\n",
      "episode number:  817\n",
      "reward till now:  -275.0\n",
      "time step:  0\n",
      "episode number:  817\n",
      "reward till now:  -275.0\n",
      "time step:  1\n",
      "episode number:  817\n",
      "reward till now:  -275.0\n",
      "time step:  2\n",
      "episode number:  817\n",
      "reward till now:  -275.0\n",
      "time step:  3\n",
      "episode number:  817\n",
      "reward till now:  -276.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 818 reward -276.00, Last 30ep Avg. rewards -276.00.\n",
      "episode number:  818\n",
      "reward till now:  -276.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time step:  0\n",
      "episode number:  818\n",
      "reward till now:  -276.0\n",
      "time step:  1\n",
      "episode number:  818\n",
      "reward till now:  -276.0\n",
      "time step:  2\n",
      "episode number:  818\n",
      "reward till now:  -276.0\n",
      "time step:  3\n",
      "episode number:  818\n",
      "reward till now:  -277.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 819 reward -277.00, Last 30ep Avg. rewards -277.00.\n",
      "episode number:  819\n",
      "reward till now:  -277.0\n",
      "time step:  0\n",
      "episode number:  819\n",
      "reward till now:  -277.0\n",
      "time step:  1\n",
      "episode number:  819\n",
      "reward till now:  -277.0\n",
      "time step:  2\n",
      "episode number:  819\n",
      "reward till now:  -277.0\n",
      "time step:  3\n",
      "episode number:  819\n",
      "reward till now:  -278.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 820 reward -278.00, Last 30ep Avg. rewards -278.00.\n",
      "episode number:  820\n",
      "reward till now:  -278.0\n",
      "time step:  0\n",
      "episode number:  820\n",
      "reward till now:  -278.0\n",
      "time step:  1\n",
      "episode number:  820\n",
      "reward till now:  -278.0\n",
      "time step:  2\n",
      "episode number:  820\n",
      "reward till now:  -278.0\n",
      "time step:  3\n",
      "episode number:  820\n",
      "reward till now:  -279.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 821 reward -279.00, Last 30ep Avg. rewards -279.00.\n",
      "episode number:  821\n",
      "reward till now:  -279.0\n",
      "time step:  0\n",
      "episode number:  821\n",
      "reward till now:  -279.0\n",
      "time step:  1\n",
      "episode number:  821\n",
      "reward till now:  -279.0\n",
      "time step:  2\n",
      "episode number:  821\n",
      "reward till now:  -279.0\n",
      "time step:  3\n",
      "episode number:  821\n",
      "reward till now:  -280.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 822 reward -280.00, Last 30ep Avg. rewards -280.00.\n",
      "episode number:  822\n",
      "reward till now:  -280.0\n",
      "time step:  0\n",
      "episode number:  822\n",
      "reward till now:  -280.0\n",
      "time step:  1\n",
      "episode number:  822\n",
      "reward till now:  -280.0\n",
      "time step:  2\n",
      "episode number:  822\n",
      "reward till now:  -280.0\n",
      "time step:  3\n",
      "episode number:  822\n",
      "reward till now:  -281.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 823 reward -281.00, Last 30ep Avg. rewards -281.00.\n",
      "episode number:  823\n",
      "reward till now:  -281.0\n",
      "time step:  0\n",
      "episode number:  823\n",
      "reward till now:  -281.0\n",
      "time step:  1\n",
      "episode number:  823\n",
      "reward till now:  -281.0\n",
      "time step:  2\n",
      "episode number:  823\n",
      "reward till now:  -281.0\n",
      "time step:  3\n",
      "episode number:  823\n",
      "reward till now:  -282.0\n",
      "time step:  4\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]]\n",
      "Episode 824 reward -282.00, Last 30ep Avg. rewards -282.00.\n",
      "episode number:  824\n",
      "reward till now:  -282.0\n",
      "time step:  0\n",
      "episode number:  824\n",
      "reward till now:  -281.0\n",
      "time step:  1\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]]\n",
      "Episode 825 reward -281.00, Last 30ep Avg. rewards -281.00.\n",
      "episode number:  825\n",
      "reward till now:  -280.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 826 reward -280.00, Last 30ep Avg. rewards -280.00.\n",
      "episode number:  826\n",
      "reward till now:  -279.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 827 reward -279.00, Last 30ep Avg. rewards -279.00.\n",
      "episode number:  827\n",
      "reward till now:  -278.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 828 reward -278.00, Last 30ep Avg. rewards -278.00.\n",
      "episode number:  828\n",
      "reward till now:  -277.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 829 reward -277.00, Last 30ep Avg. rewards -277.00.\n",
      "episode number:  829\n",
      "reward till now:  -276.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [-0.81450625]\n",
      " [-0.857375  ]\n",
      " [-0.9025    ]\n",
      " [-0.95      ]\n",
      " [-1.        ]\n",
      " [ 0.95      ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 1.        ]]\n",
      "Episode 830 reward -276.00, Last 30ep Avg. rewards -276.00.\n",
      "episode number:  830\n",
      "reward till now:  -275.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 831 reward -275.00, Last 30ep Avg. rewards -275.00.\n",
      "episode number:  831\n",
      "reward till now:  -274.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 832 reward -274.00, Last 30ep Avg. rewards -274.00.\n",
      "episode number:  832\n",
      "reward till now:  -273.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 833 reward -273.00, Last 30ep Avg. rewards -273.00.\n",
      "episode number:  833\n",
      "reward till now:  -272.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 834 reward -272.00, Last 30ep Avg. rewards -272.00.\n",
      "episode number:  834\n",
      "reward till now:  -271.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 835 reward -271.00, Last 30ep Avg. rewards -271.00.\n",
      "episode number:  835\n",
      "reward till now:  -270.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 836 reward -270.00, Last 30ep Avg. rewards -270.00.\n",
      "episode number:  836\n",
      "reward till now:  -269.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 837 reward -269.00, Last 30ep Avg. rewards -269.00.\n",
      "episode number:  837\n",
      "reward till now:  -268.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 838 reward -268.00, Last 30ep Avg. rewards -268.00.\n",
      "episode number:  838\n",
      "reward till now:  -267.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 839 reward -267.00, Last 30ep Avg. rewards -267.00.\n",
      "episode number:  839\n",
      "reward till now:  -266.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 840 reward -266.00, Last 30ep Avg. rewards -266.00.\n",
      "episode number:  840\n",
      "reward till now:  -265.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 841 reward -265.00, Last 30ep Avg. rewards -265.00.\n",
      "episode number:  841\n",
      "reward till now:  -264.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 842 reward -264.00, Last 30ep Avg. rewards -264.00.\n",
      "episode number:  842\n",
      "reward till now:  -263.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 843 reward -263.00, Last 30ep Avg. rewards -263.00.\n",
      "episode number:  843\n",
      "reward till now:  -262.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 844 reward -262.00, Last 30ep Avg. rewards -262.00.\n",
      "episode number:  844\n",
      "reward till now:  -261.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 845 reward -261.00, Last 30ep Avg. rewards -261.00.\n",
      "episode number:  845\n",
      "reward till now:  -260.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 846 reward -260.00, Last 30ep Avg. rewards -260.00.\n",
      "episode number:  846\n",
      "reward till now:  -259.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 847 reward -259.00, Last 30ep Avg. rewards -259.00.\n",
      "episode number:  847\n",
      "reward till now:  -258.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 848 reward -258.00, Last 30ep Avg. rewards -258.00.\n",
      "episode number:  848\n",
      "reward till now:  -257.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 849 reward -257.00, Last 30ep Avg. rewards -257.00.\n",
      "episode number:  849\n",
      "reward till now:  -256.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 850 reward -256.00, Last 30ep Avg. rewards -256.00.\n",
      "episode number:  850\n",
      "reward till now:  -255.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 851 reward -255.00, Last 30ep Avg. rewards -255.00.\n",
      "episode number:  851\n",
      "reward till now:  -254.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 852 reward -254.00, Last 30ep Avg. rewards -254.00.\n",
      "episode number:  852\n",
      "reward till now:  -253.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 853 reward -253.00, Last 30ep Avg. rewards -253.00.\n",
      "episode number:  853\n",
      "reward till now:  -252.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 854 reward -252.00, Last 30ep Avg. rewards -252.00.\n",
      "episode number:  854\n",
      "reward till now:  -251.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 855 reward -251.00, Last 30ep Avg. rewards -251.00.\n",
      "episode number:  855\n",
      "reward till now:  -250.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 856 reward -250.00, Last 30ep Avg. rewards -250.00.\n",
      "episode number:  856\n",
      "reward till now:  -249.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 857 reward -249.00, Last 30ep Avg. rewards -249.00.\n",
      "episode number:  857\n",
      "reward till now:  -248.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 858 reward -248.00, Last 30ep Avg. rewards -248.00.\n",
      "episode number:  858\n",
      "reward till now:  -247.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 859 reward -247.00, Last 30ep Avg. rewards -247.00.\n",
      "episode number:  859\n",
      "reward till now:  -246.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 860 reward -246.00, Last 30ep Avg. rewards -246.00.\n",
      "episode number:  860\n",
      "reward till now:  -245.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 861 reward -245.00, Last 30ep Avg. rewards -245.00.\n",
      "episode number:  861\n",
      "reward till now:  -244.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 862 reward -244.00, Last 30ep Avg. rewards -244.00.\n",
      "episode number:  862\n",
      "reward till now:  -243.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 863 reward -243.00, Last 30ep Avg. rewards -243.00.\n",
      "episode number:  863\n",
      "reward till now:  -242.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 864 reward -242.00, Last 30ep Avg. rewards -242.00.\n",
      "episode number:  864\n",
      "reward till now:  -241.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 865 reward -241.00, Last 30ep Avg. rewards -241.00.\n",
      "episode number:  865\n",
      "reward till now:  -240.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 866 reward -240.00, Last 30ep Avg. rewards -240.00.\n",
      "episode number:  866\n",
      "reward till now:  -239.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 867 reward -239.00, Last 30ep Avg. rewards -239.00.\n",
      "episode number:  867\n",
      "reward till now:  -238.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 868 reward -238.00, Last 30ep Avg. rewards -238.00.\n",
      "episode number:  868\n",
      "reward till now:  -237.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 869 reward -237.00, Last 30ep Avg. rewards -237.00.\n",
      "episode number:  869\n",
      "reward till now:  -236.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 870 reward -236.00, Last 30ep Avg. rewards -236.00.\n",
      "episode number:  870\n",
      "reward till now:  -235.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 871 reward -235.00, Last 30ep Avg. rewards -235.00.\n",
      "episode number:  871\n",
      "reward till now:  -234.0\n",
      "time step:  0\n",
      "in discounted reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 872 reward -234.00, Last 30ep Avg. rewards -234.00.\n",
      "episode number:  872\n",
      "reward till now:  -233.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 873 reward -233.00, Last 30ep Avg. rewards -233.00.\n",
      "episode number:  873\n",
      "reward till now:  -232.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 874 reward -232.00, Last 30ep Avg. rewards -232.00.\n",
      "episode number:  874\n",
      "reward till now:  -231.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 875 reward -231.00, Last 30ep Avg. rewards -231.00.\n",
      "episode number:  875\n",
      "reward till now:  -230.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 876 reward -230.00, Last 30ep Avg. rewards -230.00.\n",
      "episode number:  876\n",
      "reward till now:  -229.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 877 reward -229.00, Last 30ep Avg. rewards -229.00.\n",
      "episode number:  877\n",
      "reward till now:  -228.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 878 reward -228.00, Last 30ep Avg. rewards -228.00.\n",
      "episode number:  878\n",
      "reward till now:  -227.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 879 reward -227.00, Last 30ep Avg. rewards -227.00.\n",
      "episode number:  879\n",
      "reward till now:  -226.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 880 reward -226.00, Last 30ep Avg. rewards -226.00.\n",
      "episode number:  880\n",
      "reward till now:  -225.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 881 reward -225.00, Last 30ep Avg. rewards -225.00.\n",
      "episode number:  881\n",
      "reward till now:  -224.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 882 reward -224.00, Last 30ep Avg. rewards -224.00.\n",
      "episode number:  882\n",
      "reward till now:  -223.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 883 reward -223.00, Last 30ep Avg. rewards -223.00.\n",
      "episode number:  883\n",
      "reward till now:  -222.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 884 reward -222.00, Last 30ep Avg. rewards -222.00.\n",
      "episode number:  884\n",
      "reward till now:  -221.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 885 reward -221.00, Last 30ep Avg. rewards -221.00.\n",
      "episode number:  885\n",
      "reward till now:  -220.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 886 reward -220.00, Last 30ep Avg. rewards -220.00.\n",
      "episode number:  886\n",
      "reward till now:  -219.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 887 reward -219.00, Last 30ep Avg. rewards -219.00.\n",
      "episode number:  887\n",
      "reward till now:  -218.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 888 reward -218.00, Last 30ep Avg. rewards -218.00.\n",
      "episode number:  888\n",
      "reward till now:  -217.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 889 reward -217.00, Last 30ep Avg. rewards -217.00.\n",
      "episode number:  889\n",
      "reward till now:  -216.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 890 reward -216.00, Last 30ep Avg. rewards -216.00.\n",
      "episode number:  890\n",
      "reward till now:  -215.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 891 reward -215.00, Last 30ep Avg. rewards -215.00.\n",
      "episode number:  891\n",
      "reward till now:  -214.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 892 reward -214.00, Last 30ep Avg. rewards -214.00.\n",
      "episode number:  892\n",
      "reward till now:  -213.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 893 reward -213.00, Last 30ep Avg. rewards -213.00.\n",
      "episode number:  893\n",
      "reward till now:  -212.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 894 reward -212.00, Last 30ep Avg. rewards -212.00.\n",
      "episode number:  894\n",
      "reward till now:  -211.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 895 reward -211.00, Last 30ep Avg. rewards -211.00.\n",
      "episode number:  895\n",
      "reward till now:  -210.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 896 reward -210.00, Last 30ep Avg. rewards -210.00.\n",
      "episode number:  896\n",
      "reward till now:  -209.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 897 reward -209.00, Last 30ep Avg. rewards -209.00.\n",
      "episode number:  897\n",
      "reward till now:  -208.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 898 reward -208.00, Last 30ep Avg. rewards -208.00.\n",
      "episode number:  898\n",
      "reward till now:  -207.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 899 reward -207.00, Last 30ep Avg. rewards -207.00.\n",
      "episode number:  899\n",
      "reward till now:  -206.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 900 reward -206.00, Last 30ep Avg. rewards -206.00.\n",
      "episode number:  900\n",
      "reward till now:  -205.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 901 reward -205.00, Last 30ep Avg. rewards -205.00.\n",
      "episode number:  901\n",
      "reward till now:  -204.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 902 reward -204.00, Last 30ep Avg. rewards -204.00.\n",
      "episode number:  902\n",
      "reward till now:  -203.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 903 reward -203.00, Last 30ep Avg. rewards -203.00.\n",
      "episode number:  903\n",
      "reward till now:  -202.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 904 reward -202.00, Last 30ep Avg. rewards -202.00.\n",
      "episode number:  904\n",
      "reward till now:  -201.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 905 reward -201.00, Last 30ep Avg. rewards -201.00.\n",
      "episode number:  905\n",
      "reward till now:  -200.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 906 reward -200.00, Last 30ep Avg. rewards -200.00.\n",
      "episode number:  906\n",
      "reward till now:  -199.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 907 reward -199.00, Last 30ep Avg. rewards -199.00.\n",
      "episode number:  907\n",
      "reward till now:  -198.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 908 reward -198.00, Last 30ep Avg. rewards -198.00.\n",
      "episode number:  908\n",
      "reward till now:  -197.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 909 reward -197.00, Last 30ep Avg. rewards -197.00.\n",
      "episode number:  909\n",
      "reward till now:  -196.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 910 reward -196.00, Last 30ep Avg. rewards -196.00.\n",
      "episode number:  910\n",
      "reward till now:  -195.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 911 reward -195.00, Last 30ep Avg. rewards -195.00.\n",
      "episode number:  911\n",
      "reward till now:  -194.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 912 reward -194.00, Last 30ep Avg. rewards -194.00.\n",
      "episode number:  912\n",
      "reward till now:  -193.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 913 reward -193.00, Last 30ep Avg. rewards -193.00.\n",
      "episode number:  913\n",
      "reward till now:  -192.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 914 reward -192.00, Last 30ep Avg. rewards -192.00.\n",
      "episode number:  914\n",
      "reward till now:  -191.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 915 reward -191.00, Last 30ep Avg. rewards -191.00.\n",
      "episode number:  915\n",
      "reward till now:  -190.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 916 reward -190.00, Last 30ep Avg. rewards -190.00.\n",
      "episode number:  916\n",
      "reward till now:  -189.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 917 reward -189.00, Last 30ep Avg. rewards -189.00.\n",
      "episode number:  917\n",
      "reward till now:  -188.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 918 reward -188.00, Last 30ep Avg. rewards -188.00.\n",
      "episode number:  918\n",
      "reward till now:  -187.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 919 reward -187.00, Last 30ep Avg. rewards -187.00.\n",
      "episode number:  919\n",
      "reward till now:  -186.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 920 reward -186.00, Last 30ep Avg. rewards -186.00.\n",
      "episode number:  920\n",
      "reward till now:  -185.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 921 reward -185.00, Last 30ep Avg. rewards -185.00.\n",
      "episode number:  921\n",
      "reward till now:  -184.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 922 reward -184.00, Last 30ep Avg. rewards -184.00.\n",
      "episode number:  922\n",
      "reward till now:  -183.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 923 reward -183.00, Last 30ep Avg. rewards -183.00.\n",
      "episode number:  923\n",
      "reward till now:  -182.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 924 reward -182.00, Last 30ep Avg. rewards -182.00.\n",
      "episode number:  924\n",
      "reward till now:  -181.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 925 reward -181.00, Last 30ep Avg. rewards -181.00.\n",
      "episode number:  925\n",
      "reward till now:  -180.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 926 reward -180.00, Last 30ep Avg. rewards -180.00.\n",
      "episode number:  926\n",
      "reward till now:  -179.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 927 reward -179.00, Last 30ep Avg. rewards -179.00.\n",
      "episode number:  927\n",
      "reward till now:  -178.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 928 reward -178.00, Last 30ep Avg. rewards -178.00.\n",
      "episode number:  928\n",
      "reward till now:  -177.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 929 reward -177.00, Last 30ep Avg. rewards -177.00.\n",
      "episode number:  929\n",
      "reward till now:  -176.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 930 reward -176.00, Last 30ep Avg. rewards -176.00.\n",
      "episode number:  930\n",
      "reward till now:  -175.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 931 reward -175.00, Last 30ep Avg. rewards -175.00.\n",
      "episode number:  931\n",
      "reward till now:  -174.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 932 reward -174.00, Last 30ep Avg. rewards -174.00.\n",
      "episode number:  932\n",
      "reward till now:  -173.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 933 reward -173.00, Last 30ep Avg. rewards -173.00.\n",
      "episode number:  933\n",
      "reward till now:  -172.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 934 reward -172.00, Last 30ep Avg. rewards -172.00.\n",
      "episode number:  934\n",
      "reward till now:  -171.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 935 reward -171.00, Last 30ep Avg. rewards -171.00.\n",
      "episode number:  935\n",
      "reward till now:  -170.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 936 reward -170.00, Last 30ep Avg. rewards -170.00.\n",
      "episode number:  936\n",
      "reward till now:  -169.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 937 reward -169.00, Last 30ep Avg. rewards -169.00.\n",
      "episode number:  937\n",
      "reward till now:  -168.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 938 reward -168.00, Last 30ep Avg. rewards -168.00.\n",
      "episode number:  938\n",
      "reward till now:  -167.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 939 reward -167.00, Last 30ep Avg. rewards -167.00.\n",
      "episode number:  939\n",
      "reward till now:  -166.0\n",
      "time step:  0\n",
      "in discounted reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 940 reward -166.00, Last 30ep Avg. rewards -166.00.\n",
      "episode number:  940\n",
      "reward till now:  -165.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 941 reward -165.00, Last 30ep Avg. rewards -165.00.\n",
      "episode number:  941\n",
      "reward till now:  -164.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 942 reward -164.00, Last 30ep Avg. rewards -164.00.\n",
      "episode number:  942\n",
      "reward till now:  -163.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 943 reward -163.00, Last 30ep Avg. rewards -163.00.\n",
      "episode number:  943\n",
      "reward till now:  -162.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 944 reward -162.00, Last 30ep Avg. rewards -162.00.\n",
      "episode number:  944\n",
      "reward till now:  -161.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 945 reward -161.00, Last 30ep Avg. rewards -161.00.\n",
      "episode number:  945\n",
      "reward till now:  -160.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 946 reward -160.00, Last 30ep Avg. rewards -160.00.\n",
      "episode number:  946\n",
      "reward till now:  -159.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 947 reward -159.00, Last 30ep Avg. rewards -159.00.\n",
      "episode number:  947\n",
      "reward till now:  -158.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 948 reward -158.00, Last 30ep Avg. rewards -158.00.\n",
      "episode number:  948\n",
      "reward till now:  -157.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 949 reward -157.00, Last 30ep Avg. rewards -157.00.\n",
      "episode number:  949\n",
      "reward till now:  -156.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 950 reward -156.00, Last 30ep Avg. rewards -156.00.\n",
      "episode number:  950\n",
      "reward till now:  -155.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 951 reward -155.00, Last 30ep Avg. rewards -155.00.\n",
      "episode number:  951\n",
      "reward till now:  -154.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 952 reward -154.00, Last 30ep Avg. rewards -154.00.\n",
      "episode number:  952\n",
      "reward till now:  -153.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 953 reward -153.00, Last 30ep Avg. rewards -153.00.\n",
      "episode number:  953\n",
      "reward till now:  -152.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 954 reward -152.00, Last 30ep Avg. rewards -152.00.\n",
      "episode number:  954\n",
      "reward till now:  -151.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 955 reward -151.00, Last 30ep Avg. rewards -151.00.\n",
      "episode number:  955\n",
      "reward till now:  -150.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 956 reward -150.00, Last 30ep Avg. rewards -150.00.\n",
      "episode number:  956\n",
      "reward till now:  -149.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 957 reward -149.00, Last 30ep Avg. rewards -149.00.\n",
      "episode number:  957\n",
      "reward till now:  -148.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 958 reward -148.00, Last 30ep Avg. rewards -148.00.\n",
      "episode number:  958\n",
      "reward till now:  -147.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 959 reward -147.00, Last 30ep Avg. rewards -147.00.\n",
      "episode number:  959\n",
      "reward till now:  -146.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 960 reward -146.00, Last 30ep Avg. rewards -146.00.\n",
      "episode number:  960\n",
      "reward till now:  -145.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 961 reward -145.00, Last 30ep Avg. rewards -145.00.\n",
      "episode number:  961\n",
      "reward till now:  -144.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 962 reward -144.00, Last 30ep Avg. rewards -144.00.\n",
      "episode number:  962\n",
      "reward till now:  -143.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 963 reward -143.00, Last 30ep Avg. rewards -143.00.\n",
      "episode number:  963\n",
      "reward till now:  -142.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 964 reward -142.00, Last 30ep Avg. rewards -142.00.\n",
      "episode number:  964\n",
      "reward till now:  -141.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 965 reward -141.00, Last 30ep Avg. rewards -141.00.\n",
      "episode number:  965\n",
      "reward till now:  -140.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 966 reward -140.00, Last 30ep Avg. rewards -140.00.\n",
      "episode number:  966\n",
      "reward till now:  -139.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 967 reward -139.00, Last 30ep Avg. rewards -139.00.\n",
      "episode number:  967\n",
      "reward till now:  -138.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 968 reward -138.00, Last 30ep Avg. rewards -138.00.\n",
      "episode number:  968\n",
      "reward till now:  -137.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 969 reward -137.00, Last 30ep Avg. rewards -137.00.\n",
      "episode number:  969\n",
      "reward till now:  -136.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 970 reward -136.00, Last 30ep Avg. rewards -136.00.\n",
      "episode number:  970\n",
      "reward till now:  -135.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 971 reward -135.00, Last 30ep Avg. rewards -135.00.\n",
      "episode number:  971\n",
      "reward till now:  -134.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 972 reward -134.00, Last 30ep Avg. rewards -134.00.\n",
      "episode number:  972\n",
      "reward till now:  -133.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 973 reward -133.00, Last 30ep Avg. rewards -133.00.\n",
      "episode number:  973\n",
      "reward till now:  -132.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 974 reward -132.00, Last 30ep Avg. rewards -132.00.\n",
      "episode number:  974\n",
      "reward till now:  -131.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 975 reward -131.00, Last 30ep Avg. rewards -131.00.\n",
      "episode number:  975\n",
      "reward till now:  -130.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 976 reward -130.00, Last 30ep Avg. rewards -130.00.\n",
      "episode number:  976\n",
      "reward till now:  -129.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 977 reward -129.00, Last 30ep Avg. rewards -129.00.\n",
      "episode number:  977\n",
      "reward till now:  -128.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 978 reward -128.00, Last 30ep Avg. rewards -128.00.\n",
      "episode number:  978\n",
      "reward till now:  -127.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 979 reward -127.00, Last 30ep Avg. rewards -127.00.\n",
      "episode number:  979\n",
      "reward till now:  -126.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 980 reward -126.00, Last 30ep Avg. rewards -126.00.\n",
      "episode number:  980\n",
      "reward till now:  -125.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 981 reward -125.00, Last 30ep Avg. rewards -125.00.\n",
      "episode number:  981\n",
      "reward till now:  -124.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 982 reward -124.00, Last 30ep Avg. rewards -124.00.\n",
      "episode number:  982\n",
      "reward till now:  -123.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 983 reward -123.00, Last 30ep Avg. rewards -123.00.\n",
      "episode number:  983\n",
      "reward till now:  -122.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 984 reward -122.00, Last 30ep Avg. rewards -122.00.\n",
      "episode number:  984\n",
      "reward till now:  -121.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 985 reward -121.00, Last 30ep Avg. rewards -121.00.\n",
      "episode number:  985\n",
      "reward till now:  -120.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 986 reward -120.00, Last 30ep Avg. rewards -120.00.\n",
      "episode number:  986\n",
      "reward till now:  -119.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 987 reward -119.00, Last 30ep Avg. rewards -119.00.\n",
      "episode number:  987\n",
      "reward till now:  -118.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 988 reward -118.00, Last 30ep Avg. rewards -118.00.\n",
      "episode number:  988\n",
      "reward till now:  -117.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 989 reward -117.00, Last 30ep Avg. rewards -117.00.\n",
      "episode number:  989\n",
      "reward till now:  -116.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 990 reward -116.00, Last 30ep Avg. rewards -116.00.\n",
      "episode number:  990\n",
      "reward till now:  -115.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]]\n",
      "Episode 991 reward -115.00, Last 30ep Avg. rewards -115.00.\n",
      "episode number:  991\n",
      "reward till now:  -114.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]]\n",
      "Episode 992 reward -114.00, Last 30ep Avg. rewards -114.00.\n",
      "episode number:  992\n",
      "reward till now:  -113.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 993 reward -113.00, Last 30ep Avg. rewards -113.00.\n",
      "episode number:  993\n",
      "reward till now:  -112.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 994 reward -112.00, Last 30ep Avg. rewards -112.00.\n",
      "episode number:  994\n",
      "reward till now:  -111.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 995 reward -111.00, Last 30ep Avg. rewards -111.00.\n",
      "episode number:  995\n",
      "reward till now:  -110.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 996 reward -110.00, Last 30ep Avg. rewards -110.00.\n",
      "episode number:  996\n",
      "reward till now:  -109.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 997 reward -109.00, Last 30ep Avg. rewards -109.00.\n",
      "episode number:  997\n",
      "reward till now:  -108.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 998 reward -108.00, Last 30ep Avg. rewards -108.00.\n",
      "episode number:  998\n",
      "reward till now:  -107.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 999 reward -107.00, Last 30ep Avg. rewards -107.00.\n",
      "episode number:  999\n",
      "reward till now:  -106.0\n",
      "time step:  0\n",
      "in discounted reward\n",
      "disc_rw:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Episode 1000 reward -106.00, Last 30ep Avg. rewards -106.00.\n"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "state = env.reset()\n",
    "\n",
    "agent = Agent(state[0].shape, state)\n",
    "final_reward = agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(final_reward)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.model.save(\"model_June_23.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
